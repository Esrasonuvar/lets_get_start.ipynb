{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "!nvcc -V"
      ],
      "metadata": {
        "id": "0ke2ASFJqw9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5608d638-ce89-40ed-e4eb-17a22f338132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct  6 18:00:06 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import librosa\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import tqdm \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense , Activation , Dropout\n",
        "\n",
        "import IPython.display as ipd\n",
        "from sklearn import preprocessing"
      ],
      "metadata": {
        "id": "Z2BX0Lbgqxbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HKv6dqZpri-",
        "outputId": "722ddf92-711f-4738-c2ac-ac286640935e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd gdrive/MyDrive/UrbanSound8K/metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zToKUhVWqR92",
        "outputId": "c4f5fab0-43a1-4139-ba79-d122063e2429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/UrbanSound8K/metadata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_jlCIrpqXeG",
        "outputId": "0b6fc66c-4e6c-41ca-a4a3-442e76521a68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UrbanSound8K.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!tar -xzvf \"UrbanSound8K.tar.gz\""
      ],
      "metadata": {
        "id": "FEnuUAePqfDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('UrbanSound8K.csv')"
      ],
      "metadata": {
        "id": "I8hZn5xIxE2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "TDY0toiJxn6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2e114b48-a873-4c03-d697-999a004e5c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
              "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
              "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
              "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
              "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
              "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
              "\n",
              "              class  \n",
              "0          dog_bark  \n",
              "1  children_playing  \n",
              "2  children_playing  \n",
              "3  children_playing  \n",
              "4  children_playing  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb9fb267-f556-4e1b-9737-861774fe3cbf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>slice_file_name</th>\n",
              "      <th>fsID</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>salience</th>\n",
              "      <th>fold</th>\n",
              "      <th>classID</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100032-3-0-0.wav</td>\n",
              "      <td>100032</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.317551</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100263-2-0-117.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>58.5</td>\n",
              "      <td>62.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100263-2-0-121.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>60.5</td>\n",
              "      <td>64.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100263-2-0-126.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>63.0</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100263-2-0-137.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>68.5</td>\n",
              "      <td>72.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb9fb267-f556-4e1b-9737-861774fe3cbf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb9fb267-f556-4e1b-9737-861774fe3cbf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb9fb267-f556-4e1b-9737-861774fe3cbf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "035jZgLexNmu",
        "outputId": "d378e661-eb8c-4ef6-fd2b-b300856d24e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8732 entries, 0 to 8731\n",
            "Data columns (total 8 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   slice_file_name  8732 non-null   object \n",
            " 1   fsID             8732 non-null   int64  \n",
            " 2   start            8732 non-null   float64\n",
            " 3   end              8732 non-null   float64\n",
            " 4   salience         8732 non-null   int64  \n",
            " 5   fold             8732 non-null   int64  \n",
            " 6   classID          8732 non-null   int64  \n",
            " 7   class            8732 non-null   object \n",
            "dtypes: float64(2), int64(4), object(2)\n",
            "memory usage: 545.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "1vcMYNuZqVLu",
        "outputId": "f51567de-4a56-4856-9e30-01d5baff35ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                fsID        start          end     salience         fold  \\\n",
              "count    8732.000000  8732.000000  8732.000000  8732.000000  8732.000000   \n",
              "mean   116033.493816    38.645409    42.253312     1.347000     5.385937   \n",
              "std     57991.017218    74.292126    74.369669     0.476043     2.846820   \n",
              "min       344.000000     0.000000     0.105962     1.000000     1.000000   \n",
              "25%     69942.250000     3.000000     6.839398     1.000000     3.000000   \n",
              "50%    118279.000000    10.376492    14.000000     1.000000     5.000000   \n",
              "75%    166942.000000    35.131372    38.866979     2.000000     8.000000   \n",
              "max    209992.000000   600.125356   604.125356     2.000000    10.000000   \n",
              "\n",
              "           classID  \n",
              "count  8732.000000  \n",
              "mean      4.592877  \n",
              "std       2.894544  \n",
              "min       0.000000  \n",
              "25%       2.000000  \n",
              "50%       4.000000  \n",
              "75%       7.000000  \n",
              "max       9.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-219504be-deaa-43e9-9e28-215ba51369d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fsID</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>salience</th>\n",
              "      <th>fold</th>\n",
              "      <th>classID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>8732.000000</td>\n",
              "      <td>8732.000000</td>\n",
              "      <td>8732.000000</td>\n",
              "      <td>8732.000000</td>\n",
              "      <td>8732.000000</td>\n",
              "      <td>8732.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>116033.493816</td>\n",
              "      <td>38.645409</td>\n",
              "      <td>42.253312</td>\n",
              "      <td>1.347000</td>\n",
              "      <td>5.385937</td>\n",
              "      <td>4.592877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>57991.017218</td>\n",
              "      <td>74.292126</td>\n",
              "      <td>74.369669</td>\n",
              "      <td>0.476043</td>\n",
              "      <td>2.846820</td>\n",
              "      <td>2.894544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>344.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.105962</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>69942.250000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.839398</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>118279.000000</td>\n",
              "      <td>10.376492</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>166942.000000</td>\n",
              "      <td>35.131372</td>\n",
              "      <td>38.866979</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>209992.000000</td>\n",
              "      <td>600.125356</td>\n",
              "      <td>604.125356</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-219504be-deaa-43e9-9e28-215ba51369d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-219504be-deaa-43e9-9e28-215ba51369d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-219504be-deaa-43e9-9e28-215ba51369d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "explode = (0.2, 0.2, 0.2, 0.2,0.2, 0.2, 0.2, 0.2,0.2, 0.2) \n",
        "df.groupby(['class']).sum().plot(kind='pie', y='classID',startangle=60,pctdistance=5.1, labeldistance=1.1,explode=explode,figsize=(15,15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 883
        },
        "id": "vHOI7s6Zqa2x",
        "outputId": "e03c04ff-1b80-4530-928f-290fd759f6d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe887c4da10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x1080 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"salience\"].unique() #belirginlik"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKAYQyS-rD1_",
        "outputId": "9b898e8b-c970-4d54-f3b2-1b446944fa94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_feature(file_path):\n",
        "  audio,sample_rate = librosa.load(file_path,res_type='kaiser_fast')\n",
        "  spec = librosa.feature.mfcc(y=audio,sr=sample_rate) \n",
        "  spec_cony = librosa.amplitude_to_db(spec, ref=np.max) \n",
        "  scaled_feature = np.mean(spec_cony.T,axis=0)\n",
        "  normalized_feature = preprocessing.minmax_scale(scaled_feature)\n",
        "  return normalized_feature"
      ],
      "metadata": {
        "id": "Z7IYVtQ4tzDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1UIVSH5GGlGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ew2YVbTuMUR",
        "outputId": "563ae489-d59b-40cb-9517-6b5e0e248f92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/UrbanSound8K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fold=5\n",
        "name=\"100032-3-0-0.wav\"\n",
        "path=f\"audio/fold{fold}/{name}\"\n",
        "extract_feature(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cozeC-FCGtTT",
        "outputId": "470334ce-f419-4aed-a21f-e786b10058b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.9999994e-01, 7.5367975e-01, 9.2535901e-01, 6.8857473e-01,\n",
              "       3.8730288e-01, 3.8152748e-01, 2.2929060e-01, 3.7296689e-01,\n",
              "       3.3009410e-02, 3.1196690e-01, 3.2675332e-01, 0.0000000e+00,\n",
              "       3.6786997e-01, 2.4934173e-01, 2.3050189e-02, 4.9532652e-03,\n",
              "       4.0458208e-01, 8.5365772e-04, 7.2633028e-02, 1.7787051e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XleQoLf9Gw3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8f-42L1Nzvbz",
        "outputId": "c6245a1a-ae6c-4310-ec17-06b27b4bf888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         slice_file_name    fsID       start         end  salience  fold  \\\n",
              "0       100032-3-0-0.wav  100032    0.000000    0.317551         1     5   \n",
              "1     100263-2-0-117.wav  100263   58.500000   62.500000         1     5   \n",
              "2     100263-2-0-121.wav  100263   60.500000   64.500000         1     5   \n",
              "3     100263-2-0-126.wav  100263   63.000000   67.000000         1     5   \n",
              "4     100263-2-0-137.wav  100263   68.500000   72.500000         1     5   \n",
              "...                  ...     ...         ...         ...       ...   ...   \n",
              "8727     99812-1-2-0.wav   99812  159.522205  163.522205         2     7   \n",
              "8728     99812-1-3-0.wav   99812  181.142431  183.284976         2     7   \n",
              "8729     99812-1-4-0.wav   99812  242.691902  246.197885         2     7   \n",
              "8730     99812-1-5-0.wav   99812  253.209850  255.741948         2     7   \n",
              "8731     99812-1-6-0.wav   99812  332.289233  334.821332         2     7   \n",
              "\n",
              "      classID             class  \n",
              "0           3          dog_bark  \n",
              "1           2  children_playing  \n",
              "2           2  children_playing  \n",
              "3           2  children_playing  \n",
              "4           2  children_playing  \n",
              "...       ...               ...  \n",
              "8727        1          car_horn  \n",
              "8728        1          car_horn  \n",
              "8729        1          car_horn  \n",
              "8730        1          car_horn  \n",
              "8731        1          car_horn  \n",
              "\n",
              "[8732 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2adc4d71-5969-4263-9bea-f01f6592916b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>slice_file_name</th>\n",
              "      <th>fsID</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>salience</th>\n",
              "      <th>fold</th>\n",
              "      <th>classID</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100032-3-0-0.wav</td>\n",
              "      <td>100032</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.317551</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100263-2-0-117.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>58.500000</td>\n",
              "      <td>62.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100263-2-0-121.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>60.500000</td>\n",
              "      <td>64.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100263-2-0-126.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100263-2-0-137.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>68.500000</td>\n",
              "      <td>72.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8727</th>\n",
              "      <td>99812-1-2-0.wav</td>\n",
              "      <td>99812</td>\n",
              "      <td>159.522205</td>\n",
              "      <td>163.522205</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8728</th>\n",
              "      <td>99812-1-3-0.wav</td>\n",
              "      <td>99812</td>\n",
              "      <td>181.142431</td>\n",
              "      <td>183.284976</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8729</th>\n",
              "      <td>99812-1-4-0.wav</td>\n",
              "      <td>99812</td>\n",
              "      <td>242.691902</td>\n",
              "      <td>246.197885</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8730</th>\n",
              "      <td>99812-1-5-0.wav</td>\n",
              "      <td>99812</td>\n",
              "      <td>253.209850</td>\n",
              "      <td>255.741948</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8731</th>\n",
              "      <td>99812-1-6-0.wav</td>\n",
              "      <td>99812</td>\n",
              "      <td>332.289233</td>\n",
              "      <td>334.821332</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8732 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2adc4d71-5969-4263-9bea-f01f6592916b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2adc4d71-5969-4263-9bea-f01f6592916b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2adc4d71-5969-4263-9bea-f01f6592916b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "labels=[]\n",
        "for index_num,row in df.iterrows():\n",
        "  name=row[\"slice_file_name\"]\n",
        "  fold=row[\"fold\"]\n",
        "  path=f\"audio/fold{fold}/{name}\"\n",
        "  print(index_num)\n",
        "  dat1, sampling_rate1 = librosa.load(path)\n",
        "  feature=extract_feature(path)\n",
        "  labels.append([feature,row[\"class\"]])\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "wQJIU5nizZP2",
        "outputId": "cac03a9c-0405-4fca-f816-5fc5d41576a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nlabels=[]\\nfor index_num,row in df.iterrows():\\n  name=row[\"slice_file_name\"]\\n  fold=row[\"fold\"]\\n  path=f\"audio/fold{fold}/{name}\"\\n  print(index_num)\\n  dat1, sampling_rate1 = librosa.load(path)\\n  feature=extract_feature(path)\\n  labels.append([feature,row[\"class\"]])\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "extracted_df = pd.DataFrame(labels,columns=['feature','class'])\n",
        "\n",
        "# display first fivve rows of the dataframe\n",
        "extracted_df.head()\n",
        "extracted_df.to_csv(\"extracted_df.csv\")\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "r5Ao-grW1sUY",
        "outputId": "37a1726a-ab9e-4704-b6bb-309ffbcb6918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nextracted_df = pd.DataFrame(labels,columns=[\\'feature\\',\\'class\\'])\\n\\n# display first fivve rows of the dataframe\\nextracted_df.head()\\nextracted_df.to_csv(\"extracted_df.csv\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_df=pd.read_csv(\"extracted_df.csv\")"
      ],
      "metadata": {
        "id": "qu_csSvdeaBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "d1fRyjHzeqbf",
        "outputId": "d4507b07-ac97-4256-e4a4-be8fbc9cb846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0                                            feature  \\\n",
              "0              0  [9.9999994e-01 7.5367975e-01 9.2535901e-01 6.8...   \n",
              "1              1  [1.         0.7223865  0.56764567 0.6013166  0...   \n",
              "2              2  [1.         0.73758954 0.5444557  0.56031173 0...   \n",
              "3              3  [1.         0.68863904 0.426674   0.53967434 0...   \n",
              "4              4  [0.99999994 0.7325834  0.578877   0.60740143 0...   \n",
              "...          ...                                                ...   \n",
              "8727        8727  [1.         0.7830202  0.58318514 0.5133966  0...   \n",
              "8728        8728  [0.99999994 0.7023515  0.5899351  0.606835   0...   \n",
              "8729        8729  [1.         0.76614255 0.58644474 0.53276306 0...   \n",
              "8730        8730  [0.99999994 0.7910475  0.61657596 0.52089477 0...   \n",
              "8731        8731  [1.         0.74602944 0.5467452  0.59541845 0...   \n",
              "\n",
              "                 class  \n",
              "0             dog_bark  \n",
              "1     children_playing  \n",
              "2     children_playing  \n",
              "3     children_playing  \n",
              "4     children_playing  \n",
              "...                ...  \n",
              "8727          car_horn  \n",
              "8728          car_horn  \n",
              "8729          car_horn  \n",
              "8730          car_horn  \n",
              "8731          car_horn  \n",
              "\n",
              "[8732 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a71e8f4d-eb6b-43b7-a1e0-f1a440b2817b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>feature</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[9.9999994e-01 7.5367975e-01 9.2535901e-01 6.8...</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[1.         0.7223865  0.56764567 0.6013166  0...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[1.         0.73758954 0.5444557  0.56031173 0...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[1.         0.68863904 0.426674   0.53967434 0...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[0.99999994 0.7325834  0.578877   0.60740143 0...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8727</th>\n",
              "      <td>8727</td>\n",
              "      <td>[1.         0.7830202  0.58318514 0.5133966  0...</td>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8728</th>\n",
              "      <td>8728</td>\n",
              "      <td>[0.99999994 0.7023515  0.5899351  0.606835   0...</td>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8729</th>\n",
              "      <td>8729</td>\n",
              "      <td>[1.         0.76614255 0.58644474 0.53276306 0...</td>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8730</th>\n",
              "      <td>8730</td>\n",
              "      <td>[0.99999994 0.7910475  0.61657596 0.52089477 0...</td>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8731</th>\n",
              "      <td>8731</td>\n",
              "      <td>[1.         0.74602944 0.5467452  0.59541845 0...</td>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8732 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a71e8f4d-eb6b-43b7-a1e0-f1a440b2817b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a71e8f4d-eb6b-43b7-a1e0-f1a440b2817b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a71e8f4d-eb6b-43b7-a1e0-f1a440b2817b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_df['feature']=extracted_df['feature'].str.replace(\"\\n\",\"\")"
      ],
      "metadata": {
        "id": "rEXCvuHee5sL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x=[]\n",
        "Y=[]\n",
        "for index,row in extracted_df.iterrows():\n",
        "  list_of_integers = list(map(float, np.asarray(row['feature'].strip(\"[\").strip(\"]\").split())))\n",
        "  \n",
        "  x.append(np.asarray(list_of_integers))\n",
        "  Y.append(row['class'])\n"
      ],
      "metadata": {
        "id": "yrj_i48qj48o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.asarray(x)\n",
        "Y=np.asarray(Y)"
      ],
      "metadata": {
        "id": "n9B6lNbolTmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v0NZlji2QJf",
        "outputId": "af45a00d-b341-485c-9b1e-e81d0aa1e6db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8732 entries, 0 to 8731\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Unnamed: 0  8732 non-null   int64 \n",
            " 1   feature     8732 non-null   object\n",
            " 2   class       8732 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 204.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyP6y8g3anCf",
        "outputId": "3b0e2586-2ada-470e-da31-5d4b3372a692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9999994e-01, 7.5367975e-01, 9.2535901e-01, ..., 8.5365772e-04,\n",
              "        7.2633028e-02, 1.7787051e-01],\n",
              "       [1.0000000e+00, 7.2238650e-01, 5.6764567e-01, ..., 2.0551407e-01,\n",
              "        1.3491052e-01, 1.2729698e-01],\n",
              "       [1.0000000e+00, 7.3758954e-01, 5.4445570e-01, ..., 6.6820320e-02,\n",
              "        4.8623680e-02, 2.4974936e-01],\n",
              "       ...,\n",
              "       [1.0000000e+00, 7.6614255e-01, 5.8644474e-01, ..., 1.4125037e-01,\n",
              "        2.1325469e-01, 0.0000000e+00],\n",
              "       [9.9999994e-01, 7.9104750e-01, 6.1657596e-01, ..., 1.4472115e-01,\n",
              "        1.0814518e-01, 5.6410430e-02],\n",
              "       [1.0000000e+00, 7.4602944e-01, 5.4674520e-01, ..., 4.1212636e-01,\n",
              "        3.5268310e-02, 1.7636311e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "Y = to_categorical(le.fit_transform(Y))"
      ],
      "metadata": {
        "id": "OklZ12qj1dbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, Y, test_size=0.2, random_state = 42)\n",
        "\n",
        "print(\"Number of training samples = \", x_train.shape[0])\n",
        "print(\"Number of testing samples = \",x_test.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTxK-O3LIgag",
        "outputId": "1e8880c3-06f7-42b2-a6b8-dbf8ea122d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples =  6985\n",
            "Number of testing samples =  1747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0].shape\n",
        "\n"
      ],
      "metadata": {
        "id": "PaBmQprLJTif",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11d6e71e-835b-4655-fc09-15f632c5356d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20,)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv1D(32,3, activation ='relu', input_shape= (20, 1)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCgedG3WIktJ",
        "outputId": "381441ec-748d-4881-e350-5234e37cd8f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_8 (Conv1D)           (None, 18, 32)            128       \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 128)               73856     \n",
            "                                                                 \n",
            " activation_24 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " activation_25 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 115,914\n",
            "Trainable params: 115,914\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam( lr=1e-3),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "uD-h8QX-JAHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 300\n",
        "num_batch_size = 64\n",
        "\n",
        "model.fit(\n",
        "          x_train, \n",
        "          y_train, \n",
        "          batch_size=num_batch_size, \n",
        "          epochs=num_epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "         )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHU0GVGkJIZG",
        "outputId": "9f314d5e-04a3-45f9-f075-4c7ca7766da8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 2.1556 - accuracy: 0.1791 - val_loss: 1.8606 - val_accuracy: 0.3005\n",
            "Epoch 2/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8506 - accuracy: 0.3105 - val_loss: 1.6643 - val_accuracy: 0.3898\n",
            "Epoch 3/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.7324 - accuracy: 0.3602 - val_loss: 1.5670 - val_accuracy: 0.4493\n",
            "Epoch 4/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6383 - accuracy: 0.4024 - val_loss: 1.4904 - val_accuracy: 0.4705\n",
            "Epoch 5/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.5682 - accuracy: 0.4286 - val_loss: 1.4286 - val_accuracy: 0.4860\n",
            "Epoch 6/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5378 - accuracy: 0.4498 - val_loss: 1.4009 - val_accuracy: 0.5077\n",
            "Epoch 7/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5025 - accuracy: 0.4596 - val_loss: 1.3566 - val_accuracy: 0.5283\n",
            "Epoch 8/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4383 - accuracy: 0.4898 - val_loss: 1.3254 - val_accuracy: 0.5421\n",
            "Epoch 9/300\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 1.3952 - accuracy: 0.5077 - val_loss: 1.2571 - val_accuracy: 0.5741\n",
            "Epoch 10/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 1.3778 - accuracy: 0.5168 - val_loss: 1.2364 - val_accuracy: 0.5890\n",
            "Epoch 11/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3449 - accuracy: 0.5244 - val_loss: 1.2161 - val_accuracy: 0.5924\n",
            "Epoch 12/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3195 - accuracy: 0.5340 - val_loss: 1.1920 - val_accuracy: 0.6016\n",
            "Epoch 13/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2881 - accuracy: 0.5516 - val_loss: 1.1512 - val_accuracy: 0.6234\n",
            "Epoch 14/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2570 - accuracy: 0.5635 - val_loss: 1.1377 - val_accuracy: 0.6274\n",
            "Epoch 15/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.2346 - accuracy: 0.5748 - val_loss: 1.1117 - val_accuracy: 0.6297\n",
            "Epoch 16/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2080 - accuracy: 0.5791 - val_loss: 1.0650 - val_accuracy: 0.6548\n",
            "Epoch 17/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1861 - accuracy: 0.5832 - val_loss: 1.0518 - val_accuracy: 0.6434\n",
            "Epoch 18/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1711 - accuracy: 0.5963 - val_loss: 1.0390 - val_accuracy: 0.6543\n",
            "Epoch 19/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1566 - accuracy: 0.6000 - val_loss: 1.0064 - val_accuracy: 0.6680\n",
            "Epoch 20/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1261 - accuracy: 0.6105 - val_loss: 1.0194 - val_accuracy: 0.6537\n",
            "Epoch 21/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1242 - accuracy: 0.6163 - val_loss: 0.9954 - val_accuracy: 0.6674\n",
            "Epoch 22/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0960 - accuracy: 0.6185 - val_loss: 0.9729 - val_accuracy: 0.6800\n",
            "Epoch 23/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0898 - accuracy: 0.6223 - val_loss: 0.9758 - val_accuracy: 0.6691\n",
            "Epoch 24/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0730 - accuracy: 0.6404 - val_loss: 0.9887 - val_accuracy: 0.6686\n",
            "Epoch 25/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0650 - accuracy: 0.6369 - val_loss: 0.9775 - val_accuracy: 0.6766\n",
            "Epoch 26/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0507 - accuracy: 0.6392 - val_loss: 0.9516 - val_accuracy: 0.6909\n",
            "Epoch 27/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0332 - accuracy: 0.6481 - val_loss: 0.9380 - val_accuracy: 0.6926\n",
            "Epoch 28/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0241 - accuracy: 0.6471 - val_loss: 0.9220 - val_accuracy: 0.6949\n",
            "Epoch 29/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0199 - accuracy: 0.6491 - val_loss: 0.9152 - val_accuracy: 0.7132\n",
            "Epoch 30/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0164 - accuracy: 0.6545 - val_loss: 0.9281 - val_accuracy: 0.6909\n",
            "Epoch 31/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0004 - accuracy: 0.6597 - val_loss: 0.9173 - val_accuracy: 0.7012\n",
            "Epoch 32/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9952 - accuracy: 0.6565 - val_loss: 0.8974 - val_accuracy: 0.7115\n",
            "Epoch 33/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9725 - accuracy: 0.6637 - val_loss: 0.8899 - val_accuracy: 0.7069\n",
            "Epoch 34/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9575 - accuracy: 0.6749 - val_loss: 0.8858 - val_accuracy: 0.7109\n",
            "Epoch 35/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9790 - accuracy: 0.6674 - val_loss: 0.8803 - val_accuracy: 0.7241\n",
            "Epoch 36/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9460 - accuracy: 0.6754 - val_loss: 0.8852 - val_accuracy: 0.7184\n",
            "Epoch 37/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9510 - accuracy: 0.6790 - val_loss: 0.8775 - val_accuracy: 0.7127\n",
            "Epoch 38/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9351 - accuracy: 0.6829 - val_loss: 0.8780 - val_accuracy: 0.7201\n",
            "Epoch 39/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9313 - accuracy: 0.6813 - val_loss: 0.8862 - val_accuracy: 0.7144\n",
            "Epoch 40/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9351 - accuracy: 0.6809 - val_loss: 0.8610 - val_accuracy: 0.7252\n",
            "Epoch 41/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9182 - accuracy: 0.6873 - val_loss: 0.8483 - val_accuracy: 0.7293\n",
            "Epoch 42/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9235 - accuracy: 0.6858 - val_loss: 0.8565 - val_accuracy: 0.7275\n",
            "Epoch 43/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9246 - accuracy: 0.6760 - val_loss: 0.8548 - val_accuracy: 0.7235\n",
            "Epoch 44/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9182 - accuracy: 0.6863 - val_loss: 0.8351 - val_accuracy: 0.7241\n",
            "Epoch 45/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9063 - accuracy: 0.6842 - val_loss: 0.8567 - val_accuracy: 0.7293\n",
            "Epoch 46/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9127 - accuracy: 0.6911 - val_loss: 0.8457 - val_accuracy: 0.7264\n",
            "Epoch 47/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8992 - accuracy: 0.6880 - val_loss: 0.8396 - val_accuracy: 0.7304\n",
            "Epoch 48/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8901 - accuracy: 0.6953 - val_loss: 0.8289 - val_accuracy: 0.7327\n",
            "Epoch 49/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8927 - accuracy: 0.6966 - val_loss: 0.8538 - val_accuracy: 0.7310\n",
            "Epoch 50/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8774 - accuracy: 0.6976 - val_loss: 0.8249 - val_accuracy: 0.7327\n",
            "Epoch 51/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8822 - accuracy: 0.6986 - val_loss: 0.8189 - val_accuracy: 0.7396\n",
            "Epoch 52/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8773 - accuracy: 0.7016 - val_loss: 0.8170 - val_accuracy: 0.7310\n",
            "Epoch 53/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8614 - accuracy: 0.7069 - val_loss: 0.8379 - val_accuracy: 0.7315\n",
            "Epoch 54/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8754 - accuracy: 0.7037 - val_loss: 0.8100 - val_accuracy: 0.7378\n",
            "Epoch 55/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.8599 - accuracy: 0.7128 - val_loss: 0.8107 - val_accuracy: 0.7373\n",
            "Epoch 56/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8620 - accuracy: 0.7112 - val_loss: 0.8202 - val_accuracy: 0.7315\n",
            "Epoch 57/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8420 - accuracy: 0.7097 - val_loss: 0.8199 - val_accuracy: 0.7418\n",
            "Epoch 58/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8611 - accuracy: 0.7041 - val_loss: 0.8099 - val_accuracy: 0.7413\n",
            "Epoch 59/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8617 - accuracy: 0.7057 - val_loss: 0.8188 - val_accuracy: 0.7396\n",
            "Epoch 60/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8470 - accuracy: 0.7104 - val_loss: 0.8166 - val_accuracy: 0.7384\n",
            "Epoch 61/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8440 - accuracy: 0.7120 - val_loss: 0.8026 - val_accuracy: 0.7418\n",
            "Epoch 62/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.8362 - accuracy: 0.7117 - val_loss: 0.8131 - val_accuracy: 0.7350\n",
            "Epoch 63/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8270 - accuracy: 0.7101 - val_loss: 0.8193 - val_accuracy: 0.7470\n",
            "Epoch 64/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8393 - accuracy: 0.7144 - val_loss: 0.8086 - val_accuracy: 0.7476\n",
            "Epoch 65/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8185 - accuracy: 0.7227 - val_loss: 0.8122 - val_accuracy: 0.7378\n",
            "Epoch 66/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8353 - accuracy: 0.7178 - val_loss: 0.7857 - val_accuracy: 0.7504\n",
            "Epoch 67/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8136 - accuracy: 0.7188 - val_loss: 0.8001 - val_accuracy: 0.7510\n",
            "Epoch 68/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8143 - accuracy: 0.7197 - val_loss: 0.7944 - val_accuracy: 0.7476\n",
            "Epoch 69/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8152 - accuracy: 0.7215 - val_loss: 0.8025 - val_accuracy: 0.7499\n",
            "Epoch 70/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7961 - accuracy: 0.7244 - val_loss: 0.7957 - val_accuracy: 0.7493\n",
            "Epoch 71/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8101 - accuracy: 0.7190 - val_loss: 0.7809 - val_accuracy: 0.7544\n",
            "Epoch 72/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8064 - accuracy: 0.7271 - val_loss: 0.7856 - val_accuracy: 0.7521\n",
            "Epoch 73/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7856 - accuracy: 0.7300 - val_loss: 0.7859 - val_accuracy: 0.7550\n",
            "Epoch 74/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7960 - accuracy: 0.7309 - val_loss: 0.7808 - val_accuracy: 0.7499\n",
            "Epoch 75/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7972 - accuracy: 0.7238 - val_loss: 0.7878 - val_accuracy: 0.7504\n",
            "Epoch 76/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8129 - accuracy: 0.7228 - val_loss: 0.7947 - val_accuracy: 0.7470\n",
            "Epoch 77/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7725 - accuracy: 0.7257 - val_loss: 0.8246 - val_accuracy: 0.7378\n",
            "Epoch 78/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7748 - accuracy: 0.7347 - val_loss: 0.7806 - val_accuracy: 0.7579\n",
            "Epoch 79/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7855 - accuracy: 0.7288 - val_loss: 0.7926 - val_accuracy: 0.7539\n",
            "Epoch 80/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7979 - accuracy: 0.7273 - val_loss: 0.8035 - val_accuracy: 0.7544\n",
            "Epoch 81/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7903 - accuracy: 0.7273 - val_loss: 0.7911 - val_accuracy: 0.7504\n",
            "Epoch 82/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7960 - accuracy: 0.7246 - val_loss: 0.7778 - val_accuracy: 0.7602\n",
            "Epoch 83/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7695 - accuracy: 0.7399 - val_loss: 0.8108 - val_accuracy: 0.7441\n",
            "Epoch 84/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7723 - accuracy: 0.7317 - val_loss: 0.7905 - val_accuracy: 0.7487\n",
            "Epoch 85/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7512 - accuracy: 0.7437 - val_loss: 0.7911 - val_accuracy: 0.7499\n",
            "Epoch 86/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7652 - accuracy: 0.7356 - val_loss: 0.7979 - val_accuracy: 0.7459\n",
            "Epoch 87/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7645 - accuracy: 0.7400 - val_loss: 0.7894 - val_accuracy: 0.7476\n",
            "Epoch 88/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7732 - accuracy: 0.7443 - val_loss: 0.8007 - val_accuracy: 0.7516\n",
            "Epoch 89/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7686 - accuracy: 0.7360 - val_loss: 0.7970 - val_accuracy: 0.7521\n",
            "Epoch 90/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7381 - accuracy: 0.7447 - val_loss: 0.7927 - val_accuracy: 0.7493\n",
            "Epoch 91/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7658 - accuracy: 0.7366 - val_loss: 0.7770 - val_accuracy: 0.7544\n",
            "Epoch 92/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7449 - accuracy: 0.7396 - val_loss: 0.7935 - val_accuracy: 0.7470\n",
            "Epoch 93/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7452 - accuracy: 0.7404 - val_loss: 0.7889 - val_accuracy: 0.7510\n",
            "Epoch 94/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7713 - accuracy: 0.7333 - val_loss: 0.7695 - val_accuracy: 0.7539\n",
            "Epoch 95/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7418 - accuracy: 0.7374 - val_loss: 0.7615 - val_accuracy: 0.7642\n",
            "Epoch 96/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7225 - accuracy: 0.7510 - val_loss: 0.8020 - val_accuracy: 0.7447\n",
            "Epoch 97/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.7637 - accuracy: 0.7402 - val_loss: 0.7756 - val_accuracy: 0.7567\n",
            "Epoch 98/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7385 - accuracy: 0.7475 - val_loss: 0.7763 - val_accuracy: 0.7499\n",
            "Epoch 99/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7399 - accuracy: 0.7473 - val_loss: 0.7793 - val_accuracy: 0.7579\n",
            "Epoch 100/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7671 - accuracy: 0.7382 - val_loss: 0.7807 - val_accuracy: 0.7613\n",
            "Epoch 101/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7249 - accuracy: 0.7485 - val_loss: 0.7939 - val_accuracy: 0.7476\n",
            "Epoch 102/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7305 - accuracy: 0.7503 - val_loss: 0.7761 - val_accuracy: 0.7544\n",
            "Epoch 103/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7333 - accuracy: 0.7467 - val_loss: 0.7893 - val_accuracy: 0.7602\n",
            "Epoch 104/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.7188 - accuracy: 0.7520 - val_loss: 0.7873 - val_accuracy: 0.7556\n",
            "Epoch 105/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7333 - accuracy: 0.7470 - val_loss: 0.7735 - val_accuracy: 0.7619\n",
            "Epoch 106/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7131 - accuracy: 0.7566 - val_loss: 0.7781 - val_accuracy: 0.7504\n",
            "Epoch 107/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7318 - accuracy: 0.7479 - val_loss: 0.7863 - val_accuracy: 0.7567\n",
            "Epoch 108/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7124 - accuracy: 0.7558 - val_loss: 0.7784 - val_accuracy: 0.7624\n",
            "Epoch 109/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7159 - accuracy: 0.7487 - val_loss: 0.7826 - val_accuracy: 0.7504\n",
            "Epoch 110/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7148 - accuracy: 0.7536 - val_loss: 0.7574 - val_accuracy: 0.7624\n",
            "Epoch 111/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7231 - accuracy: 0.7530 - val_loss: 0.7555 - val_accuracy: 0.7642\n",
            "Epoch 112/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6979 - accuracy: 0.7565 - val_loss: 0.7695 - val_accuracy: 0.7573\n",
            "Epoch 113/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7273 - accuracy: 0.7496 - val_loss: 0.7709 - val_accuracy: 0.7539\n",
            "Epoch 114/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7196 - accuracy: 0.7565 - val_loss: 0.7504 - val_accuracy: 0.7596\n",
            "Epoch 115/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7105 - accuracy: 0.7528 - val_loss: 0.7824 - val_accuracy: 0.7556\n",
            "Epoch 116/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7204 - accuracy: 0.7522 - val_loss: 0.7517 - val_accuracy: 0.7636\n",
            "Epoch 117/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7128 - accuracy: 0.7558 - val_loss: 0.7671 - val_accuracy: 0.7567\n",
            "Epoch 118/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7020 - accuracy: 0.7599 - val_loss: 0.7694 - val_accuracy: 0.7607\n",
            "Epoch 119/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7219 - accuracy: 0.7492 - val_loss: 0.7388 - val_accuracy: 0.7722\n",
            "Epoch 120/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7046 - accuracy: 0.7582 - val_loss: 0.7652 - val_accuracy: 0.7607\n",
            "Epoch 121/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7010 - accuracy: 0.7608 - val_loss: 0.7675 - val_accuracy: 0.7647\n",
            "Epoch 122/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7033 - accuracy: 0.7548 - val_loss: 0.7470 - val_accuracy: 0.7636\n",
            "Epoch 123/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6999 - accuracy: 0.7611 - val_loss: 0.7651 - val_accuracy: 0.7562\n",
            "Epoch 124/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6802 - accuracy: 0.7628 - val_loss: 0.7875 - val_accuracy: 0.7613\n",
            "Epoch 125/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6993 - accuracy: 0.7566 - val_loss: 0.7711 - val_accuracy: 0.7636\n",
            "Epoch 126/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7139 - accuracy: 0.7543 - val_loss: 0.7601 - val_accuracy: 0.7573\n",
            "Epoch 127/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6942 - accuracy: 0.7579 - val_loss: 0.7611 - val_accuracy: 0.7665\n",
            "Epoch 128/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7017 - accuracy: 0.7576 - val_loss: 0.7727 - val_accuracy: 0.7670\n",
            "Epoch 129/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.7654 - val_loss: 0.7645 - val_accuracy: 0.7624\n",
            "Epoch 130/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6784 - accuracy: 0.7676 - val_loss: 0.7659 - val_accuracy: 0.7665\n",
            "Epoch 131/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6907 - accuracy: 0.7648 - val_loss: 0.7753 - val_accuracy: 0.7579\n",
            "Epoch 132/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6950 - accuracy: 0.7668 - val_loss: 0.7821 - val_accuracy: 0.7642\n",
            "Epoch 133/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6706 - accuracy: 0.7665 - val_loss: 0.7850 - val_accuracy: 0.7659\n",
            "Epoch 134/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7072 - accuracy: 0.7536 - val_loss: 0.7406 - val_accuracy: 0.7665\n",
            "Epoch 135/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6887 - accuracy: 0.7585 - val_loss: 0.7558 - val_accuracy: 0.7693\n",
            "Epoch 136/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7021 - accuracy: 0.7548 - val_loss: 0.7755 - val_accuracy: 0.7607\n",
            "Epoch 137/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6818 - accuracy: 0.7626 - val_loss: 0.7735 - val_accuracy: 0.7716\n",
            "Epoch 138/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6635 - accuracy: 0.7709 - val_loss: 0.7654 - val_accuracy: 0.7653\n",
            "Epoch 139/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6803 - accuracy: 0.7589 - val_loss: 0.7657 - val_accuracy: 0.7659\n",
            "Epoch 140/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6574 - accuracy: 0.7748 - val_loss: 0.7680 - val_accuracy: 0.7676\n",
            "Epoch 141/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6836 - accuracy: 0.7656 - val_loss: 0.7699 - val_accuracy: 0.7642\n",
            "Epoch 142/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6744 - accuracy: 0.7688 - val_loss: 0.7594 - val_accuracy: 0.7619\n",
            "Epoch 143/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6604 - accuracy: 0.7729 - val_loss: 0.7552 - val_accuracy: 0.7676\n",
            "Epoch 144/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6630 - accuracy: 0.7727 - val_loss: 0.7730 - val_accuracy: 0.7642\n",
            "Epoch 145/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6593 - accuracy: 0.7662 - val_loss: 0.7788 - val_accuracy: 0.7710\n",
            "Epoch 146/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6569 - accuracy: 0.7715 - val_loss: 0.7647 - val_accuracy: 0.7710\n",
            "Epoch 147/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.7674 - val_loss: 0.7936 - val_accuracy: 0.7596\n",
            "Epoch 148/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6711 - accuracy: 0.7645 - val_loss: 0.8002 - val_accuracy: 0.7550\n",
            "Epoch 149/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6583 - accuracy: 0.7692 - val_loss: 0.7894 - val_accuracy: 0.7653\n",
            "Epoch 150/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6401 - accuracy: 0.7768 - val_loss: 0.7954 - val_accuracy: 0.7710\n",
            "Epoch 151/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.7768 - val_loss: 0.7814 - val_accuracy: 0.7624\n",
            "Epoch 152/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6493 - accuracy: 0.7795 - val_loss: 0.7774 - val_accuracy: 0.7676\n",
            "Epoch 153/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.7715 - val_loss: 0.7786 - val_accuracy: 0.7693\n",
            "Epoch 154/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6468 - accuracy: 0.7725 - val_loss: 0.7851 - val_accuracy: 0.7659\n",
            "Epoch 155/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6617 - accuracy: 0.7648 - val_loss: 0.7702 - val_accuracy: 0.7682\n",
            "Epoch 156/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6682 - accuracy: 0.7702 - val_loss: 0.7819 - val_accuracy: 0.7596\n",
            "Epoch 157/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6619 - accuracy: 0.7651 - val_loss: 0.7993 - val_accuracy: 0.7624\n",
            "Epoch 158/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6476 - accuracy: 0.7782 - val_loss: 0.7798 - val_accuracy: 0.7636\n",
            "Epoch 159/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6572 - accuracy: 0.7728 - val_loss: 0.7473 - val_accuracy: 0.7762\n",
            "Epoch 160/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.7830 - val_loss: 0.7554 - val_accuracy: 0.7710\n",
            "Epoch 161/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.7754 - val_loss: 0.7724 - val_accuracy: 0.7642\n",
            "Epoch 162/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.7708 - val_loss: 0.7910 - val_accuracy: 0.7619\n",
            "Epoch 163/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6331 - accuracy: 0.7825 - val_loss: 0.7812 - val_accuracy: 0.7670\n",
            "Epoch 164/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6419 - accuracy: 0.7754 - val_loss: 0.7613 - val_accuracy: 0.7710\n",
            "Epoch 165/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6376 - accuracy: 0.7805 - val_loss: 0.7656 - val_accuracy: 0.7619\n",
            "Epoch 166/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.7768 - val_loss: 0.7794 - val_accuracy: 0.7716\n",
            "Epoch 167/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6428 - accuracy: 0.7745 - val_loss: 0.7849 - val_accuracy: 0.7728\n",
            "Epoch 168/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.7718 - val_loss: 0.7702 - val_accuracy: 0.7693\n",
            "Epoch 169/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6301 - accuracy: 0.7797 - val_loss: 0.7676 - val_accuracy: 0.7647\n",
            "Epoch 170/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6353 - accuracy: 0.7844 - val_loss: 0.8040 - val_accuracy: 0.7647\n",
            "Epoch 171/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6357 - accuracy: 0.7814 - val_loss: 0.7737 - val_accuracy: 0.7676\n",
            "Epoch 172/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6437 - accuracy: 0.7678 - val_loss: 0.7959 - val_accuracy: 0.7728\n",
            "Epoch 173/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6403 - accuracy: 0.7725 - val_loss: 0.7537 - val_accuracy: 0.7699\n",
            "Epoch 174/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6329 - accuracy: 0.7774 - val_loss: 0.7844 - val_accuracy: 0.7665\n",
            "Epoch 175/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6534 - accuracy: 0.7719 - val_loss: 0.7586 - val_accuracy: 0.7790\n",
            "Epoch 176/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6479 - accuracy: 0.7689 - val_loss: 0.7833 - val_accuracy: 0.7647\n",
            "Epoch 177/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6115 - accuracy: 0.7843 - val_loss: 0.7777 - val_accuracy: 0.7710\n",
            "Epoch 178/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6315 - accuracy: 0.7765 - val_loss: 0.7787 - val_accuracy: 0.7756\n",
            "Epoch 179/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6308 - accuracy: 0.7851 - val_loss: 0.7636 - val_accuracy: 0.7705\n",
            "Epoch 180/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6110 - accuracy: 0.7881 - val_loss: 0.7957 - val_accuracy: 0.7642\n",
            "Epoch 181/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6232 - accuracy: 0.7807 - val_loss: 0.7891 - val_accuracy: 0.7665\n",
            "Epoch 182/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6071 - accuracy: 0.7870 - val_loss: 0.7663 - val_accuracy: 0.7762\n",
            "Epoch 183/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.7772 - val_loss: 0.7731 - val_accuracy: 0.7739\n",
            "Epoch 184/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6249 - accuracy: 0.7828 - val_loss: 0.7663 - val_accuracy: 0.7808\n",
            "Epoch 185/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6138 - accuracy: 0.7881 - val_loss: 0.7773 - val_accuracy: 0.7722\n",
            "Epoch 186/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.7795 - val_loss: 0.7528 - val_accuracy: 0.7665\n",
            "Epoch 187/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6250 - accuracy: 0.7818 - val_loss: 0.7769 - val_accuracy: 0.7813\n",
            "Epoch 188/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6197 - accuracy: 0.7854 - val_loss: 0.7714 - val_accuracy: 0.7790\n",
            "Epoch 189/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6094 - accuracy: 0.7864 - val_loss: 0.7664 - val_accuracy: 0.7705\n",
            "Epoch 190/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6164 - accuracy: 0.7830 - val_loss: 0.7617 - val_accuracy: 0.7705\n",
            "Epoch 191/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.6146 - accuracy: 0.7890 - val_loss: 0.7666 - val_accuracy: 0.7699\n",
            "Epoch 192/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.6220 - accuracy: 0.7815 - val_loss: 0.7751 - val_accuracy: 0.7745\n",
            "Epoch 193/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6155 - accuracy: 0.7848 - val_loss: 0.7813 - val_accuracy: 0.7750\n",
            "Epoch 194/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.6162 - accuracy: 0.7890 - val_loss: 0.7830 - val_accuracy: 0.7573\n",
            "Epoch 195/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.6131 - accuracy: 0.7847 - val_loss: 0.7750 - val_accuracy: 0.7653\n",
            "Epoch 196/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6004 - accuracy: 0.7913 - val_loss: 0.7722 - val_accuracy: 0.7733\n",
            "Epoch 197/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5998 - accuracy: 0.7964 - val_loss: 0.7828 - val_accuracy: 0.7739\n",
            "Epoch 198/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6133 - accuracy: 0.7858 - val_loss: 0.7864 - val_accuracy: 0.7739\n",
            "Epoch 199/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6123 - accuracy: 0.7901 - val_loss: 0.7659 - val_accuracy: 0.7710\n",
            "Epoch 200/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6152 - accuracy: 0.7848 - val_loss: 0.7789 - val_accuracy: 0.7716\n",
            "Epoch 201/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6197 - accuracy: 0.7815 - val_loss: 0.7940 - val_accuracy: 0.7762\n",
            "Epoch 202/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6177 - accuracy: 0.7824 - val_loss: 0.7655 - val_accuracy: 0.7785\n",
            "Epoch 203/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6028 - accuracy: 0.7920 - val_loss: 0.7834 - val_accuracy: 0.7785\n",
            "Epoch 204/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5857 - accuracy: 0.7947 - val_loss: 0.8098 - val_accuracy: 0.7699\n",
            "Epoch 205/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5903 - accuracy: 0.7923 - val_loss: 0.7931 - val_accuracy: 0.7722\n",
            "Epoch 206/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.7906 - val_loss: 0.7921 - val_accuracy: 0.7756\n",
            "Epoch 207/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5990 - accuracy: 0.7921 - val_loss: 0.7618 - val_accuracy: 0.7762\n",
            "Epoch 208/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5862 - accuracy: 0.7954 - val_loss: 0.7724 - val_accuracy: 0.7756\n",
            "Epoch 209/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6162 - accuracy: 0.7858 - val_loss: 0.7733 - val_accuracy: 0.7739\n",
            "Epoch 210/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6162 - accuracy: 0.7871 - val_loss: 0.7516 - val_accuracy: 0.7710\n",
            "Epoch 211/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.7917 - val_loss: 0.7683 - val_accuracy: 0.7790\n",
            "Epoch 212/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5952 - accuracy: 0.7961 - val_loss: 0.7696 - val_accuracy: 0.7762\n",
            "Epoch 213/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6230 - accuracy: 0.7805 - val_loss: 0.7863 - val_accuracy: 0.7687\n",
            "Epoch 214/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5864 - accuracy: 0.7950 - val_loss: 0.7629 - val_accuracy: 0.7762\n",
            "Epoch 215/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5932 - accuracy: 0.7971 - val_loss: 0.7732 - val_accuracy: 0.7836\n",
            "Epoch 216/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5972 - accuracy: 0.7887 - val_loss: 0.7713 - val_accuracy: 0.7733\n",
            "Epoch 217/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5909 - accuracy: 0.8000 - val_loss: 0.7742 - val_accuracy: 0.7710\n",
            "Epoch 218/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6010 - accuracy: 0.7923 - val_loss: 0.7892 - val_accuracy: 0.7728\n",
            "Epoch 219/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5810 - accuracy: 0.7946 - val_loss: 0.7861 - val_accuracy: 0.7682\n",
            "Epoch 220/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5987 - accuracy: 0.7927 - val_loss: 0.7781 - val_accuracy: 0.7722\n",
            "Epoch 221/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5882 - accuracy: 0.7996 - val_loss: 0.7784 - val_accuracy: 0.7768\n",
            "Epoch 222/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.7958 - val_loss: 0.7756 - val_accuracy: 0.7750\n",
            "Epoch 223/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5974 - accuracy: 0.7906 - val_loss: 0.7825 - val_accuracy: 0.7785\n",
            "Epoch 224/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5925 - accuracy: 0.7979 - val_loss: 0.7875 - val_accuracy: 0.7762\n",
            "Epoch 225/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5897 - accuracy: 0.7941 - val_loss: 0.7839 - val_accuracy: 0.7785\n",
            "Epoch 226/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5702 - accuracy: 0.8027 - val_loss: 0.8040 - val_accuracy: 0.7728\n",
            "Epoch 227/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6067 - accuracy: 0.7913 - val_loss: 0.7820 - val_accuracy: 0.7865\n",
            "Epoch 228/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5861 - accuracy: 0.7971 - val_loss: 0.7814 - val_accuracy: 0.7802\n",
            "Epoch 229/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5867 - accuracy: 0.7921 - val_loss: 0.7922 - val_accuracy: 0.7630\n",
            "Epoch 230/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5719 - accuracy: 0.8011 - val_loss: 0.7815 - val_accuracy: 0.7831\n",
            "Epoch 231/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5725 - accuracy: 0.8060 - val_loss: 0.7928 - val_accuracy: 0.7768\n",
            "Epoch 232/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.7964 - val_loss: 0.7930 - val_accuracy: 0.7670\n",
            "Epoch 233/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5711 - accuracy: 0.7951 - val_loss: 0.7852 - val_accuracy: 0.7768\n",
            "Epoch 234/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5720 - accuracy: 0.8003 - val_loss: 0.7871 - val_accuracy: 0.7722\n",
            "Epoch 235/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.8021 - val_loss: 0.7842 - val_accuracy: 0.7745\n",
            "Epoch 236/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5854 - accuracy: 0.7924 - val_loss: 0.7747 - val_accuracy: 0.7836\n",
            "Epoch 237/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6065 - accuracy: 0.7888 - val_loss: 0.7767 - val_accuracy: 0.7722\n",
            "Epoch 238/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5716 - accuracy: 0.8009 - val_loss: 0.8034 - val_accuracy: 0.7687\n",
            "Epoch 239/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5826 - accuracy: 0.7997 - val_loss: 0.7861 - val_accuracy: 0.7785\n",
            "Epoch 240/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5752 - accuracy: 0.7984 - val_loss: 0.7989 - val_accuracy: 0.7739\n",
            "Epoch 241/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.7994 - val_loss: 0.8051 - val_accuracy: 0.7733\n",
            "Epoch 242/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.8024 - val_loss: 0.7743 - val_accuracy: 0.7836\n",
            "Epoch 243/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.8020 - val_loss: 0.8113 - val_accuracy: 0.7808\n",
            "Epoch 244/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5667 - accuracy: 0.8043 - val_loss: 0.7863 - val_accuracy: 0.7762\n",
            "Epoch 245/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5744 - accuracy: 0.7953 - val_loss: 0.7883 - val_accuracy: 0.7785\n",
            "Epoch 246/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.7999 - val_loss: 0.7843 - val_accuracy: 0.7842\n",
            "Epoch 247/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5778 - accuracy: 0.7999 - val_loss: 0.7884 - val_accuracy: 0.7762\n",
            "Epoch 248/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5529 - accuracy: 0.8070 - val_loss: 0.7891 - val_accuracy: 0.7853\n",
            "Epoch 249/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5607 - accuracy: 0.8006 - val_loss: 0.7703 - val_accuracy: 0.7808\n",
            "Epoch 250/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5784 - accuracy: 0.7960 - val_loss: 0.7776 - val_accuracy: 0.7808\n",
            "Epoch 251/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5883 - accuracy: 0.7960 - val_loss: 0.7759 - val_accuracy: 0.7819\n",
            "Epoch 252/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.7956 - val_loss: 0.7906 - val_accuracy: 0.7756\n",
            "Epoch 253/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5803 - accuracy: 0.7931 - val_loss: 0.7794 - val_accuracy: 0.7848\n",
            "Epoch 254/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5714 - accuracy: 0.8000 - val_loss: 0.7834 - val_accuracy: 0.7802\n",
            "Epoch 255/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5558 - accuracy: 0.8009 - val_loss: 0.7795 - val_accuracy: 0.7710\n",
            "Epoch 256/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5543 - accuracy: 0.8059 - val_loss: 0.8041 - val_accuracy: 0.7722\n",
            "Epoch 257/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5607 - accuracy: 0.8049 - val_loss: 0.7802 - val_accuracy: 0.7802\n",
            "Epoch 258/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.8027 - val_loss: 0.8008 - val_accuracy: 0.7642\n",
            "Epoch 259/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5562 - accuracy: 0.8013 - val_loss: 0.7951 - val_accuracy: 0.7819\n",
            "Epoch 260/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5699 - accuracy: 0.7987 - val_loss: 0.8012 - val_accuracy: 0.7785\n",
            "Epoch 261/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.8125 - val_loss: 0.8056 - val_accuracy: 0.7768\n",
            "Epoch 262/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.8072 - val_loss: 0.8075 - val_accuracy: 0.7733\n",
            "Epoch 263/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5869 - accuracy: 0.7948 - val_loss: 0.7833 - val_accuracy: 0.7871\n",
            "Epoch 264/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5706 - accuracy: 0.8026 - val_loss: 0.7926 - val_accuracy: 0.7745\n",
            "Epoch 265/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5549 - accuracy: 0.8007 - val_loss: 0.7935 - val_accuracy: 0.7768\n",
            "Epoch 266/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5451 - accuracy: 0.8074 - val_loss: 0.7901 - val_accuracy: 0.7813\n",
            "Epoch 267/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5711 - accuracy: 0.7951 - val_loss: 0.7948 - val_accuracy: 0.7773\n",
            "Epoch 268/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5403 - accuracy: 0.8125 - val_loss: 0.8029 - val_accuracy: 0.7745\n",
            "Epoch 269/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.8145 - val_loss: 0.8007 - val_accuracy: 0.7808\n",
            "Epoch 270/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5566 - accuracy: 0.8053 - val_loss: 0.7904 - val_accuracy: 0.7831\n",
            "Epoch 271/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5544 - accuracy: 0.8050 - val_loss: 0.7809 - val_accuracy: 0.7773\n",
            "Epoch 272/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5598 - accuracy: 0.8007 - val_loss: 0.7893 - val_accuracy: 0.7871\n",
            "Epoch 273/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5737 - accuracy: 0.7976 - val_loss: 0.8042 - val_accuracy: 0.7790\n",
            "Epoch 274/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5505 - accuracy: 0.8047 - val_loss: 0.8101 - val_accuracy: 0.7762\n",
            "Epoch 275/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.8107 - val_loss: 0.8497 - val_accuracy: 0.7739\n",
            "Epoch 276/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.8004 - val_loss: 0.8187 - val_accuracy: 0.7768\n",
            "Epoch 277/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.8006 - val_loss: 0.8052 - val_accuracy: 0.7859\n",
            "Epoch 278/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5497 - accuracy: 0.8069 - val_loss: 0.7823 - val_accuracy: 0.7785\n",
            "Epoch 279/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5344 - accuracy: 0.8155 - val_loss: 0.8126 - val_accuracy: 0.7779\n",
            "Epoch 280/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.8093 - val_loss: 0.8121 - val_accuracy: 0.7796\n",
            "Epoch 281/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5550 - accuracy: 0.8105 - val_loss: 0.7935 - val_accuracy: 0.7894\n",
            "Epoch 282/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.8090 - val_loss: 0.8191 - val_accuracy: 0.7756\n",
            "Epoch 283/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5537 - accuracy: 0.8100 - val_loss: 0.8334 - val_accuracy: 0.7722\n",
            "Epoch 284/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5520 - accuracy: 0.8092 - val_loss: 0.8292 - val_accuracy: 0.7745\n",
            "Epoch 285/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5420 - accuracy: 0.8133 - val_loss: 0.7802 - val_accuracy: 0.7842\n",
            "Epoch 286/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5420 - accuracy: 0.8097 - val_loss: 0.8070 - val_accuracy: 0.7808\n",
            "Epoch 287/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5619 - accuracy: 0.8072 - val_loss: 0.7941 - val_accuracy: 0.7716\n",
            "Epoch 288/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.8100 - val_loss: 0.8015 - val_accuracy: 0.7876\n",
            "Epoch 289/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.8190 - val_loss: 0.8052 - val_accuracy: 0.7728\n",
            "Epoch 290/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.8112 - val_loss: 0.8479 - val_accuracy: 0.7728\n",
            "Epoch 291/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5592 - accuracy: 0.8066 - val_loss: 0.8351 - val_accuracy: 0.7699\n",
            "Epoch 292/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5320 - accuracy: 0.8140 - val_loss: 0.8354 - val_accuracy: 0.7762\n",
            "Epoch 293/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.8105 - val_loss: 0.7823 - val_accuracy: 0.7768\n",
            "Epoch 294/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5394 - accuracy: 0.8106 - val_loss: 0.7773 - val_accuracy: 0.7831\n",
            "Epoch 295/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5344 - accuracy: 0.8152 - val_loss: 0.8025 - val_accuracy: 0.7779\n",
            "Epoch 296/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.8020 - val_loss: 0.7790 - val_accuracy: 0.7733\n",
            "Epoch 297/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5366 - accuracy: 0.8070 - val_loss: 0.7830 - val_accuracy: 0.7853\n",
            "Epoch 298/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.8170 - val_loss: 0.8107 - val_accuracy: 0.7779\n",
            "Epoch 299/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5533 - accuracy: 0.8001 - val_loss: 0.8047 - val_accuracy: 0.7796\n",
            "Epoch 300/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.8077 - val_loss: 0.8033 - val_accuracy: 0.7768\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe81c5a6590>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "grid search yapmaya calistik fakat basarisiz sonuclandi\n",
        "\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32,64]))\n",
        "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
        "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
        "HP_kernel_size = hp.HParam('kernel_size', hp.Discrete([2, 3, 4]))\n",
        "HP_filters = hp.HParam('filters', hp.Discrete([16, 32, 64]))\n",
        "\n",
        "METRIC_ACCURACY = 'accuracy'\n",
        "\n",
        "hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER,HP_kernel_size,HP_filters]\n",
        "metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')]\n",
        "'''"
      ],
      "metadata": {
        "id": "y8Wx_JStnc_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv1D(32,3, activation ='relu', input_shape= (20, 1)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(48))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl-MRphrmZW4",
        "outputId": "2671dcd5-4bd9-46fe-8ff1-22fea9e3fad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_10 (Conv1D)          (None, 18, 32)            128       \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 64)                36928     \n",
            "                                                                 \n",
            " activation_28 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 48)                3120      \n",
            "                                                                 \n",
            " activation_29 (Activation)  (None, 48)                0         \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 48)                0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 64)                3136      \n",
            "                                                                 \n",
            " activation_30 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            " activation_31 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45,722\n",
            "Trainable params: 45,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"SGD\",loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Q2IBgOO0k8ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 300\n",
        "num_batch_size = 64\n",
        "\n",
        "model.fit(\n",
        "          x_train, \n",
        "          y_train, \n",
        "          batch_size=num_batch_size, \n",
        "          epochs=num_epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "         )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHUFZdPRnzn2",
        "outputId": "8cd5730c-f564-4105-e62e-0eae98b1da34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 2.2866 - accuracy: 0.1236 - val_loss: 2.2695 - val_accuracy: 0.2009\n",
            "Epoch 2/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.2645 - accuracy: 0.1384 - val_loss: 2.2499 - val_accuracy: 0.1626\n",
            "Epoch 3/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 2.2507 - accuracy: 0.1529 - val_loss: 2.2348 - val_accuracy: 0.1883\n",
            "Epoch 4/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.2381 - accuracy: 0.1676 - val_loss: 2.2184 - val_accuracy: 0.2106\n",
            "Epoch 5/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.2221 - accuracy: 0.1762 - val_loss: 2.1964 - val_accuracy: 0.2181\n",
            "Epoch 6/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.1981 - accuracy: 0.1930 - val_loss: 2.1640 - val_accuracy: 0.2215\n",
            "Epoch 7/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.1658 - accuracy: 0.2126 - val_loss: 2.1235 - val_accuracy: 0.2335\n",
            "Epoch 8/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.1291 - accuracy: 0.2196 - val_loss: 2.0798 - val_accuracy: 0.2536\n",
            "Epoch 9/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.0952 - accuracy: 0.2273 - val_loss: 2.0362 - val_accuracy: 0.2622\n",
            "Epoch 10/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.0574 - accuracy: 0.2262 - val_loss: 2.0012 - val_accuracy: 0.2707\n",
            "Epoch 11/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.0251 - accuracy: 0.2427 - val_loss: 1.9790 - val_accuracy: 0.2530\n",
            "Epoch 12/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.0035 - accuracy: 0.2366 - val_loss: 1.9503 - val_accuracy: 0.2582\n",
            "Epoch 13/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.9846 - accuracy: 0.2628 - val_loss: 1.9308 - val_accuracy: 0.2690\n",
            "Epoch 14/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.9706 - accuracy: 0.2482 - val_loss: 1.9204 - val_accuracy: 0.2748\n",
            "Epoch 15/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.9585 - accuracy: 0.2565 - val_loss: 1.9032 - val_accuracy: 0.2770\n",
            "Epoch 16/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.9531 - accuracy: 0.2603 - val_loss: 1.8952 - val_accuracy: 0.2885\n",
            "Epoch 17/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.9392 - accuracy: 0.2689 - val_loss: 1.8770 - val_accuracy: 0.2914\n",
            "Epoch 18/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.9215 - accuracy: 0.2762 - val_loss: 1.8716 - val_accuracy: 0.2919\n",
            "Epoch 19/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.9171 - accuracy: 0.2733 - val_loss: 1.8793 - val_accuracy: 0.2942\n",
            "Epoch 20/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.9075 - accuracy: 0.2729 - val_loss: 1.8499 - val_accuracy: 0.3045\n",
            "Epoch 21/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8931 - accuracy: 0.2809 - val_loss: 1.8359 - val_accuracy: 0.3068\n",
            "Epoch 22/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8928 - accuracy: 0.2911 - val_loss: 1.8259 - val_accuracy: 0.3143\n",
            "Epoch 23/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8684 - accuracy: 0.3014 - val_loss: 1.8719 - val_accuracy: 0.2851\n",
            "Epoch 24/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8694 - accuracy: 0.2923 - val_loss: 1.8810 - val_accuracy: 0.2851\n",
            "Epoch 25/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8667 - accuracy: 0.2985 - val_loss: 1.7910 - val_accuracy: 0.3228\n",
            "Epoch 26/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8608 - accuracy: 0.2979 - val_loss: 1.8035 - val_accuracy: 0.3165\n",
            "Epoch 27/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8478 - accuracy: 0.3079 - val_loss: 1.7888 - val_accuracy: 0.3217\n",
            "Epoch 28/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8513 - accuracy: 0.2996 - val_loss: 1.8346 - val_accuracy: 0.3154\n",
            "Epoch 29/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.8383 - accuracy: 0.3065 - val_loss: 1.7697 - val_accuracy: 0.3320\n",
            "Epoch 30/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8373 - accuracy: 0.3152 - val_loss: 1.7760 - val_accuracy: 0.3251\n",
            "Epoch 31/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8248 - accuracy: 0.3048 - val_loss: 1.7513 - val_accuracy: 0.3371\n",
            "Epoch 32/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8228 - accuracy: 0.3131 - val_loss: 1.8682 - val_accuracy: 0.2856\n",
            "Epoch 33/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8033 - accuracy: 0.3164 - val_loss: 1.7422 - val_accuracy: 0.3480\n",
            "Epoch 34/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8114 - accuracy: 0.3147 - val_loss: 1.7537 - val_accuracy: 0.3360\n",
            "Epoch 35/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7961 - accuracy: 0.3190 - val_loss: 1.7240 - val_accuracy: 0.3560\n",
            "Epoch 36/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7966 - accuracy: 0.3236 - val_loss: 1.7245 - val_accuracy: 0.3589\n",
            "Epoch 37/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.7906 - accuracy: 0.3321 - val_loss: 1.7290 - val_accuracy: 0.3503\n",
            "Epoch 38/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.7910 - accuracy: 0.3230 - val_loss: 1.7023 - val_accuracy: 0.3635\n",
            "Epoch 39/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7798 - accuracy: 0.3417 - val_loss: 1.7054 - val_accuracy: 0.3715\n",
            "Epoch 40/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7822 - accuracy: 0.3290 - val_loss: 1.7065 - val_accuracy: 0.3520\n",
            "Epoch 41/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7727 - accuracy: 0.3390 - val_loss: 1.7003 - val_accuracy: 0.3732\n",
            "Epoch 42/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7770 - accuracy: 0.3372 - val_loss: 1.6856 - val_accuracy: 0.3641\n",
            "Epoch 43/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7571 - accuracy: 0.3409 - val_loss: 1.6765 - val_accuracy: 0.3772\n",
            "Epoch 44/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7616 - accuracy: 0.3412 - val_loss: 1.6681 - val_accuracy: 0.3766\n",
            "Epoch 45/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7586 - accuracy: 0.3602 - val_loss: 1.6626 - val_accuracy: 0.3869\n",
            "Epoch 46/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7470 - accuracy: 0.3515 - val_loss: 1.6635 - val_accuracy: 0.3772\n",
            "Epoch 47/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7384 - accuracy: 0.3645 - val_loss: 1.6531 - val_accuracy: 0.4053\n",
            "Epoch 48/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7325 - accuracy: 0.3611 - val_loss: 1.6625 - val_accuracy: 0.3835\n",
            "Epoch 49/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7286 - accuracy: 0.3556 - val_loss: 1.6348 - val_accuracy: 0.4093\n",
            "Epoch 50/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7281 - accuracy: 0.3668 - val_loss: 1.6537 - val_accuracy: 0.3990\n",
            "Epoch 51/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7138 - accuracy: 0.3719 - val_loss: 1.6234 - val_accuracy: 0.4047\n",
            "Epoch 52/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7142 - accuracy: 0.3684 - val_loss: 1.6209 - val_accuracy: 0.4018\n",
            "Epoch 53/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.7142 - accuracy: 0.3661 - val_loss: 1.6261 - val_accuracy: 0.3904\n",
            "Epoch 54/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6959 - accuracy: 0.3781 - val_loss: 1.6224 - val_accuracy: 0.4041\n",
            "Epoch 55/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6850 - accuracy: 0.3778 - val_loss: 1.5869 - val_accuracy: 0.4367\n",
            "Epoch 56/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6874 - accuracy: 0.3778 - val_loss: 1.5863 - val_accuracy: 0.4190\n",
            "Epoch 57/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6912 - accuracy: 0.3797 - val_loss: 1.5754 - val_accuracy: 0.4425\n",
            "Epoch 58/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.6674 - accuracy: 0.3827 - val_loss: 1.5606 - val_accuracy: 0.4425\n",
            "Epoch 59/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6706 - accuracy: 0.3893 - val_loss: 1.6045 - val_accuracy: 0.4305\n",
            "Epoch 60/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6679 - accuracy: 0.3966 - val_loss: 1.5637 - val_accuracy: 0.4345\n",
            "Epoch 61/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6595 - accuracy: 0.3950 - val_loss: 1.5456 - val_accuracy: 0.4471\n",
            "Epoch 62/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6535 - accuracy: 0.4043 - val_loss: 1.5489 - val_accuracy: 0.4356\n",
            "Epoch 63/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6449 - accuracy: 0.3913 - val_loss: 1.5692 - val_accuracy: 0.4173\n",
            "Epoch 64/300\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 1.6448 - accuracy: 0.4004 - val_loss: 1.5362 - val_accuracy: 0.4528\n",
            "Epoch 65/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.6476 - accuracy: 0.3958 - val_loss: 1.5407 - val_accuracy: 0.4408\n",
            "Epoch 66/300\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 1.6461 - accuracy: 0.3984 - val_loss: 1.5266 - val_accuracy: 0.4596\n",
            "Epoch 67/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6247 - accuracy: 0.4132 - val_loss: 1.5394 - val_accuracy: 0.4390\n",
            "Epoch 68/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6362 - accuracy: 0.4092 - val_loss: 1.5378 - val_accuracy: 0.4511\n",
            "Epoch 69/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6229 - accuracy: 0.4116 - val_loss: 1.5633 - val_accuracy: 0.4408\n",
            "Epoch 70/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.6199 - accuracy: 0.4139 - val_loss: 1.5075 - val_accuracy: 0.4602\n",
            "Epoch 71/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6201 - accuracy: 0.4054 - val_loss: 1.5032 - val_accuracy: 0.4671\n",
            "Epoch 72/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6067 - accuracy: 0.4132 - val_loss: 1.5754 - val_accuracy: 0.4396\n",
            "Epoch 73/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6065 - accuracy: 0.4145 - val_loss: 1.5105 - val_accuracy: 0.4551\n",
            "Epoch 74/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6081 - accuracy: 0.4216 - val_loss: 1.4953 - val_accuracy: 0.4745\n",
            "Epoch 75/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6047 - accuracy: 0.4198 - val_loss: 1.4966 - val_accuracy: 0.4648\n",
            "Epoch 76/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5999 - accuracy: 0.4239 - val_loss: 1.4916 - val_accuracy: 0.4482\n",
            "Epoch 77/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5804 - accuracy: 0.4285 - val_loss: 1.4641 - val_accuracy: 0.4808\n",
            "Epoch 78/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5833 - accuracy: 0.4273 - val_loss: 1.4756 - val_accuracy: 0.4625\n",
            "Epoch 79/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5771 - accuracy: 0.4271 - val_loss: 1.4591 - val_accuracy: 0.4814\n",
            "Epoch 80/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5699 - accuracy: 0.4299 - val_loss: 1.5057 - val_accuracy: 0.4677\n",
            "Epoch 81/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5769 - accuracy: 0.4311 - val_loss: 1.4587 - val_accuracy: 0.4865\n",
            "Epoch 82/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5642 - accuracy: 0.4412 - val_loss: 1.4438 - val_accuracy: 0.4911\n",
            "Epoch 83/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5542 - accuracy: 0.4385 - val_loss: 1.4790 - val_accuracy: 0.4762\n",
            "Epoch 84/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5526 - accuracy: 0.4414 - val_loss: 1.4593 - val_accuracy: 0.4803\n",
            "Epoch 85/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5524 - accuracy: 0.4346 - val_loss: 1.4352 - val_accuracy: 0.4940\n",
            "Epoch 86/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5467 - accuracy: 0.4404 - val_loss: 1.4502 - val_accuracy: 0.4974\n",
            "Epoch 87/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5450 - accuracy: 0.4471 - val_loss: 1.4422 - val_accuracy: 0.4906\n",
            "Epoch 88/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.5369 - accuracy: 0.4521 - val_loss: 1.4421 - val_accuracy: 0.4848\n",
            "Epoch 89/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5218 - accuracy: 0.4507 - val_loss: 1.4293 - val_accuracy: 0.4980\n",
            "Epoch 90/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5376 - accuracy: 0.4435 - val_loss: 1.4307 - val_accuracy: 0.4928\n",
            "Epoch 91/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5327 - accuracy: 0.4527 - val_loss: 1.4277 - val_accuracy: 0.5020\n",
            "Epoch 92/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5259 - accuracy: 0.4472 - val_loss: 1.4351 - val_accuracy: 0.4883\n",
            "Epoch 93/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5290 - accuracy: 0.4444 - val_loss: 1.4287 - val_accuracy: 0.4951\n",
            "Epoch 94/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5253 - accuracy: 0.4527 - val_loss: 1.4382 - val_accuracy: 0.4768\n",
            "Epoch 95/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5189 - accuracy: 0.4573 - val_loss: 1.3974 - val_accuracy: 0.5152\n",
            "Epoch 96/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5034 - accuracy: 0.4578 - val_loss: 1.4044 - val_accuracy: 0.5135\n",
            "Epoch 97/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5058 - accuracy: 0.4563 - val_loss: 1.3986 - val_accuracy: 0.5060\n",
            "Epoch 98/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4977 - accuracy: 0.4686 - val_loss: 1.4083 - val_accuracy: 0.5112\n",
            "Epoch 99/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.4986 - accuracy: 0.4667 - val_loss: 1.4047 - val_accuracy: 0.4991\n",
            "Epoch 100/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4995 - accuracy: 0.4667 - val_loss: 1.4233 - val_accuracy: 0.5043\n",
            "Epoch 101/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4954 - accuracy: 0.4696 - val_loss: 1.3910 - val_accuracy: 0.5175\n",
            "Epoch 102/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4856 - accuracy: 0.4775 - val_loss: 1.3801 - val_accuracy: 0.5186\n",
            "Epoch 103/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4805 - accuracy: 0.4669 - val_loss: 1.3917 - val_accuracy: 0.5043\n",
            "Epoch 104/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4758 - accuracy: 0.4759 - val_loss: 1.4032 - val_accuracy: 0.5152\n",
            "Epoch 105/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.4860 - accuracy: 0.4683 - val_loss: 1.3780 - val_accuracy: 0.5112\n",
            "Epoch 106/300\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 1.4734 - accuracy: 0.4736 - val_loss: 1.3701 - val_accuracy: 0.5215\n",
            "Epoch 107/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4669 - accuracy: 0.4752 - val_loss: 1.3838 - val_accuracy: 0.5169\n",
            "Epoch 108/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4651 - accuracy: 0.4823 - val_loss: 1.3842 - val_accuracy: 0.5203\n",
            "Epoch 109/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4748 - accuracy: 0.4734 - val_loss: 1.4245 - val_accuracy: 0.5020\n",
            "Epoch 110/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4538 - accuracy: 0.4827 - val_loss: 1.3913 - val_accuracy: 0.5089\n",
            "Epoch 111/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4606 - accuracy: 0.4803 - val_loss: 1.3419 - val_accuracy: 0.5323\n",
            "Epoch 112/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.4606 - accuracy: 0.4806 - val_loss: 1.3377 - val_accuracy: 0.5386\n",
            "Epoch 113/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4490 - accuracy: 0.4822 - val_loss: 1.3441 - val_accuracy: 0.5386\n",
            "Epoch 114/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4457 - accuracy: 0.4865 - val_loss: 1.3326 - val_accuracy: 0.5461\n",
            "Epoch 115/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4404 - accuracy: 0.4888 - val_loss: 1.3508 - val_accuracy: 0.5346\n",
            "Epoch 116/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.4498 - accuracy: 0.4868 - val_loss: 1.3316 - val_accuracy: 0.5398\n",
            "Epoch 117/300\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 1.4272 - accuracy: 0.4928 - val_loss: 1.3232 - val_accuracy: 0.5507\n",
            "Epoch 118/300\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 1.4219 - accuracy: 0.4948 - val_loss: 1.3279 - val_accuracy: 0.5467\n",
            "Epoch 119/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4346 - accuracy: 0.4846 - val_loss: 1.3218 - val_accuracy: 0.5461\n",
            "Epoch 120/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4204 - accuracy: 0.4922 - val_loss: 1.4024 - val_accuracy: 0.5106\n",
            "Epoch 121/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4093 - accuracy: 0.5052 - val_loss: 1.3070 - val_accuracy: 0.5467\n",
            "Epoch 122/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4085 - accuracy: 0.5079 - val_loss: 1.3056 - val_accuracy: 0.5604\n",
            "Epoch 123/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4150 - accuracy: 0.5002 - val_loss: 1.3159 - val_accuracy: 0.5432\n",
            "Epoch 124/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4135 - accuracy: 0.5014 - val_loss: 1.3154 - val_accuracy: 0.5524\n",
            "Epoch 125/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4142 - accuracy: 0.5014 - val_loss: 1.3093 - val_accuracy: 0.5432\n",
            "Epoch 126/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4057 - accuracy: 0.4959 - val_loss: 1.3102 - val_accuracy: 0.5335\n",
            "Epoch 127/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4079 - accuracy: 0.5039 - val_loss: 1.3045 - val_accuracy: 0.5581\n",
            "Epoch 128/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4021 - accuracy: 0.4988 - val_loss: 1.2730 - val_accuracy: 0.5758\n",
            "Epoch 129/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3973 - accuracy: 0.5044 - val_loss: 1.2913 - val_accuracy: 0.5552\n",
            "Epoch 130/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3975 - accuracy: 0.5072 - val_loss: 1.2892 - val_accuracy: 0.5695\n",
            "Epoch 131/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3893 - accuracy: 0.5055 - val_loss: 1.3112 - val_accuracy: 0.5484\n",
            "Epoch 132/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3905 - accuracy: 0.5120 - val_loss: 1.3172 - val_accuracy: 0.5570\n",
            "Epoch 133/300\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 1.3769 - accuracy: 0.5069 - val_loss: 1.2817 - val_accuracy: 0.5633\n",
            "Epoch 134/300\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 1.3683 - accuracy: 0.5231 - val_loss: 1.2756 - val_accuracy: 0.5547\n",
            "Epoch 135/300\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 1.3693 - accuracy: 0.5142 - val_loss: 1.2448 - val_accuracy: 0.5827\n",
            "Epoch 136/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3722 - accuracy: 0.5147 - val_loss: 1.2952 - val_accuracy: 0.5707\n",
            "Epoch 137/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3620 - accuracy: 0.5180 - val_loss: 1.2537 - val_accuracy: 0.5787\n",
            "Epoch 138/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3508 - accuracy: 0.5220 - val_loss: 1.3041 - val_accuracy: 0.5570\n",
            "Epoch 139/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3569 - accuracy: 0.5251 - val_loss: 1.2422 - val_accuracy: 0.5799\n",
            "Epoch 140/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3527 - accuracy: 0.5264 - val_loss: 1.2636 - val_accuracy: 0.5690\n",
            "Epoch 141/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3552 - accuracy: 0.5228 - val_loss: 1.2347 - val_accuracy: 0.5730\n",
            "Epoch 142/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3378 - accuracy: 0.5341 - val_loss: 1.2500 - val_accuracy: 0.5724\n",
            "Epoch 143/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 1.3362 - accuracy: 0.5309 - val_loss: 1.3158 - val_accuracy: 0.5489\n",
            "Epoch 144/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 1.3469 - accuracy: 0.5351 - val_loss: 1.3027 - val_accuracy: 0.5535\n",
            "Epoch 145/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 1.3308 - accuracy: 0.5311 - val_loss: 1.2241 - val_accuracy: 0.5867\n",
            "Epoch 146/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 1.3315 - accuracy: 0.5349 - val_loss: 1.2611 - val_accuracy: 0.5644\n",
            "Epoch 147/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 1.3308 - accuracy: 0.5288 - val_loss: 1.3003 - val_accuracy: 0.5678\n",
            "Epoch 148/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3249 - accuracy: 0.5324 - val_loss: 1.2326 - val_accuracy: 0.5770\n",
            "Epoch 149/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3189 - accuracy: 0.5379 - val_loss: 1.2662 - val_accuracy: 0.5484\n",
            "Epoch 150/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3235 - accuracy: 0.5346 - val_loss: 1.2099 - val_accuracy: 0.6016\n",
            "Epoch 151/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3176 - accuracy: 0.5397 - val_loss: 1.2302 - val_accuracy: 0.5810\n",
            "Epoch 152/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3050 - accuracy: 0.5469 - val_loss: 1.4658 - val_accuracy: 0.5209\n",
            "Epoch 153/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2988 - accuracy: 0.5440 - val_loss: 1.1966 - val_accuracy: 0.6005\n",
            "Epoch 154/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2956 - accuracy: 0.5450 - val_loss: 1.2237 - val_accuracy: 0.5804\n",
            "Epoch 155/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 1.3015 - accuracy: 0.5476 - val_loss: 1.2061 - val_accuracy: 0.5976\n",
            "Epoch 156/300\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 1.3014 - accuracy: 0.5410 - val_loss: 1.2115 - val_accuracy: 0.5947\n",
            "Epoch 157/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2989 - accuracy: 0.5495 - val_loss: 1.2004 - val_accuracy: 0.5965\n",
            "Epoch 158/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2857 - accuracy: 0.5495 - val_loss: 1.1978 - val_accuracy: 0.5833\n",
            "Epoch 159/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2838 - accuracy: 0.5549 - val_loss: 1.1748 - val_accuracy: 0.6062\n",
            "Epoch 160/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2790 - accuracy: 0.5583 - val_loss: 1.2324 - val_accuracy: 0.5896\n",
            "Epoch 161/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2789 - accuracy: 0.5497 - val_loss: 1.1752 - val_accuracy: 0.5953\n",
            "Epoch 162/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 1.2824 - accuracy: 0.5536 - val_loss: 1.1610 - val_accuracy: 0.6182\n",
            "Epoch 163/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 1.2687 - accuracy: 0.5659 - val_loss: 1.1754 - val_accuracy: 0.5953\n",
            "Epoch 164/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 1.2739 - accuracy: 0.5576 - val_loss: 1.2602 - val_accuracy: 0.5776\n",
            "Epoch 165/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.2627 - accuracy: 0.5635 - val_loss: 1.1624 - val_accuracy: 0.6136\n",
            "Epoch 166/300\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 1.2659 - accuracy: 0.5556 - val_loss: 1.1907 - val_accuracy: 0.6022\n",
            "Epoch 167/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2581 - accuracy: 0.5669 - val_loss: 1.1703 - val_accuracy: 0.6148\n",
            "Epoch 168/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 1.2658 - accuracy: 0.5688 - val_loss: 1.1845 - val_accuracy: 0.6010\n",
            "Epoch 169/300\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 1.2495 - accuracy: 0.5646 - val_loss: 1.1547 - val_accuracy: 0.6108\n",
            "Epoch 170/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.2433 - accuracy: 0.5722 - val_loss: 1.1652 - val_accuracy: 0.6205\n",
            "Epoch 171/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2570 - accuracy: 0.5589 - val_loss: 1.1738 - val_accuracy: 0.6119\n",
            "Epoch 172/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2364 - accuracy: 0.5758 - val_loss: 1.1376 - val_accuracy: 0.6331\n",
            "Epoch 173/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2326 - accuracy: 0.5775 - val_loss: 1.1827 - val_accuracy: 0.6068\n",
            "Epoch 174/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2411 - accuracy: 0.5719 - val_loss: 1.2099 - val_accuracy: 0.6073\n",
            "Epoch 175/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2386 - accuracy: 0.5748 - val_loss: 1.1878 - val_accuracy: 0.6068\n",
            "Epoch 176/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2292 - accuracy: 0.5788 - val_loss: 1.1334 - val_accuracy: 0.6228\n",
            "Epoch 177/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2208 - accuracy: 0.5702 - val_loss: 1.1312 - val_accuracy: 0.6337\n",
            "Epoch 178/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2209 - accuracy: 0.5778 - val_loss: 1.2965 - val_accuracy: 0.5718\n",
            "Epoch 179/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2247 - accuracy: 0.5764 - val_loss: 1.1225 - val_accuracy: 0.6234\n",
            "Epoch 180/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2231 - accuracy: 0.5770 - val_loss: 1.3308 - val_accuracy: 0.5541\n",
            "Epoch 181/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.2172 - accuracy: 0.5805 - val_loss: 1.1246 - val_accuracy: 0.6256\n",
            "Epoch 182/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.2098 - accuracy: 0.5822 - val_loss: 1.1985 - val_accuracy: 0.5959\n",
            "Epoch 183/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2182 - accuracy: 0.5800 - val_loss: 1.1345 - val_accuracy: 0.6239\n",
            "Epoch 184/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1978 - accuracy: 0.5840 - val_loss: 1.1305 - val_accuracy: 0.6165\n",
            "Epoch 185/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1907 - accuracy: 0.5906 - val_loss: 1.0985 - val_accuracy: 0.6543\n",
            "Epoch 186/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1922 - accuracy: 0.5880 - val_loss: 1.0932 - val_accuracy: 0.6451\n",
            "Epoch 187/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1892 - accuracy: 0.5917 - val_loss: 1.1058 - val_accuracy: 0.6337\n",
            "Epoch 188/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2039 - accuracy: 0.5875 - val_loss: 1.1777 - val_accuracy: 0.6102\n",
            "Epoch 189/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1940 - accuracy: 0.5875 - val_loss: 1.1097 - val_accuracy: 0.6400\n",
            "Epoch 190/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1802 - accuracy: 0.5900 - val_loss: 1.1040 - val_accuracy: 0.6342\n",
            "Epoch 191/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1869 - accuracy: 0.5924 - val_loss: 1.0985 - val_accuracy: 0.6451\n",
            "Epoch 192/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1608 - accuracy: 0.5997 - val_loss: 1.1100 - val_accuracy: 0.6428\n",
            "Epoch 193/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1722 - accuracy: 0.5984 - val_loss: 1.0853 - val_accuracy: 0.6508\n",
            "Epoch 194/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1583 - accuracy: 0.6074 - val_loss: 1.0825 - val_accuracy: 0.6480\n",
            "Epoch 195/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1672 - accuracy: 0.5999 - val_loss: 1.0759 - val_accuracy: 0.6531\n",
            "Epoch 196/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1719 - accuracy: 0.6021 - val_loss: 1.1065 - val_accuracy: 0.6445\n",
            "Epoch 197/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1536 - accuracy: 0.6064 - val_loss: 1.1052 - val_accuracy: 0.6388\n",
            "Epoch 198/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1547 - accuracy: 0.6021 - val_loss: 1.1279 - val_accuracy: 0.6302\n",
            "Epoch 199/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1498 - accuracy: 0.6026 - val_loss: 1.0614 - val_accuracy: 0.6680\n",
            "Epoch 200/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1371 - accuracy: 0.6109 - val_loss: 1.1160 - val_accuracy: 0.6234\n",
            "Epoch 201/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1643 - accuracy: 0.6029 - val_loss: 1.1491 - val_accuracy: 0.6239\n",
            "Epoch 202/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1444 - accuracy: 0.6092 - val_loss: 1.1232 - val_accuracy: 0.6388\n",
            "Epoch 203/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1471 - accuracy: 0.6102 - val_loss: 1.2045 - val_accuracy: 0.5976\n",
            "Epoch 204/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1552 - accuracy: 0.6082 - val_loss: 1.1366 - val_accuracy: 0.6188\n",
            "Epoch 205/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1407 - accuracy: 0.6113 - val_loss: 1.0734 - val_accuracy: 0.6600\n",
            "Epoch 206/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1390 - accuracy: 0.6069 - val_loss: 1.0500 - val_accuracy: 0.6594\n",
            "Epoch 207/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1318 - accuracy: 0.6172 - val_loss: 1.0621 - val_accuracy: 0.6520\n",
            "Epoch 208/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1171 - accuracy: 0.6115 - val_loss: 1.0604 - val_accuracy: 0.6497\n",
            "Epoch 209/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1238 - accuracy: 0.6157 - val_loss: 1.1073 - val_accuracy: 0.6474\n",
            "Epoch 210/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1291 - accuracy: 0.6265 - val_loss: 1.1239 - val_accuracy: 0.6394\n",
            "Epoch 211/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1214 - accuracy: 0.6193 - val_loss: 1.0973 - val_accuracy: 0.6474\n",
            "Epoch 212/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1231 - accuracy: 0.6096 - val_loss: 1.1689 - val_accuracy: 0.6096\n",
            "Epoch 213/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1143 - accuracy: 0.6210 - val_loss: 1.0768 - val_accuracy: 0.6617\n",
            "Epoch 214/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1089 - accuracy: 0.6233 - val_loss: 1.1037 - val_accuracy: 0.6445\n",
            "Epoch 215/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1098 - accuracy: 0.6196 - val_loss: 1.0430 - val_accuracy: 0.6617\n",
            "Epoch 216/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0874 - accuracy: 0.6299 - val_loss: 1.0443 - val_accuracy: 0.6646\n",
            "Epoch 217/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1127 - accuracy: 0.6220 - val_loss: 1.0757 - val_accuracy: 0.6348\n",
            "Epoch 218/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1047 - accuracy: 0.6285 - val_loss: 1.1004 - val_accuracy: 0.6480\n",
            "Epoch 219/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0946 - accuracy: 0.6288 - val_loss: 1.0474 - val_accuracy: 0.6640\n",
            "Epoch 220/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1043 - accuracy: 0.6229 - val_loss: 1.0925 - val_accuracy: 0.6485\n",
            "Epoch 221/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0868 - accuracy: 0.6315 - val_loss: 1.0739 - val_accuracy: 0.6520\n",
            "Epoch 222/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0874 - accuracy: 0.6358 - val_loss: 1.0127 - val_accuracy: 0.6743\n",
            "Epoch 223/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0907 - accuracy: 0.6312 - val_loss: 1.1412 - val_accuracy: 0.6268\n",
            "Epoch 224/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0908 - accuracy: 0.6281 - val_loss: 1.0303 - val_accuracy: 0.6760\n",
            "Epoch 225/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0828 - accuracy: 0.6374 - val_loss: 1.0365 - val_accuracy: 0.6732\n",
            "Epoch 226/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0700 - accuracy: 0.6306 - val_loss: 1.0481 - val_accuracy: 0.6583\n",
            "Epoch 227/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0787 - accuracy: 0.6359 - val_loss: 1.0257 - val_accuracy: 0.6737\n",
            "Epoch 228/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0594 - accuracy: 0.6388 - val_loss: 1.0206 - val_accuracy: 0.6754\n",
            "Epoch 229/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0646 - accuracy: 0.6352 - val_loss: 1.0937 - val_accuracy: 0.6451\n",
            "Epoch 230/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.0634 - accuracy: 0.6346 - val_loss: 1.0307 - val_accuracy: 0.6697\n",
            "Epoch 231/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0748 - accuracy: 0.6304 - val_loss: 1.0141 - val_accuracy: 0.6726\n",
            "Epoch 232/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0659 - accuracy: 0.6395 - val_loss: 1.0129 - val_accuracy: 0.6646\n",
            "Epoch 233/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.0661 - accuracy: 0.6398 - val_loss: 1.0354 - val_accuracy: 0.6766\n",
            "Epoch 234/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0535 - accuracy: 0.6389 - val_loss: 1.0510 - val_accuracy: 0.6594\n",
            "Epoch 235/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0653 - accuracy: 0.6299 - val_loss: 1.0139 - val_accuracy: 0.6823\n",
            "Epoch 236/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0468 - accuracy: 0.6411 - val_loss: 1.0821 - val_accuracy: 0.6514\n",
            "Epoch 237/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0452 - accuracy: 0.6382 - val_loss: 1.0885 - val_accuracy: 0.6422\n",
            "Epoch 238/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0519 - accuracy: 0.6429 - val_loss: 1.0141 - val_accuracy: 0.6915\n",
            "Epoch 239/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0513 - accuracy: 0.6460 - val_loss: 1.0174 - val_accuracy: 0.6669\n",
            "Epoch 240/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.0360 - accuracy: 0.6492 - val_loss: 1.0328 - val_accuracy: 0.6571\n",
            "Epoch 241/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0451 - accuracy: 0.6460 - val_loss: 1.0086 - val_accuracy: 0.6749\n",
            "Epoch 242/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.0292 - accuracy: 0.6520 - val_loss: 1.0025 - val_accuracy: 0.6754\n",
            "Epoch 243/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0355 - accuracy: 0.6407 - val_loss: 1.0113 - val_accuracy: 0.6835\n",
            "Epoch 244/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.0480 - accuracy: 0.6394 - val_loss: 1.0241 - val_accuracy: 0.6709\n",
            "Epoch 245/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0406 - accuracy: 0.6491 - val_loss: 0.9910 - val_accuracy: 0.6840\n",
            "Epoch 246/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0309 - accuracy: 0.6422 - val_loss: 0.9886 - val_accuracy: 0.6800\n",
            "Epoch 247/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0283 - accuracy: 0.6497 - val_loss: 1.1295 - val_accuracy: 0.6337\n",
            "Epoch 248/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0356 - accuracy: 0.6497 - val_loss: 1.0960 - val_accuracy: 0.6697\n",
            "Epoch 249/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0239 - accuracy: 0.6574 - val_loss: 0.9780 - val_accuracy: 0.6875\n",
            "Epoch 250/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0261 - accuracy: 0.6511 - val_loss: 1.0161 - val_accuracy: 0.6789\n",
            "Epoch 251/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0145 - accuracy: 0.6604 - val_loss: 0.9959 - val_accuracy: 0.6835\n",
            "Epoch 252/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0084 - accuracy: 0.6607 - val_loss: 1.0278 - val_accuracy: 0.6697\n",
            "Epoch 253/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0195 - accuracy: 0.6538 - val_loss: 1.0004 - val_accuracy: 0.6840\n",
            "Epoch 254/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0181 - accuracy: 0.6610 - val_loss: 0.9790 - val_accuracy: 0.6949\n",
            "Epoch 255/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0117 - accuracy: 0.6586 - val_loss: 1.0281 - val_accuracy: 0.6697\n",
            "Epoch 256/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9942 - accuracy: 0.6669 - val_loss: 0.9661 - val_accuracy: 0.6943\n",
            "Epoch 257/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0149 - accuracy: 0.6594 - val_loss: 1.0685 - val_accuracy: 0.6629\n",
            "Epoch 258/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0263 - accuracy: 0.6534 - val_loss: 1.0065 - val_accuracy: 0.6714\n",
            "Epoch 259/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0058 - accuracy: 0.6593 - val_loss: 0.9794 - val_accuracy: 0.6932\n",
            "Epoch 260/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9970 - accuracy: 0.6584 - val_loss: 0.9913 - val_accuracy: 0.6972\n",
            "Epoch 261/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0007 - accuracy: 0.6650 - val_loss: 0.9683 - val_accuracy: 0.6915\n",
            "Epoch 262/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0199 - accuracy: 0.6584 - val_loss: 1.0131 - val_accuracy: 0.6720\n",
            "Epoch 263/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9803 - accuracy: 0.6641 - val_loss: 0.9661 - val_accuracy: 0.6903\n",
            "Epoch 264/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9962 - accuracy: 0.6606 - val_loss: 1.0252 - val_accuracy: 0.6691\n",
            "Epoch 265/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9877 - accuracy: 0.6654 - val_loss: 1.0224 - val_accuracy: 0.6754\n",
            "Epoch 266/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9857 - accuracy: 0.6666 - val_loss: 1.0670 - val_accuracy: 0.6371\n",
            "Epoch 267/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9954 - accuracy: 0.6618 - val_loss: 0.9774 - val_accuracy: 0.6880\n",
            "Epoch 268/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9972 - accuracy: 0.6598 - val_loss: 1.3386 - val_accuracy: 0.5999\n",
            "Epoch 269/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9991 - accuracy: 0.6573 - val_loss: 1.0147 - val_accuracy: 0.6800\n",
            "Epoch 270/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9787 - accuracy: 0.6717 - val_loss: 0.9936 - val_accuracy: 0.6915\n",
            "Epoch 271/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9851 - accuracy: 0.6710 - val_loss: 0.9467 - val_accuracy: 0.7064\n",
            "Epoch 272/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9804 - accuracy: 0.6673 - val_loss: 0.9625 - val_accuracy: 0.7041\n",
            "Epoch 273/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9743 - accuracy: 0.6667 - val_loss: 0.9848 - val_accuracy: 0.6955\n",
            "Epoch 274/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9579 - accuracy: 0.6842 - val_loss: 0.9392 - val_accuracy: 0.7104\n",
            "Epoch 275/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9666 - accuracy: 0.6653 - val_loss: 0.9548 - val_accuracy: 0.7046\n",
            "Epoch 276/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9779 - accuracy: 0.6702 - val_loss: 0.9664 - val_accuracy: 0.6978\n",
            "Epoch 277/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9683 - accuracy: 0.6767 - val_loss: 0.9543 - val_accuracy: 0.7018\n",
            "Epoch 278/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9629 - accuracy: 0.6759 - val_loss: 0.9576 - val_accuracy: 0.7115\n",
            "Epoch 279/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9587 - accuracy: 0.6699 - val_loss: 0.9901 - val_accuracy: 0.6955\n",
            "Epoch 280/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9666 - accuracy: 0.6719 - val_loss: 0.9619 - val_accuracy: 0.6995\n",
            "Epoch 281/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9682 - accuracy: 0.6740 - val_loss: 0.9601 - val_accuracy: 0.6915\n",
            "Epoch 282/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9668 - accuracy: 0.6744 - val_loss: 0.9572 - val_accuracy: 0.6995\n",
            "Epoch 283/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9575 - accuracy: 0.6747 - val_loss: 0.9424 - val_accuracy: 0.7023\n",
            "Epoch 284/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9504 - accuracy: 0.6800 - val_loss: 0.9700 - val_accuracy: 0.6932\n",
            "Epoch 285/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.9595 - accuracy: 0.6789 - val_loss: 0.9344 - val_accuracy: 0.7109\n",
            "Epoch 286/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9549 - accuracy: 0.6710 - val_loss: 0.9455 - val_accuracy: 0.7064\n",
            "Epoch 287/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9475 - accuracy: 0.6825 - val_loss: 0.9823 - val_accuracy: 0.6903\n",
            "Epoch 288/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9478 - accuracy: 0.6823 - val_loss: 0.9477 - val_accuracy: 0.7018\n",
            "Epoch 289/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9570 - accuracy: 0.6766 - val_loss: 0.9508 - val_accuracy: 0.7046\n",
            "Epoch 290/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9427 - accuracy: 0.6901 - val_loss: 0.9409 - val_accuracy: 0.7029\n",
            "Epoch 291/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9506 - accuracy: 0.6769 - val_loss: 0.9655 - val_accuracy: 0.7058\n",
            "Epoch 292/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9409 - accuracy: 0.6852 - val_loss: 0.9559 - val_accuracy: 0.6938\n",
            "Epoch 293/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9348 - accuracy: 0.6846 - val_loss: 0.9413 - val_accuracy: 0.7081\n",
            "Epoch 294/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9370 - accuracy: 0.6809 - val_loss: 0.9384 - val_accuracy: 0.7058\n",
            "Epoch 295/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9252 - accuracy: 0.6817 - val_loss: 0.9708 - val_accuracy: 0.6898\n",
            "Epoch 296/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.9296 - accuracy: 0.6839 - val_loss: 0.9479 - val_accuracy: 0.7001\n",
            "Epoch 297/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9349 - accuracy: 0.6826 - val_loss: 0.9458 - val_accuracy: 0.7018\n",
            "Epoch 298/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9134 - accuracy: 0.6956 - val_loss: 0.9200 - val_accuracy: 0.7218\n",
            "Epoch 299/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9201 - accuracy: 0.6848 - val_loss: 0.9572 - val_accuracy: 0.6920\n",
            "Epoch 300/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9210 - accuracy: 0.6870 - val_loss: 1.1145 - val_accuracy: 0.6525\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe81c306ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv1D(32,3, activation ='relu', input_shape= (20, 1)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(48))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPd44Dlqk8sK",
        "outputId": "60f7a1a2-8d02-4597-80f5-7a98214a880e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_11 (Conv1D)          (None, 18, 32)            128       \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 64)                36928     \n",
            "                                                                 \n",
            " activation_32 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 48)                3120      \n",
            "                                                                 \n",
            " activation_33 (Activation)  (None, 48)                0         \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 48)                0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 64)                3136      \n",
            "                                                                 \n",
            " activation_34 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            " activation_35 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45,722\n",
            "Trainable params: 45,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"Adam\",loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YUwkPqk8k8us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 300\n",
        "num_batch_size = 64\n",
        "\n",
        "model.fit(\n",
        "          x_train, \n",
        "          y_train, \n",
        "          batch_size=num_batch_size, \n",
        "          epochs=num_epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "         )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eQf-n6Bk8x-",
        "outputId": "91c75713-7382-46eb-9633-c5f570b2caeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 2.1646 - accuracy: 0.1768 - val_loss: 1.9067 - val_accuracy: 0.2902\n",
            "Epoch 2/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8795 - accuracy: 0.2966 - val_loss: 1.7036 - val_accuracy: 0.3910\n",
            "Epoch 3/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7240 - accuracy: 0.3602 - val_loss: 1.5790 - val_accuracy: 0.4339\n",
            "Epoch 4/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6467 - accuracy: 0.4052 - val_loss: 1.5355 - val_accuracy: 0.4574\n",
            "Epoch 5/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.6097 - accuracy: 0.4133 - val_loss: 1.4630 - val_accuracy: 0.4917\n",
            "Epoch 6/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5488 - accuracy: 0.4411 - val_loss: 1.4308 - val_accuracy: 0.4997\n",
            "Epoch 7/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5094 - accuracy: 0.4606 - val_loss: 1.4001 - val_accuracy: 0.5117\n",
            "Epoch 8/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4640 - accuracy: 0.4840 - val_loss: 1.3536 - val_accuracy: 0.5358\n",
            "Epoch 9/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4455 - accuracy: 0.4971 - val_loss: 1.3310 - val_accuracy: 0.5529\n",
            "Epoch 10/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4015 - accuracy: 0.5045 - val_loss: 1.3339 - val_accuracy: 0.5472\n",
            "Epoch 11/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3706 - accuracy: 0.5205 - val_loss: 1.2744 - val_accuracy: 0.5816\n",
            "Epoch 12/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3281 - accuracy: 0.5372 - val_loss: 1.2332 - val_accuracy: 0.5884\n",
            "Epoch 13/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2992 - accuracy: 0.5493 - val_loss: 1.2060 - val_accuracy: 0.6085\n",
            "Epoch 14/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2738 - accuracy: 0.5559 - val_loss: 1.1861 - val_accuracy: 0.6039\n",
            "Epoch 15/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2279 - accuracy: 0.5721 - val_loss: 1.1663 - val_accuracy: 0.6085\n",
            "Epoch 16/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2130 - accuracy: 0.5844 - val_loss: 1.1282 - val_accuracy: 0.6234\n",
            "Epoch 17/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1898 - accuracy: 0.5923 - val_loss: 1.1054 - val_accuracy: 0.6211\n",
            "Epoch 18/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1802 - accuracy: 0.5953 - val_loss: 1.0799 - val_accuracy: 0.6422\n",
            "Epoch 19/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1566 - accuracy: 0.6070 - val_loss: 1.0799 - val_accuracy: 0.6405\n",
            "Epoch 20/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1280 - accuracy: 0.6152 - val_loss: 1.0573 - val_accuracy: 0.6468\n",
            "Epoch 21/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1015 - accuracy: 0.6163 - val_loss: 1.0425 - val_accuracy: 0.6508\n",
            "Epoch 22/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0917 - accuracy: 0.6205 - val_loss: 1.0222 - val_accuracy: 0.6691\n",
            "Epoch 23/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0710 - accuracy: 0.6292 - val_loss: 1.0126 - val_accuracy: 0.6640\n",
            "Epoch 24/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0643 - accuracy: 0.6377 - val_loss: 1.0065 - val_accuracy: 0.6726\n",
            "Epoch 25/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0391 - accuracy: 0.6427 - val_loss: 1.0013 - val_accuracy: 0.6812\n",
            "Epoch 26/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0478 - accuracy: 0.6432 - val_loss: 1.0291 - val_accuracy: 0.6606\n",
            "Epoch 27/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0111 - accuracy: 0.6583 - val_loss: 0.9811 - val_accuracy: 0.6772\n",
            "Epoch 28/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0052 - accuracy: 0.6511 - val_loss: 0.9787 - val_accuracy: 0.6800\n",
            "Epoch 29/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.9789 - accuracy: 0.6623 - val_loss: 0.9646 - val_accuracy: 0.6829\n",
            "Epoch 30/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9711 - accuracy: 0.6617 - val_loss: 0.9615 - val_accuracy: 0.6898\n",
            "Epoch 31/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9651 - accuracy: 0.6649 - val_loss: 0.9743 - val_accuracy: 0.7018\n",
            "Epoch 32/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9558 - accuracy: 0.6752 - val_loss: 0.9458 - val_accuracy: 0.7029\n",
            "Epoch 33/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9630 - accuracy: 0.6779 - val_loss: 0.9263 - val_accuracy: 0.7035\n",
            "Epoch 34/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9299 - accuracy: 0.6812 - val_loss: 0.9359 - val_accuracy: 0.6938\n",
            "Epoch 35/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9203 - accuracy: 0.6820 - val_loss: 0.9341 - val_accuracy: 0.7006\n",
            "Epoch 36/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9222 - accuracy: 0.6822 - val_loss: 0.9422 - val_accuracy: 0.6926\n",
            "Epoch 37/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9149 - accuracy: 0.6835 - val_loss: 0.9374 - val_accuracy: 0.7115\n",
            "Epoch 38/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9184 - accuracy: 0.6876 - val_loss: 0.9319 - val_accuracy: 0.7012\n",
            "Epoch 39/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8981 - accuracy: 0.6925 - val_loss: 0.9108 - val_accuracy: 0.7207\n",
            "Epoch 40/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8793 - accuracy: 0.6955 - val_loss: 0.9195 - val_accuracy: 0.7132\n",
            "Epoch 41/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8738 - accuracy: 0.6966 - val_loss: 0.9065 - val_accuracy: 0.7178\n",
            "Epoch 42/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8735 - accuracy: 0.7008 - val_loss: 0.9249 - val_accuracy: 0.7132\n",
            "Epoch 43/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8752 - accuracy: 0.6992 - val_loss: 0.9416 - val_accuracy: 0.7127\n",
            "Epoch 44/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8432 - accuracy: 0.7077 - val_loss: 0.9098 - val_accuracy: 0.7195\n",
            "Epoch 45/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8480 - accuracy: 0.7098 - val_loss: 0.9106 - val_accuracy: 0.7207\n",
            "Epoch 46/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.8700 - accuracy: 0.7058 - val_loss: 0.9149 - val_accuracy: 0.7247\n",
            "Epoch 47/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8316 - accuracy: 0.7177 - val_loss: 0.9007 - val_accuracy: 0.7270\n",
            "Epoch 48/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8406 - accuracy: 0.7127 - val_loss: 0.8972 - val_accuracy: 0.7230\n",
            "Epoch 49/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8342 - accuracy: 0.7165 - val_loss: 0.8969 - val_accuracy: 0.7281\n",
            "Epoch 50/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8170 - accuracy: 0.7184 - val_loss: 0.8874 - val_accuracy: 0.7367\n",
            "Epoch 51/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8036 - accuracy: 0.7231 - val_loss: 0.8979 - val_accuracy: 0.7218\n",
            "Epoch 52/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8063 - accuracy: 0.7254 - val_loss: 0.8773 - val_accuracy: 0.7344\n",
            "Epoch 53/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8175 - accuracy: 0.7238 - val_loss: 0.8773 - val_accuracy: 0.7321\n",
            "Epoch 54/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8048 - accuracy: 0.7264 - val_loss: 0.8868 - val_accuracy: 0.7350\n",
            "Epoch 55/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7956 - accuracy: 0.7264 - val_loss: 0.9025 - val_accuracy: 0.7367\n",
            "Epoch 56/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8003 - accuracy: 0.7300 - val_loss: 0.8773 - val_accuracy: 0.7327\n",
            "Epoch 57/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8021 - accuracy: 0.7268 - val_loss: 0.8818 - val_accuracy: 0.7396\n",
            "Epoch 58/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7789 - accuracy: 0.7346 - val_loss: 0.8810 - val_accuracy: 0.7396\n",
            "Epoch 59/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7940 - accuracy: 0.7287 - val_loss: 0.8648 - val_accuracy: 0.7413\n",
            "Epoch 60/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7853 - accuracy: 0.7349 - val_loss: 0.8582 - val_accuracy: 0.7470\n",
            "Epoch 61/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7802 - accuracy: 0.7357 - val_loss: 0.8939 - val_accuracy: 0.7378\n",
            "Epoch 62/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7615 - accuracy: 0.7436 - val_loss: 0.8631 - val_accuracy: 0.7476\n",
            "Epoch 63/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7646 - accuracy: 0.7406 - val_loss: 0.8990 - val_accuracy: 0.7344\n",
            "Epoch 64/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7556 - accuracy: 0.7390 - val_loss: 0.8606 - val_accuracy: 0.7390\n",
            "Epoch 65/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7644 - accuracy: 0.7396 - val_loss: 0.8614 - val_accuracy: 0.7441\n",
            "Epoch 66/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7395 - accuracy: 0.7492 - val_loss: 0.8584 - val_accuracy: 0.7453\n",
            "Epoch 67/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7540 - accuracy: 0.7490 - val_loss: 0.8457 - val_accuracy: 0.7470\n",
            "Epoch 68/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7501 - accuracy: 0.7465 - val_loss: 0.8537 - val_accuracy: 0.7487\n",
            "Epoch 69/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7329 - accuracy: 0.7492 - val_loss: 0.8428 - val_accuracy: 0.7447\n",
            "Epoch 70/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7533 - accuracy: 0.7447 - val_loss: 0.8713 - val_accuracy: 0.7430\n",
            "Epoch 71/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7445 - accuracy: 0.7499 - val_loss: 0.8464 - val_accuracy: 0.7516\n",
            "Epoch 72/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7252 - accuracy: 0.7518 - val_loss: 0.8668 - val_accuracy: 0.7310\n",
            "Epoch 73/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7287 - accuracy: 0.7483 - val_loss: 0.8347 - val_accuracy: 0.7470\n",
            "Epoch 74/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7344 - accuracy: 0.7522 - val_loss: 0.8460 - val_accuracy: 0.7499\n",
            "Epoch 75/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7358 - accuracy: 0.7520 - val_loss: 0.8494 - val_accuracy: 0.7430\n",
            "Epoch 76/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7120 - accuracy: 0.7555 - val_loss: 0.8560 - val_accuracy: 0.7481\n",
            "Epoch 77/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7204 - accuracy: 0.7616 - val_loss: 0.8473 - val_accuracy: 0.7447\n",
            "Epoch 78/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7160 - accuracy: 0.7569 - val_loss: 0.8704 - val_accuracy: 0.7487\n",
            "Epoch 79/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7011 - accuracy: 0.7586 - val_loss: 0.8727 - val_accuracy: 0.7430\n",
            "Epoch 80/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7107 - accuracy: 0.7543 - val_loss: 0.8483 - val_accuracy: 0.7441\n",
            "Epoch 81/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7058 - accuracy: 0.7599 - val_loss: 0.8766 - val_accuracy: 0.7396\n",
            "Epoch 82/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7156 - accuracy: 0.7555 - val_loss: 0.8457 - val_accuracy: 0.7539\n",
            "Epoch 83/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.7055 - accuracy: 0.7549 - val_loss: 0.8472 - val_accuracy: 0.7579\n",
            "Epoch 84/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6999 - accuracy: 0.7652 - val_loss: 0.8497 - val_accuracy: 0.7401\n",
            "Epoch 85/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6853 - accuracy: 0.7606 - val_loss: 0.8644 - val_accuracy: 0.7487\n",
            "Epoch 86/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7148 - accuracy: 0.7538 - val_loss: 0.8411 - val_accuracy: 0.7476\n",
            "Epoch 87/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6896 - accuracy: 0.7668 - val_loss: 0.8531 - val_accuracy: 0.7539\n",
            "Epoch 88/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6973 - accuracy: 0.7646 - val_loss: 0.8510 - val_accuracy: 0.7464\n",
            "Epoch 89/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.7628 - val_loss: 0.8475 - val_accuracy: 0.7470\n",
            "Epoch 90/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6739 - accuracy: 0.7722 - val_loss: 0.8539 - val_accuracy: 0.7516\n",
            "Epoch 91/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6843 - accuracy: 0.7612 - val_loss: 0.8397 - val_accuracy: 0.7573\n",
            "Epoch 92/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6810 - accuracy: 0.7678 - val_loss: 0.8475 - val_accuracy: 0.7470\n",
            "Epoch 93/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.7661 - val_loss: 0.8500 - val_accuracy: 0.7447\n",
            "Epoch 94/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6628 - accuracy: 0.7778 - val_loss: 0.8998 - val_accuracy: 0.7424\n",
            "Epoch 95/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6447 - accuracy: 0.7767 - val_loss: 0.8712 - val_accuracy: 0.7533\n",
            "Epoch 96/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.7744 - val_loss: 0.8422 - val_accuracy: 0.7499\n",
            "Epoch 97/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6477 - accuracy: 0.7844 - val_loss: 0.8623 - val_accuracy: 0.7481\n",
            "Epoch 98/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6798 - accuracy: 0.7748 - val_loss: 0.8399 - val_accuracy: 0.7607\n",
            "Epoch 99/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6664 - accuracy: 0.7744 - val_loss: 0.8291 - val_accuracy: 0.7579\n",
            "Epoch 100/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.7744 - val_loss: 0.8699 - val_accuracy: 0.7459\n",
            "Epoch 101/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6631 - accuracy: 0.7808 - val_loss: 0.8552 - val_accuracy: 0.7476\n",
            "Epoch 102/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6361 - accuracy: 0.7808 - val_loss: 0.8420 - val_accuracy: 0.7607\n",
            "Epoch 103/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.7777 - val_loss: 0.8708 - val_accuracy: 0.7567\n",
            "Epoch 104/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6647 - accuracy: 0.7748 - val_loss: 0.8513 - val_accuracy: 0.7556\n",
            "Epoch 105/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6681 - accuracy: 0.7745 - val_loss: 0.8715 - val_accuracy: 0.7584\n",
            "Epoch 106/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.7817 - val_loss: 0.8536 - val_accuracy: 0.7544\n",
            "Epoch 107/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6383 - accuracy: 0.7864 - val_loss: 0.8550 - val_accuracy: 0.7624\n",
            "Epoch 108/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6300 - accuracy: 0.7878 - val_loss: 0.8708 - val_accuracy: 0.7550\n",
            "Epoch 109/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6456 - accuracy: 0.7781 - val_loss: 0.8798 - val_accuracy: 0.7453\n",
            "Epoch 110/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6252 - accuracy: 0.7893 - val_loss: 0.8707 - val_accuracy: 0.7533\n",
            "Epoch 111/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6253 - accuracy: 0.7877 - val_loss: 0.8274 - val_accuracy: 0.7630\n",
            "Epoch 112/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6337 - accuracy: 0.7821 - val_loss: 0.8486 - val_accuracy: 0.7493\n",
            "Epoch 113/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6209 - accuracy: 0.7900 - val_loss: 0.8482 - val_accuracy: 0.7544\n",
            "Epoch 114/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6403 - accuracy: 0.7858 - val_loss: 0.8564 - val_accuracy: 0.7499\n",
            "Epoch 115/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.7863 - val_loss: 0.8527 - val_accuracy: 0.7562\n",
            "Epoch 116/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6307 - accuracy: 0.7853 - val_loss: 0.8747 - val_accuracy: 0.7493\n",
            "Epoch 117/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6218 - accuracy: 0.7847 - val_loss: 0.8534 - val_accuracy: 0.7584\n",
            "Epoch 118/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6160 - accuracy: 0.7864 - val_loss: 0.8708 - val_accuracy: 0.7613\n",
            "Epoch 119/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6093 - accuracy: 0.7904 - val_loss: 0.8657 - val_accuracy: 0.7584\n",
            "Epoch 120/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6111 - accuracy: 0.7898 - val_loss: 0.8684 - val_accuracy: 0.7573\n",
            "Epoch 121/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6110 - accuracy: 0.7924 - val_loss: 0.8667 - val_accuracy: 0.7533\n",
            "Epoch 122/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.7868 - val_loss: 0.8513 - val_accuracy: 0.7659\n",
            "Epoch 123/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6067 - accuracy: 0.7957 - val_loss: 0.8632 - val_accuracy: 0.7573\n",
            "Epoch 124/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6162 - accuracy: 0.7908 - val_loss: 0.8746 - val_accuracy: 0.7562\n",
            "Epoch 125/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5812 - accuracy: 0.8027 - val_loss: 0.8426 - val_accuracy: 0.7665\n",
            "Epoch 126/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6090 - accuracy: 0.7911 - val_loss: 0.8638 - val_accuracy: 0.7550\n",
            "Epoch 127/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6037 - accuracy: 0.7973 - val_loss: 0.8693 - val_accuracy: 0.7504\n",
            "Epoch 128/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6031 - accuracy: 0.7954 - val_loss: 0.8474 - val_accuracy: 0.7630\n",
            "Epoch 129/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6007 - accuracy: 0.7986 - val_loss: 0.8656 - val_accuracy: 0.7499\n",
            "Epoch 130/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.8010 - val_loss: 0.8729 - val_accuracy: 0.7550\n",
            "Epoch 131/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5919 - accuracy: 0.8014 - val_loss: 0.8386 - val_accuracy: 0.7624\n",
            "Epoch 132/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6025 - accuracy: 0.7971 - val_loss: 0.8595 - val_accuracy: 0.7619\n",
            "Epoch 133/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6016 - accuracy: 0.7951 - val_loss: 0.8892 - val_accuracy: 0.7579\n",
            "Epoch 134/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5900 - accuracy: 0.8004 - val_loss: 0.8446 - val_accuracy: 0.7642\n",
            "Epoch 135/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6035 - accuracy: 0.7984 - val_loss: 0.8575 - val_accuracy: 0.7613\n",
            "Epoch 136/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6049 - accuracy: 0.7940 - val_loss: 0.8791 - val_accuracy: 0.7453\n",
            "Epoch 137/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5899 - accuracy: 0.7986 - val_loss: 0.8675 - val_accuracy: 0.7602\n",
            "Epoch 138/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5642 - accuracy: 0.8066 - val_loss: 0.8608 - val_accuracy: 0.7613\n",
            "Epoch 139/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.8026 - val_loss: 0.8732 - val_accuracy: 0.7619\n",
            "Epoch 140/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.8043 - val_loss: 0.8522 - val_accuracy: 0.7636\n",
            "Epoch 141/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5871 - accuracy: 0.8013 - val_loss: 0.8807 - val_accuracy: 0.7567\n",
            "Epoch 142/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5818 - accuracy: 0.8050 - val_loss: 0.8613 - val_accuracy: 0.7504\n",
            "Epoch 143/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5823 - accuracy: 0.8027 - val_loss: 0.8830 - val_accuracy: 0.7533\n",
            "Epoch 144/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5864 - accuracy: 0.8072 - val_loss: 0.8343 - val_accuracy: 0.7642\n",
            "Epoch 145/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.8046 - val_loss: 0.8626 - val_accuracy: 0.7510\n",
            "Epoch 146/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.8067 - val_loss: 0.8863 - val_accuracy: 0.7602\n",
            "Epoch 147/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5801 - accuracy: 0.8130 - val_loss: 0.8569 - val_accuracy: 0.7624\n",
            "Epoch 148/300\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.5775 - accuracy: 0.8046 - val_loss: 0.8560 - val_accuracy: 0.7705\n",
            "Epoch 149/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5698 - accuracy: 0.8036 - val_loss: 0.8897 - val_accuracy: 0.7636\n",
            "Epoch 150/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.7960 - val_loss: 0.8576 - val_accuracy: 0.7676\n",
            "Epoch 151/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5797 - accuracy: 0.8020 - val_loss: 0.8638 - val_accuracy: 0.7670\n",
            "Epoch 152/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5575 - accuracy: 0.8099 - val_loss: 0.8873 - val_accuracy: 0.7630\n",
            "Epoch 153/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.5729 - accuracy: 0.8033 - val_loss: 0.8730 - val_accuracy: 0.7602\n",
            "Epoch 154/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.5524 - accuracy: 0.8109 - val_loss: 0.8599 - val_accuracy: 0.7584\n",
            "Epoch 155/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.5605 - accuracy: 0.8083 - val_loss: 0.8684 - val_accuracy: 0.7619\n",
            "Epoch 156/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.5639 - accuracy: 0.8103 - val_loss: 0.8915 - val_accuracy: 0.7642\n",
            "Epoch 157/300\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.5528 - accuracy: 0.8135 - val_loss: 0.8513 - val_accuracy: 0.7590\n",
            "Epoch 158/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5468 - accuracy: 0.8112 - val_loss: 0.8718 - val_accuracy: 0.7579\n",
            "Epoch 159/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.8113 - val_loss: 0.8651 - val_accuracy: 0.7590\n",
            "Epoch 160/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.8142 - val_loss: 0.9169 - val_accuracy: 0.7579\n",
            "Epoch 161/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5711 - accuracy: 0.8102 - val_loss: 0.8838 - val_accuracy: 0.7624\n",
            "Epoch 162/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5583 - accuracy: 0.8153 - val_loss: 0.9061 - val_accuracy: 0.7556\n",
            "Epoch 163/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.8152 - val_loss: 0.8574 - val_accuracy: 0.7665\n",
            "Epoch 164/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.8110 - val_loss: 0.8724 - val_accuracy: 0.7699\n",
            "Epoch 165/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.8168 - val_loss: 0.8686 - val_accuracy: 0.7602\n",
            "Epoch 166/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5611 - accuracy: 0.8097 - val_loss: 0.8905 - val_accuracy: 0.7624\n",
            "Epoch 167/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.8109 - val_loss: 0.8915 - val_accuracy: 0.7642\n",
            "Epoch 168/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.8202 - val_loss: 0.9328 - val_accuracy: 0.7573\n",
            "Epoch 169/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.8162 - val_loss: 0.8647 - val_accuracy: 0.7665\n",
            "Epoch 170/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.8146 - val_loss: 0.9014 - val_accuracy: 0.7602\n",
            "Epoch 171/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.8135 - val_loss: 0.8936 - val_accuracy: 0.7676\n",
            "Epoch 172/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.8127 - val_loss: 0.8961 - val_accuracy: 0.7579\n",
            "Epoch 173/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.8163 - val_loss: 0.8970 - val_accuracy: 0.7647\n",
            "Epoch 174/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5366 - accuracy: 0.8179 - val_loss: 0.8708 - val_accuracy: 0.7670\n",
            "Epoch 175/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5520 - accuracy: 0.8130 - val_loss: 0.8937 - val_accuracy: 0.7630\n",
            "Epoch 176/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.8241 - val_loss: 0.9132 - val_accuracy: 0.7624\n",
            "Epoch 177/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.8173 - val_loss: 0.9048 - val_accuracy: 0.7693\n",
            "Epoch 178/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.8159 - val_loss: 0.8959 - val_accuracy: 0.7624\n",
            "Epoch 179/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.8226 - val_loss: 0.8788 - val_accuracy: 0.7624\n",
            "Epoch 180/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.8099 - val_loss: 0.8624 - val_accuracy: 0.7579\n",
            "Epoch 181/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.8232 - val_loss: 0.9067 - val_accuracy: 0.7533\n",
            "Epoch 182/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.8253 - val_loss: 0.8811 - val_accuracy: 0.7670\n",
            "Epoch 183/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.8220 - val_loss: 0.9035 - val_accuracy: 0.7630\n",
            "Epoch 184/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.8198 - val_loss: 0.9453 - val_accuracy: 0.7527\n",
            "Epoch 185/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.8249 - val_loss: 0.9250 - val_accuracy: 0.7624\n",
            "Epoch 186/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.8195 - val_loss: 0.9125 - val_accuracy: 0.7539\n",
            "Epoch 187/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.8275 - val_loss: 0.8938 - val_accuracy: 0.7556\n",
            "Epoch 188/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.8296 - val_loss: 0.9198 - val_accuracy: 0.7510\n",
            "Epoch 189/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.8268 - val_loss: 0.9082 - val_accuracy: 0.7636\n",
            "Epoch 190/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.8228 - val_loss: 0.9299 - val_accuracy: 0.7584\n",
            "Epoch 191/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.8208 - val_loss: 0.9122 - val_accuracy: 0.7562\n",
            "Epoch 192/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.8285 - val_loss: 0.8875 - val_accuracy: 0.7665\n",
            "Epoch 193/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.8196 - val_loss: 0.9120 - val_accuracy: 0.7607\n",
            "Epoch 194/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.8222 - val_loss: 0.9299 - val_accuracy: 0.7470\n",
            "Epoch 195/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.8243 - val_loss: 0.8996 - val_accuracy: 0.7550\n",
            "Epoch 196/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.8269 - val_loss: 0.8976 - val_accuracy: 0.7550\n",
            "Epoch 197/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.8242 - val_loss: 0.8840 - val_accuracy: 0.7562\n",
            "Epoch 198/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.8275 - val_loss: 0.9168 - val_accuracy: 0.7607\n",
            "Epoch 199/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.8288 - val_loss: 0.8885 - val_accuracy: 0.7653\n",
            "Epoch 200/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.8289 - val_loss: 0.8840 - val_accuracy: 0.7584\n",
            "Epoch 201/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.8301 - val_loss: 0.8945 - val_accuracy: 0.7659\n",
            "Epoch 202/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5116 - accuracy: 0.8306 - val_loss: 0.9174 - val_accuracy: 0.7670\n",
            "Epoch 203/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.8354 - val_loss: 0.9312 - val_accuracy: 0.7556\n",
            "Epoch 204/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.8251 - val_loss: 0.9071 - val_accuracy: 0.7544\n",
            "Epoch 205/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.8309 - val_loss: 0.9162 - val_accuracy: 0.7590\n",
            "Epoch 206/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.8305 - val_loss: 0.8904 - val_accuracy: 0.7647\n",
            "Epoch 207/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.8344 - val_loss: 0.8785 - val_accuracy: 0.7670\n",
            "Epoch 208/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.8341 - val_loss: 0.8840 - val_accuracy: 0.7619\n",
            "Epoch 209/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.8404 - val_loss: 0.9125 - val_accuracy: 0.7590\n",
            "Epoch 210/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5033 - accuracy: 0.8339 - val_loss: 0.9013 - val_accuracy: 0.7647\n",
            "Epoch 211/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.8306 - val_loss: 0.9016 - val_accuracy: 0.7624\n",
            "Epoch 212/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.8286 - val_loss: 0.9130 - val_accuracy: 0.7659\n",
            "Epoch 213/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4799 - accuracy: 0.8344 - val_loss: 0.9407 - val_accuracy: 0.7544\n",
            "Epoch 214/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.8361 - val_loss: 0.9205 - val_accuracy: 0.7544\n",
            "Epoch 215/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.8308 - val_loss: 0.9096 - val_accuracy: 0.7693\n",
            "Epoch 216/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.8371 - val_loss: 0.9221 - val_accuracy: 0.7590\n",
            "Epoch 217/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4984 - accuracy: 0.8338 - val_loss: 0.9363 - val_accuracy: 0.7613\n",
            "Epoch 218/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.8448 - val_loss: 0.8972 - val_accuracy: 0.7636\n",
            "Epoch 219/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.8342 - val_loss: 0.9395 - val_accuracy: 0.7521\n",
            "Epoch 220/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.8448 - val_loss: 0.9259 - val_accuracy: 0.7630\n",
            "Epoch 221/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.8273 - val_loss: 0.9331 - val_accuracy: 0.7584\n",
            "Epoch 222/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.8296 - val_loss: 0.8750 - val_accuracy: 0.7659\n",
            "Epoch 223/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4847 - accuracy: 0.8371 - val_loss: 0.8929 - val_accuracy: 0.7670\n",
            "Epoch 224/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4789 - accuracy: 0.8417 - val_loss: 0.9561 - val_accuracy: 0.7613\n",
            "Epoch 225/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4877 - accuracy: 0.8368 - val_loss: 0.9305 - val_accuracy: 0.7527\n",
            "Epoch 226/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4755 - accuracy: 0.8419 - val_loss: 0.9178 - val_accuracy: 0.7642\n",
            "Epoch 227/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.8355 - val_loss: 0.9264 - val_accuracy: 0.7533\n",
            "Epoch 228/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.8381 - val_loss: 0.9417 - val_accuracy: 0.7573\n",
            "Epoch 229/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.8407 - val_loss: 0.9328 - val_accuracy: 0.7665\n",
            "Epoch 230/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.8381 - val_loss: 0.9413 - val_accuracy: 0.7481\n",
            "Epoch 231/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.8381 - val_loss: 0.9432 - val_accuracy: 0.7573\n",
            "Epoch 232/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.8448 - val_loss: 0.9228 - val_accuracy: 0.7579\n",
            "Epoch 233/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.8371 - val_loss: 0.9554 - val_accuracy: 0.7647\n",
            "Epoch 234/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.8415 - val_loss: 0.9596 - val_accuracy: 0.7613\n",
            "Epoch 235/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.8355 - val_loss: 0.8916 - val_accuracy: 0.7687\n",
            "Epoch 236/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.8440 - val_loss: 0.9473 - val_accuracy: 0.7647\n",
            "Epoch 237/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.8444 - val_loss: 0.9259 - val_accuracy: 0.7573\n",
            "Epoch 238/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.8385 - val_loss: 0.9168 - val_accuracy: 0.7682\n",
            "Epoch 239/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.8441 - val_loss: 0.9223 - val_accuracy: 0.7653\n",
            "Epoch 240/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.8331 - val_loss: 0.9294 - val_accuracy: 0.7653\n",
            "Epoch 241/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.8444 - val_loss: 0.9068 - val_accuracy: 0.7693\n",
            "Epoch 242/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4586 - accuracy: 0.8458 - val_loss: 0.9140 - val_accuracy: 0.7653\n",
            "Epoch 243/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4566 - accuracy: 0.8458 - val_loss: 0.9436 - val_accuracy: 0.7619\n",
            "Epoch 244/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.8472 - val_loss: 0.9296 - val_accuracy: 0.7624\n",
            "Epoch 245/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.8521 - val_loss: 0.9723 - val_accuracy: 0.7659\n",
            "Epoch 246/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.8442 - val_loss: 0.9150 - val_accuracy: 0.7716\n",
            "Epoch 247/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.8485 - val_loss: 0.9453 - val_accuracy: 0.7630\n",
            "Epoch 248/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.8419 - val_loss: 0.9463 - val_accuracy: 0.7642\n",
            "Epoch 249/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.8448 - val_loss: 0.9373 - val_accuracy: 0.7745\n",
            "Epoch 250/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.8520 - val_loss: 0.9508 - val_accuracy: 0.7705\n",
            "Epoch 251/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.8344 - val_loss: 0.9510 - val_accuracy: 0.7642\n",
            "Epoch 252/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.8478 - val_loss: 0.9356 - val_accuracy: 0.7665\n",
            "Epoch 253/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.8478 - val_loss: 0.9260 - val_accuracy: 0.7687\n",
            "Epoch 254/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.8409 - val_loss: 0.9411 - val_accuracy: 0.7647\n",
            "Epoch 255/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.8462 - val_loss: 0.9480 - val_accuracy: 0.7693\n",
            "Epoch 256/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.8475 - val_loss: 0.9436 - val_accuracy: 0.7642\n",
            "Epoch 257/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4763 - accuracy: 0.8417 - val_loss: 0.9273 - val_accuracy: 0.7624\n",
            "Epoch 258/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.8444 - val_loss: 0.8949 - val_accuracy: 0.7659\n",
            "Epoch 259/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.8505 - val_loss: 0.9492 - val_accuracy: 0.7682\n",
            "Epoch 260/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.8471 - val_loss: 0.9096 - val_accuracy: 0.7693\n",
            "Epoch 261/300\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4533 - accuracy: 0.8528 - val_loss: 0.9449 - val_accuracy: 0.7687\n",
            "Epoch 262/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.8518 - val_loss: 0.8909 - val_accuracy: 0.7722\n",
            "Epoch 263/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.8520 - val_loss: 0.9240 - val_accuracy: 0.7722\n",
            "Epoch 264/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.8478 - val_loss: 0.9429 - val_accuracy: 0.7728\n",
            "Epoch 265/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4431 - accuracy: 0.8494 - val_loss: 0.9237 - val_accuracy: 0.7670\n",
            "Epoch 266/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.8517 - val_loss: 0.9602 - val_accuracy: 0.7659\n",
            "Epoch 267/300\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4532 - accuracy: 0.8477 - val_loss: 0.9572 - val_accuracy: 0.7676\n",
            "Epoch 268/300\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4629 - accuracy: 0.8460 - val_loss: 0.9117 - val_accuracy: 0.7676\n",
            "Epoch 269/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.8547 - val_loss: 0.9522 - val_accuracy: 0.7682\n",
            "Epoch 270/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.8593 - val_loss: 0.9435 - val_accuracy: 0.7813\n",
            "Epoch 271/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.8545 - val_loss: 0.9301 - val_accuracy: 0.7745\n",
            "Epoch 272/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.8431 - val_loss: 0.9329 - val_accuracy: 0.7687\n",
            "Epoch 273/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4453 - accuracy: 0.8520 - val_loss: 0.9583 - val_accuracy: 0.7613\n",
            "Epoch 274/300\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4494 - accuracy: 0.8467 - val_loss: 0.9450 - val_accuracy: 0.7659\n",
            "Epoch 275/300\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4411 - accuracy: 0.8547 - val_loss: 0.9695 - val_accuracy: 0.7613\n",
            "Epoch 276/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4510 - accuracy: 0.8478 - val_loss: 0.9347 - val_accuracy: 0.7722\n",
            "Epoch 277/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4329 - accuracy: 0.8563 - val_loss: 0.9350 - val_accuracy: 0.7756\n",
            "Epoch 278/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4390 - accuracy: 0.8520 - val_loss: 0.9449 - val_accuracy: 0.7682\n",
            "Epoch 279/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4402 - accuracy: 0.8487 - val_loss: 0.9134 - val_accuracy: 0.7693\n",
            "Epoch 280/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4195 - accuracy: 0.8596 - val_loss: 0.9341 - val_accuracy: 0.7779\n",
            "Epoch 281/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4450 - accuracy: 0.8533 - val_loss: 0.9312 - val_accuracy: 0.7653\n",
            "Epoch 282/300\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4466 - accuracy: 0.8515 - val_loss: 0.9595 - val_accuracy: 0.7710\n",
            "Epoch 283/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4355 - accuracy: 0.8587 - val_loss: 0.9479 - val_accuracy: 0.7653\n",
            "Epoch 284/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4529 - accuracy: 0.8488 - val_loss: 0.9486 - val_accuracy: 0.7602\n",
            "Epoch 285/300\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4385 - accuracy: 0.8521 - val_loss: 0.9415 - val_accuracy: 0.7722\n",
            "Epoch 286/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.8504 - val_loss: 0.9339 - val_accuracy: 0.7647\n",
            "Epoch 287/300\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.8550 - val_loss: 0.9385 - val_accuracy: 0.7722\n",
            "Epoch 288/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.8460 - val_loss: 0.9405 - val_accuracy: 0.7762\n",
            "Epoch 289/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.8508 - val_loss: 0.9366 - val_accuracy: 0.7733\n",
            "Epoch 290/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8560 - val_loss: 0.9928 - val_accuracy: 0.7642\n",
            "Epoch 291/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.8524 - val_loss: 0.9238 - val_accuracy: 0.7687\n",
            "Epoch 292/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.8544 - val_loss: 0.9420 - val_accuracy: 0.7682\n",
            "Epoch 293/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.8550 - val_loss: 0.9790 - val_accuracy: 0.7670\n",
            "Epoch 294/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.8578 - val_loss: 0.9426 - val_accuracy: 0.7693\n",
            "Epoch 295/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4202 - accuracy: 0.8576 - val_loss: 0.9630 - val_accuracy: 0.7699\n",
            "Epoch 296/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.8580 - val_loss: 0.9276 - val_accuracy: 0.7773\n",
            "Epoch 297/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4219 - accuracy: 0.8583 - val_loss: 0.9539 - val_accuracy: 0.7773\n",
            "Epoch 298/300\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4159 - accuracy: 0.8565 - val_loss: 0.9445 - val_accuracy: 0.7636\n",
            "Epoch 299/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4265 - accuracy: 0.8613 - val_loss: 0.9786 - val_accuracy: 0.7659\n",
            "Epoch 300/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8597 - val_loss: 0.9654 - val_accuracy: 0.7693\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe81c0e3190>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "                                #filter sayisi #kernel_size\n",
        "model.add(tf.keras.layers.Conv1D(64,2, activation ='relu', input_shape= (20, 1)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "              #noron sayisi\n",
        "model.add(Dense(32))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "#dropoutlar 0 ile 1 arasinda olcak\n",
        "model.add(Dense(48))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32))\n",
        "\n",
        "            #burayi degistirmeyin\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=\"Adam\",loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])\n",
        "\n",
        "num_epochs = 300\n",
        "num_batch_size = 32\n",
        "\n",
        "model.fit(\n",
        "          x_train, \n",
        "          y_train, \n",
        "          batch_size=num_batch_size, \n",
        "          epochs=num_epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "         )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh252Ucjk805",
        "outputId": "d59fd686-ae0b-4ebc-9483-e4b3b116a1a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_12 (Conv1D)          (None, 19, 64)            192       \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 1216)              0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 32)                38944     \n",
            "                                                                 \n",
            " activation_36 (Activation)  (None, 32)                0         \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 48)                1584      \n",
            "                                                                 \n",
            " activation_37 (Activation)  (None, 48)                0         \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 48)                0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 64)                3136      \n",
            "                                                                 \n",
            " activation_38 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            " activation_39 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 46,266\n",
            "Trainable params: 46,266\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "                  #optimizer cesitle\n",
        "model.compile(optimizer=\"Adam\",loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "PNM1q-bAk83m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 300\n",
        "num_batch_size = 32\n",
        "\n",
        "model.fit(\n",
        "          x_train, \n",
        "          y_train, \n",
        "          batch_size=num_batch_size, \n",
        "          epochs=num_epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "         )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAnjHx-jk87M",
        "outputId": "a246a960-ee41-4121-9530-1c11c2857510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "219/219 [==============================] - 2s 5ms/step - loss: 2.1005 - accuracy: 0.1954 - val_loss: 1.8473 - val_accuracy: 0.2770\n",
            "Epoch 2/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.8790 - accuracy: 0.2777 - val_loss: 1.7618 - val_accuracy: 0.3017\n",
            "Epoch 3/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.8162 - accuracy: 0.3011 - val_loss: 1.6886 - val_accuracy: 0.3652\n",
            "Epoch 4/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.7661 - accuracy: 0.3380 - val_loss: 1.6428 - val_accuracy: 0.4184\n",
            "Epoch 5/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.7259 - accuracy: 0.3611 - val_loss: 1.5963 - val_accuracy: 0.4173\n",
            "Epoch 6/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.6908 - accuracy: 0.3759 - val_loss: 1.5826 - val_accuracy: 0.4236\n",
            "Epoch 7/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.6807 - accuracy: 0.3857 - val_loss: 1.5273 - val_accuracy: 0.4602\n",
            "Epoch 8/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.6624 - accuracy: 0.3924 - val_loss: 1.5673 - val_accuracy: 0.4516\n",
            "Epoch 9/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.6467 - accuracy: 0.3944 - val_loss: 1.5293 - val_accuracy: 0.4820\n",
            "Epoch 10/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.6191 - accuracy: 0.4137 - val_loss: 1.4923 - val_accuracy: 0.4665\n",
            "Epoch 11/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.6013 - accuracy: 0.4157 - val_loss: 1.4618 - val_accuracy: 0.4711\n",
            "Epoch 12/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.5885 - accuracy: 0.4185 - val_loss: 1.4611 - val_accuracy: 0.5123\n",
            "Epoch 13/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.5886 - accuracy: 0.4269 - val_loss: 1.4579 - val_accuracy: 0.5049\n",
            "Epoch 14/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.5640 - accuracy: 0.4345 - val_loss: 1.4394 - val_accuracy: 0.5094\n",
            "Epoch 15/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.5516 - accuracy: 0.4371 - val_loss: 1.4111 - val_accuracy: 0.5163\n",
            "Epoch 16/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.5386 - accuracy: 0.4492 - val_loss: 1.4207 - val_accuracy: 0.5175\n",
            "Epoch 17/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.5339 - accuracy: 0.4491 - val_loss: 1.4145 - val_accuracy: 0.5215\n",
            "Epoch 18/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.5309 - accuracy: 0.4523 - val_loss: 1.4319 - val_accuracy: 0.5129\n",
            "Epoch 19/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.5230 - accuracy: 0.4561 - val_loss: 1.3919 - val_accuracy: 0.5301\n",
            "Epoch 20/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.5177 - accuracy: 0.4570 - val_loss: 1.3648 - val_accuracy: 0.5323\n",
            "Epoch 21/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4941 - accuracy: 0.4618 - val_loss: 1.3633 - val_accuracy: 0.5369\n",
            "Epoch 22/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4954 - accuracy: 0.4614 - val_loss: 1.3431 - val_accuracy: 0.5289\n",
            "Epoch 23/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4670 - accuracy: 0.4780 - val_loss: 1.3432 - val_accuracy: 0.5375\n",
            "Epoch 24/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4895 - accuracy: 0.4680 - val_loss: 1.3423 - val_accuracy: 0.5455\n",
            "Epoch 25/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4732 - accuracy: 0.4720 - val_loss: 1.3370 - val_accuracy: 0.5432\n",
            "Epoch 26/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4654 - accuracy: 0.4776 - val_loss: 1.3329 - val_accuracy: 0.5449\n",
            "Epoch 27/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4659 - accuracy: 0.4862 - val_loss: 1.3237 - val_accuracy: 0.5444\n",
            "Epoch 28/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4391 - accuracy: 0.4835 - val_loss: 1.3103 - val_accuracy: 0.5529\n",
            "Epoch 29/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4375 - accuracy: 0.4875 - val_loss: 1.3081 - val_accuracy: 0.5444\n",
            "Epoch 30/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4333 - accuracy: 0.4888 - val_loss: 1.3174 - val_accuracy: 0.5507\n",
            "Epoch 31/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4492 - accuracy: 0.4886 - val_loss: 1.3280 - val_accuracy: 0.5621\n",
            "Epoch 32/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4327 - accuracy: 0.4942 - val_loss: 1.2958 - val_accuracy: 0.5478\n",
            "Epoch 33/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4392 - accuracy: 0.4958 - val_loss: 1.3255 - val_accuracy: 0.5392\n",
            "Epoch 34/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4129 - accuracy: 0.5029 - val_loss: 1.3147 - val_accuracy: 0.5432\n",
            "Epoch 35/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4261 - accuracy: 0.4956 - val_loss: 1.2899 - val_accuracy: 0.5581\n",
            "Epoch 36/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4152 - accuracy: 0.5058 - val_loss: 1.3195 - val_accuracy: 0.5495\n",
            "Epoch 37/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4025 - accuracy: 0.5084 - val_loss: 1.2941 - val_accuracy: 0.5518\n",
            "Epoch 38/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4163 - accuracy: 0.5005 - val_loss: 1.3017 - val_accuracy: 0.5472\n",
            "Epoch 39/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3969 - accuracy: 0.5021 - val_loss: 1.3166 - val_accuracy: 0.5404\n",
            "Epoch 40/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.3973 - accuracy: 0.5079 - val_loss: 1.2688 - val_accuracy: 0.5667\n",
            "Epoch 41/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.3931 - accuracy: 0.5183 - val_loss: 1.2765 - val_accuracy: 0.5633\n",
            "Epoch 42/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.3756 - accuracy: 0.5164 - val_loss: 1.2737 - val_accuracy: 0.5667\n",
            "Epoch 43/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3693 - accuracy: 0.5208 - val_loss: 1.2533 - val_accuracy: 0.5678\n",
            "Epoch 44/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3894 - accuracy: 0.5137 - val_loss: 1.2455 - val_accuracy: 0.5713\n",
            "Epoch 45/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3630 - accuracy: 0.5217 - val_loss: 1.2461 - val_accuracy: 0.5781\n",
            "Epoch 46/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3716 - accuracy: 0.5128 - val_loss: 1.2698 - val_accuracy: 0.5552\n",
            "Epoch 47/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3647 - accuracy: 0.5273 - val_loss: 1.2531 - val_accuracy: 0.5707\n",
            "Epoch 48/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3801 - accuracy: 0.5147 - val_loss: 1.2555 - val_accuracy: 0.5747\n",
            "Epoch 49/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3534 - accuracy: 0.5266 - val_loss: 1.2438 - val_accuracy: 0.5730\n",
            "Epoch 50/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3717 - accuracy: 0.5240 - val_loss: 1.2659 - val_accuracy: 0.5707\n",
            "Epoch 51/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3579 - accuracy: 0.5263 - val_loss: 1.2777 - val_accuracy: 0.5489\n",
            "Epoch 52/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3483 - accuracy: 0.5336 - val_loss: 1.2560 - val_accuracy: 0.5650\n",
            "Epoch 53/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3578 - accuracy: 0.5271 - val_loss: 1.2540 - val_accuracy: 0.5650\n",
            "Epoch 54/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3498 - accuracy: 0.5268 - val_loss: 1.2300 - val_accuracy: 0.5770\n",
            "Epoch 55/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3463 - accuracy: 0.5231 - val_loss: 1.2575 - val_accuracy: 0.5638\n",
            "Epoch 56/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3298 - accuracy: 0.5387 - val_loss: 1.2478 - val_accuracy: 0.5661\n",
            "Epoch 57/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3233 - accuracy: 0.5430 - val_loss: 1.2356 - val_accuracy: 0.5650\n",
            "Epoch 58/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3395 - accuracy: 0.5337 - val_loss: 1.2195 - val_accuracy: 0.5718\n",
            "Epoch 59/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3355 - accuracy: 0.5341 - val_loss: 1.2393 - val_accuracy: 0.5730\n",
            "Epoch 60/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3398 - accuracy: 0.5374 - val_loss: 1.2051 - val_accuracy: 0.5810\n",
            "Epoch 61/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3298 - accuracy: 0.5390 - val_loss: 1.2225 - val_accuracy: 0.5799\n",
            "Epoch 62/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3244 - accuracy: 0.5382 - val_loss: 1.2070 - val_accuracy: 0.5678\n",
            "Epoch 63/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3277 - accuracy: 0.5390 - val_loss: 1.2435 - val_accuracy: 0.5615\n",
            "Epoch 64/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3088 - accuracy: 0.5414 - val_loss: 1.2457 - val_accuracy: 0.5610\n",
            "Epoch 65/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3116 - accuracy: 0.5453 - val_loss: 1.2546 - val_accuracy: 0.5627\n",
            "Epoch 66/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3055 - accuracy: 0.5470 - val_loss: 1.2427 - val_accuracy: 0.5564\n",
            "Epoch 67/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3128 - accuracy: 0.5433 - val_loss: 1.1859 - val_accuracy: 0.5890\n",
            "Epoch 68/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3131 - accuracy: 0.5429 - val_loss: 1.2064 - val_accuracy: 0.5787\n",
            "Epoch 69/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3025 - accuracy: 0.5508 - val_loss: 1.1932 - val_accuracy: 0.5844\n",
            "Epoch 70/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3125 - accuracy: 0.5450 - val_loss: 1.1962 - val_accuracy: 0.5907\n",
            "Epoch 71/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3071 - accuracy: 0.5452 - val_loss: 1.2020 - val_accuracy: 0.5816\n",
            "Epoch 72/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3050 - accuracy: 0.5453 - val_loss: 1.1934 - val_accuracy: 0.5816\n",
            "Epoch 73/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2977 - accuracy: 0.5437 - val_loss: 1.2014 - val_accuracy: 0.5821\n",
            "Epoch 74/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2972 - accuracy: 0.5490 - val_loss: 1.2153 - val_accuracy: 0.5833\n",
            "Epoch 75/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2992 - accuracy: 0.5523 - val_loss: 1.1997 - val_accuracy: 0.5799\n",
            "Epoch 76/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2911 - accuracy: 0.5559 - val_loss: 1.1788 - val_accuracy: 0.5936\n",
            "Epoch 77/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2958 - accuracy: 0.5479 - val_loss: 1.2052 - val_accuracy: 0.5833\n",
            "Epoch 78/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2911 - accuracy: 0.5455 - val_loss: 1.2034 - val_accuracy: 0.5776\n",
            "Epoch 79/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2685 - accuracy: 0.5529 - val_loss: 1.2078 - val_accuracy: 0.5833\n",
            "Epoch 80/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3040 - accuracy: 0.5529 - val_loss: 1.2341 - val_accuracy: 0.5781\n",
            "Epoch 81/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2804 - accuracy: 0.5475 - val_loss: 1.2072 - val_accuracy: 0.5827\n",
            "Epoch 82/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2844 - accuracy: 0.5519 - val_loss: 1.2311 - val_accuracy: 0.5902\n",
            "Epoch 83/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2954 - accuracy: 0.5540 - val_loss: 1.2176 - val_accuracy: 0.5770\n",
            "Epoch 84/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2798 - accuracy: 0.5542 - val_loss: 1.1974 - val_accuracy: 0.5839\n",
            "Epoch 85/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2773 - accuracy: 0.5549 - val_loss: 1.1995 - val_accuracy: 0.5873\n",
            "Epoch 86/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2830 - accuracy: 0.5550 - val_loss: 1.2274 - val_accuracy: 0.5667\n",
            "Epoch 87/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2834 - accuracy: 0.5635 - val_loss: 1.2187 - val_accuracy: 0.5879\n",
            "Epoch 88/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2695 - accuracy: 0.5569 - val_loss: 1.2092 - val_accuracy: 0.5787\n",
            "Epoch 89/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2704 - accuracy: 0.5634 - val_loss: 1.1977 - val_accuracy: 0.5821\n",
            "Epoch 90/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2792 - accuracy: 0.5550 - val_loss: 1.2070 - val_accuracy: 0.5816\n",
            "Epoch 91/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2681 - accuracy: 0.5609 - val_loss: 1.1849 - val_accuracy: 0.5787\n",
            "Epoch 92/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2745 - accuracy: 0.5592 - val_loss: 1.1909 - val_accuracy: 0.5879\n",
            "Epoch 93/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2816 - accuracy: 0.5609 - val_loss: 1.2165 - val_accuracy: 0.5793\n",
            "Epoch 94/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2592 - accuracy: 0.5646 - val_loss: 1.2239 - val_accuracy: 0.5627\n",
            "Epoch 95/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2587 - accuracy: 0.5638 - val_loss: 1.1951 - val_accuracy: 0.5781\n",
            "Epoch 96/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2721 - accuracy: 0.5635 - val_loss: 1.1862 - val_accuracy: 0.5861\n",
            "Epoch 97/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2665 - accuracy: 0.5576 - val_loss: 1.1738 - val_accuracy: 0.5936\n",
            "Epoch 98/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2581 - accuracy: 0.5596 - val_loss: 1.2054 - val_accuracy: 0.5821\n",
            "Epoch 99/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2572 - accuracy: 0.5654 - val_loss: 1.1873 - val_accuracy: 0.5839\n",
            "Epoch 100/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2585 - accuracy: 0.5621 - val_loss: 1.2034 - val_accuracy: 0.5867\n",
            "Epoch 101/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2539 - accuracy: 0.5718 - val_loss: 1.1755 - val_accuracy: 0.5930\n",
            "Epoch 102/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2617 - accuracy: 0.5649 - val_loss: 1.1857 - val_accuracy: 0.5924\n",
            "Epoch 103/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2437 - accuracy: 0.5695 - val_loss: 1.1939 - val_accuracy: 0.5861\n",
            "Epoch 104/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2641 - accuracy: 0.5582 - val_loss: 1.2002 - val_accuracy: 0.5850\n",
            "Epoch 105/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2470 - accuracy: 0.5701 - val_loss: 1.2011 - val_accuracy: 0.5821\n",
            "Epoch 106/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2547 - accuracy: 0.5639 - val_loss: 1.1590 - val_accuracy: 0.6039\n",
            "Epoch 107/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2524 - accuracy: 0.5686 - val_loss: 1.1793 - val_accuracy: 0.5810\n",
            "Epoch 108/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2458 - accuracy: 0.5669 - val_loss: 1.1691 - val_accuracy: 0.5924\n",
            "Epoch 109/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2450 - accuracy: 0.5681 - val_loss: 1.1557 - val_accuracy: 0.5970\n",
            "Epoch 110/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2605 - accuracy: 0.5619 - val_loss: 1.1906 - val_accuracy: 0.5896\n",
            "Epoch 111/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2432 - accuracy: 0.5735 - val_loss: 1.1868 - val_accuracy: 0.5873\n",
            "Epoch 112/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2482 - accuracy: 0.5707 - val_loss: 1.1692 - val_accuracy: 0.6010\n",
            "Epoch 113/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2419 - accuracy: 0.5742 - val_loss: 1.1580 - val_accuracy: 0.6027\n",
            "Epoch 114/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2327 - accuracy: 0.5709 - val_loss: 1.1659 - val_accuracy: 0.5993\n",
            "Epoch 115/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2420 - accuracy: 0.5696 - val_loss: 1.1578 - val_accuracy: 0.6016\n",
            "Epoch 116/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2362 - accuracy: 0.5785 - val_loss: 1.2003 - val_accuracy: 0.5850\n",
            "Epoch 117/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2467 - accuracy: 0.5685 - val_loss: 1.2233 - val_accuracy: 0.5741\n",
            "Epoch 118/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2540 - accuracy: 0.5696 - val_loss: 1.1740 - val_accuracy: 0.5987\n",
            "Epoch 119/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2320 - accuracy: 0.5711 - val_loss: 1.1469 - val_accuracy: 0.6159\n",
            "Epoch 120/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2551 - accuracy: 0.5665 - val_loss: 1.1555 - val_accuracy: 0.5976\n",
            "Epoch 121/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2239 - accuracy: 0.5815 - val_loss: 1.1608 - val_accuracy: 0.6068\n",
            "Epoch 122/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2323 - accuracy: 0.5792 - val_loss: 1.1677 - val_accuracy: 0.5890\n",
            "Epoch 123/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2313 - accuracy: 0.5741 - val_loss: 1.1785 - val_accuracy: 0.5879\n",
            "Epoch 124/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2309 - accuracy: 0.5781 - val_loss: 1.1586 - val_accuracy: 0.6022\n",
            "Epoch 125/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2241 - accuracy: 0.5807 - val_loss: 1.1562 - val_accuracy: 0.6045\n",
            "Epoch 126/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2154 - accuracy: 0.5827 - val_loss: 1.1794 - val_accuracy: 0.5976\n",
            "Epoch 127/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2181 - accuracy: 0.5860 - val_loss: 1.1495 - val_accuracy: 0.6016\n",
            "Epoch 128/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2244 - accuracy: 0.5835 - val_loss: 1.1785 - val_accuracy: 0.5839\n",
            "Epoch 129/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2124 - accuracy: 0.5835 - val_loss: 1.1526 - val_accuracy: 0.6085\n",
            "Epoch 130/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2087 - accuracy: 0.5895 - val_loss: 1.1752 - val_accuracy: 0.5999\n",
            "Epoch 131/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2075 - accuracy: 0.5914 - val_loss: 1.1509 - val_accuracy: 0.6033\n",
            "Epoch 132/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2182 - accuracy: 0.5851 - val_loss: 1.1529 - val_accuracy: 0.6136\n",
            "Epoch 133/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2175 - accuracy: 0.5787 - val_loss: 1.1579 - val_accuracy: 0.6113\n",
            "Epoch 134/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2127 - accuracy: 0.5864 - val_loss: 1.1650 - val_accuracy: 0.6050\n",
            "Epoch 135/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2253 - accuracy: 0.5811 - val_loss: 1.1682 - val_accuracy: 0.6102\n",
            "Epoch 136/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1963 - accuracy: 0.5950 - val_loss: 1.1870 - val_accuracy: 0.5959\n",
            "Epoch 137/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2143 - accuracy: 0.5904 - val_loss: 1.1671 - val_accuracy: 0.5987\n",
            "Epoch 138/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2002 - accuracy: 0.5936 - val_loss: 1.1521 - val_accuracy: 0.5999\n",
            "Epoch 139/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2249 - accuracy: 0.5815 - val_loss: 1.1665 - val_accuracy: 0.5942\n",
            "Epoch 140/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1926 - accuracy: 0.5924 - val_loss: 1.1448 - val_accuracy: 0.6102\n",
            "Epoch 141/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2069 - accuracy: 0.5835 - val_loss: 1.1356 - val_accuracy: 0.6148\n",
            "Epoch 142/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1970 - accuracy: 0.5936 - val_loss: 1.1891 - val_accuracy: 0.5913\n",
            "Epoch 143/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1955 - accuracy: 0.5891 - val_loss: 1.1483 - val_accuracy: 0.6090\n",
            "Epoch 144/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2115 - accuracy: 0.5864 - val_loss: 1.1615 - val_accuracy: 0.6050\n",
            "Epoch 145/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1801 - accuracy: 0.5974 - val_loss: 1.1617 - val_accuracy: 0.6010\n",
            "Epoch 146/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2162 - accuracy: 0.5908 - val_loss: 1.1585 - val_accuracy: 0.5993\n",
            "Epoch 147/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2000 - accuracy: 0.5917 - val_loss: 1.1574 - val_accuracy: 0.6039\n",
            "Epoch 148/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2089 - accuracy: 0.5881 - val_loss: 1.1515 - val_accuracy: 0.6108\n",
            "Epoch 149/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1906 - accuracy: 0.5981 - val_loss: 1.1182 - val_accuracy: 0.6234\n",
            "Epoch 150/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2062 - accuracy: 0.5885 - val_loss: 1.1474 - val_accuracy: 0.6050\n",
            "Epoch 151/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2038 - accuracy: 0.5913 - val_loss: 1.1744 - val_accuracy: 0.6005\n",
            "Epoch 152/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2029 - accuracy: 0.5944 - val_loss: 1.1560 - val_accuracy: 0.6073\n",
            "Epoch 153/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2083 - accuracy: 0.5860 - val_loss: 1.1668 - val_accuracy: 0.6068\n",
            "Epoch 154/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1778 - accuracy: 0.6004 - val_loss: 1.1575 - val_accuracy: 0.5993\n",
            "Epoch 155/300\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.1951 - accuracy: 0.5937 - val_loss: 1.1506 - val_accuracy: 0.6039\n",
            "Epoch 156/300\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.1954 - accuracy: 0.5923 - val_loss: 1.1392 - val_accuracy: 0.6136\n",
            "Epoch 157/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.1939 - accuracy: 0.5940 - val_loss: 1.1294 - val_accuracy: 0.6108\n",
            "Epoch 158/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1861 - accuracy: 0.5950 - val_loss: 1.1550 - val_accuracy: 0.6022\n",
            "Epoch 159/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1769 - accuracy: 0.5993 - val_loss: 1.1509 - val_accuracy: 0.6131\n",
            "Epoch 160/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1836 - accuracy: 0.5944 - val_loss: 1.1411 - val_accuracy: 0.6188\n",
            "Epoch 161/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1867 - accuracy: 0.5973 - val_loss: 1.1551 - val_accuracy: 0.6153\n",
            "Epoch 162/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1797 - accuracy: 0.6037 - val_loss: 1.1550 - val_accuracy: 0.6022\n",
            "Epoch 163/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1884 - accuracy: 0.5917 - val_loss: 1.1406 - val_accuracy: 0.6176\n",
            "Epoch 164/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1700 - accuracy: 0.6052 - val_loss: 1.1436 - val_accuracy: 0.6062\n",
            "Epoch 165/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1735 - accuracy: 0.5970 - val_loss: 1.1847 - val_accuracy: 0.5965\n",
            "Epoch 166/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1872 - accuracy: 0.5999 - val_loss: 1.1442 - val_accuracy: 0.6182\n",
            "Epoch 167/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1711 - accuracy: 0.6066 - val_loss: 1.1553 - val_accuracy: 0.6102\n",
            "Epoch 168/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1819 - accuracy: 0.5993 - val_loss: 1.1220 - val_accuracy: 0.6119\n",
            "Epoch 169/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2027 - accuracy: 0.5900 - val_loss: 1.1609 - val_accuracy: 0.5947\n",
            "Epoch 170/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1731 - accuracy: 0.6059 - val_loss: 1.1502 - val_accuracy: 0.6033\n",
            "Epoch 171/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1705 - accuracy: 0.6031 - val_loss: 1.1513 - val_accuracy: 0.6090\n",
            "Epoch 172/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1814 - accuracy: 0.6020 - val_loss: 1.1653 - val_accuracy: 0.5953\n",
            "Epoch 173/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1838 - accuracy: 0.5970 - val_loss: 1.1603 - val_accuracy: 0.6073\n",
            "Epoch 174/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1753 - accuracy: 0.6010 - val_loss: 1.1462 - val_accuracy: 0.6068\n",
            "Epoch 175/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1494 - accuracy: 0.6080 - val_loss: 1.1438 - val_accuracy: 0.6113\n",
            "Epoch 176/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1695 - accuracy: 0.6049 - val_loss: 1.1539 - val_accuracy: 0.6159\n",
            "Epoch 177/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1729 - accuracy: 0.5990 - val_loss: 1.1367 - val_accuracy: 0.6268\n",
            "Epoch 178/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1690 - accuracy: 0.6047 - val_loss: 1.1346 - val_accuracy: 0.6188\n",
            "Epoch 179/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1782 - accuracy: 0.6001 - val_loss: 1.1458 - val_accuracy: 0.6205\n",
            "Epoch 180/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1740 - accuracy: 0.6026 - val_loss: 1.1279 - val_accuracy: 0.6205\n",
            "Epoch 181/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1506 - accuracy: 0.6089 - val_loss: 1.1392 - val_accuracy: 0.6096\n",
            "Epoch 182/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1734 - accuracy: 0.5977 - val_loss: 1.1526 - val_accuracy: 0.6090\n",
            "Epoch 183/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1958 - accuracy: 0.5930 - val_loss: 1.1503 - val_accuracy: 0.6136\n",
            "Epoch 184/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1550 - accuracy: 0.6010 - val_loss: 1.1398 - val_accuracy: 0.6216\n",
            "Epoch 185/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1905 - accuracy: 0.6016 - val_loss: 1.1617 - val_accuracy: 0.6085\n",
            "Epoch 186/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1440 - accuracy: 0.6163 - val_loss: 1.1163 - val_accuracy: 0.6285\n",
            "Epoch 187/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1749 - accuracy: 0.6062 - val_loss: 1.1628 - val_accuracy: 0.6136\n",
            "Epoch 188/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1624 - accuracy: 0.6043 - val_loss: 1.1215 - val_accuracy: 0.6142\n",
            "Epoch 189/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1490 - accuracy: 0.6200 - val_loss: 1.1784 - val_accuracy: 0.6068\n",
            "Epoch 190/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1598 - accuracy: 0.6082 - val_loss: 1.1268 - val_accuracy: 0.6302\n",
            "Epoch 191/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1750 - accuracy: 0.5916 - val_loss: 1.1392 - val_accuracy: 0.6199\n",
            "Epoch 192/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1690 - accuracy: 0.6033 - val_loss: 1.1363 - val_accuracy: 0.6148\n",
            "Epoch 193/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1579 - accuracy: 0.6093 - val_loss: 1.1324 - val_accuracy: 0.6325\n",
            "Epoch 194/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1464 - accuracy: 0.6084 - val_loss: 1.1538 - val_accuracy: 0.6159\n",
            "Epoch 195/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1707 - accuracy: 0.6027 - val_loss: 1.1311 - val_accuracy: 0.6256\n",
            "Epoch 196/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1584 - accuracy: 0.6146 - val_loss: 1.1446 - val_accuracy: 0.6171\n",
            "Epoch 197/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1524 - accuracy: 0.6105 - val_loss: 1.1690 - val_accuracy: 0.5970\n",
            "Epoch 198/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1607 - accuracy: 0.6029 - val_loss: 1.1443 - val_accuracy: 0.6148\n",
            "Epoch 199/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1573 - accuracy: 0.6053 - val_loss: 1.1260 - val_accuracy: 0.6153\n",
            "Epoch 200/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1539 - accuracy: 0.6014 - val_loss: 1.1199 - val_accuracy: 0.6279\n",
            "Epoch 201/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1597 - accuracy: 0.6062 - val_loss: 1.1123 - val_accuracy: 0.6314\n",
            "Epoch 202/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1710 - accuracy: 0.6057 - val_loss: 1.1470 - val_accuracy: 0.6159\n",
            "Epoch 203/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1654 - accuracy: 0.6047 - val_loss: 1.1347 - val_accuracy: 0.6199\n",
            "Epoch 204/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1697 - accuracy: 0.6109 - val_loss: 1.1451 - val_accuracy: 0.6211\n",
            "Epoch 205/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1410 - accuracy: 0.6109 - val_loss: 1.1551 - val_accuracy: 0.6182\n",
            "Epoch 206/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1594 - accuracy: 0.6054 - val_loss: 1.1171 - val_accuracy: 0.6291\n",
            "Epoch 207/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1544 - accuracy: 0.6112 - val_loss: 1.1327 - val_accuracy: 0.6159\n",
            "Epoch 208/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1688 - accuracy: 0.6053 - val_loss: 1.1656 - val_accuracy: 0.6085\n",
            "Epoch 209/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1633 - accuracy: 0.6103 - val_loss: 1.1484 - val_accuracy: 0.6079\n",
            "Epoch 210/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1482 - accuracy: 0.6099 - val_loss: 1.1395 - val_accuracy: 0.6159\n",
            "Epoch 211/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1558 - accuracy: 0.6107 - val_loss: 1.1564 - val_accuracy: 0.6125\n",
            "Epoch 212/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1810 - accuracy: 0.6056 - val_loss: 1.1042 - val_accuracy: 0.6405\n",
            "Epoch 213/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1555 - accuracy: 0.6133 - val_loss: 1.1684 - val_accuracy: 0.5936\n",
            "Epoch 214/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1466 - accuracy: 0.6079 - val_loss: 1.1482 - val_accuracy: 0.6153\n",
            "Epoch 215/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1761 - accuracy: 0.6003 - val_loss: 1.1437 - val_accuracy: 0.6228\n",
            "Epoch 216/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1431 - accuracy: 0.6150 - val_loss: 1.1214 - val_accuracy: 0.6308\n",
            "Epoch 217/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1483 - accuracy: 0.6116 - val_loss: 1.1503 - val_accuracy: 0.6062\n",
            "Epoch 218/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1413 - accuracy: 0.6143 - val_loss: 1.1664 - val_accuracy: 0.6045\n",
            "Epoch 219/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1425 - accuracy: 0.6153 - val_loss: 1.1426 - val_accuracy: 0.6239\n",
            "Epoch 220/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1502 - accuracy: 0.6043 - val_loss: 1.1248 - val_accuracy: 0.6274\n",
            "Epoch 221/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1454 - accuracy: 0.6105 - val_loss: 1.1500 - val_accuracy: 0.6222\n",
            "Epoch 222/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1448 - accuracy: 0.6112 - val_loss: 1.1795 - val_accuracy: 0.6022\n",
            "Epoch 223/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1439 - accuracy: 0.6146 - val_loss: 1.1798 - val_accuracy: 0.6171\n",
            "Epoch 224/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1605 - accuracy: 0.6086 - val_loss: 1.1201 - val_accuracy: 0.6297\n",
            "Epoch 225/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1507 - accuracy: 0.6074 - val_loss: 1.1677 - val_accuracy: 0.6068\n",
            "Epoch 226/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1553 - accuracy: 0.6084 - val_loss: 1.1314 - val_accuracy: 0.6274\n",
            "Epoch 227/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1568 - accuracy: 0.6042 - val_loss: 1.1402 - val_accuracy: 0.6211\n",
            "Epoch 228/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1445 - accuracy: 0.6113 - val_loss: 1.1536 - val_accuracy: 0.6062\n",
            "Epoch 229/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1410 - accuracy: 0.6110 - val_loss: 1.1426 - val_accuracy: 0.6148\n",
            "Epoch 230/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1589 - accuracy: 0.6072 - val_loss: 1.1643 - val_accuracy: 0.6136\n",
            "Epoch 231/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1425 - accuracy: 0.6163 - val_loss: 1.0949 - val_accuracy: 0.6371\n",
            "Epoch 232/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1417 - accuracy: 0.6143 - val_loss: 1.1433 - val_accuracy: 0.6239\n",
            "Epoch 233/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1426 - accuracy: 0.6172 - val_loss: 1.1362 - val_accuracy: 0.6188\n",
            "Epoch 234/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1416 - accuracy: 0.6135 - val_loss: 1.1311 - val_accuracy: 0.6274\n",
            "Epoch 235/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1421 - accuracy: 0.6087 - val_loss: 1.1312 - val_accuracy: 0.6199\n",
            "Epoch 236/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1501 - accuracy: 0.6096 - val_loss: 1.1249 - val_accuracy: 0.6279\n",
            "Epoch 237/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1523 - accuracy: 0.6105 - val_loss: 1.1248 - val_accuracy: 0.6268\n",
            "Epoch 238/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1355 - accuracy: 0.6169 - val_loss: 1.1409 - val_accuracy: 0.6308\n",
            "Epoch 239/300\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 1.1502 - accuracy: 0.6105 - val_loss: 1.1281 - val_accuracy: 0.6285\n",
            "Epoch 240/300\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.1225 - accuracy: 0.6225 - val_loss: 1.0950 - val_accuracy: 0.6463\n",
            "Epoch 241/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1258 - accuracy: 0.6228 - val_loss: 1.1340 - val_accuracy: 0.6302\n",
            "Epoch 242/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1471 - accuracy: 0.6050 - val_loss: 1.1400 - val_accuracy: 0.6142\n",
            "Epoch 243/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1242 - accuracy: 0.6289 - val_loss: 1.1426 - val_accuracy: 0.6108\n",
            "Epoch 244/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1416 - accuracy: 0.6129 - val_loss: 1.1376 - val_accuracy: 0.6113\n",
            "Epoch 245/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1288 - accuracy: 0.6157 - val_loss: 1.1291 - val_accuracy: 0.6308\n",
            "Epoch 246/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1441 - accuracy: 0.6120 - val_loss: 1.1645 - val_accuracy: 0.6005\n",
            "Epoch 247/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1574 - accuracy: 0.6060 - val_loss: 1.1169 - val_accuracy: 0.6365\n",
            "Epoch 248/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1342 - accuracy: 0.6163 - val_loss: 1.1209 - val_accuracy: 0.6365\n",
            "Epoch 249/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1511 - accuracy: 0.6122 - val_loss: 1.1544 - val_accuracy: 0.6216\n",
            "Epoch 250/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1539 - accuracy: 0.6099 - val_loss: 1.1144 - val_accuracy: 0.6337\n",
            "Epoch 251/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1347 - accuracy: 0.6153 - val_loss: 1.1172 - val_accuracy: 0.6365\n",
            "Epoch 252/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1211 - accuracy: 0.6208 - val_loss: 1.1571 - val_accuracy: 0.6228\n",
            "Epoch 253/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1570 - accuracy: 0.6100 - val_loss: 1.1477 - val_accuracy: 0.6113\n",
            "Epoch 254/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1281 - accuracy: 0.6159 - val_loss: 1.1310 - val_accuracy: 0.6239\n",
            "Epoch 255/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1294 - accuracy: 0.6135 - val_loss: 1.1314 - val_accuracy: 0.6285\n",
            "Epoch 256/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1369 - accuracy: 0.6132 - val_loss: 1.1592 - val_accuracy: 0.6165\n",
            "Epoch 257/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1379 - accuracy: 0.6186 - val_loss: 1.1198 - val_accuracy: 0.6348\n",
            "Epoch 258/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1401 - accuracy: 0.6107 - val_loss: 1.1178 - val_accuracy: 0.6377\n",
            "Epoch 259/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1408 - accuracy: 0.6132 - val_loss: 1.1101 - val_accuracy: 0.6463\n",
            "Epoch 260/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1445 - accuracy: 0.6132 - val_loss: 1.1337 - val_accuracy: 0.6319\n",
            "Epoch 261/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1455 - accuracy: 0.6123 - val_loss: 1.1331 - val_accuracy: 0.6216\n",
            "Epoch 262/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1387 - accuracy: 0.6208 - val_loss: 1.1070 - val_accuracy: 0.6371\n",
            "Epoch 263/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1272 - accuracy: 0.6179 - val_loss: 1.1626 - val_accuracy: 0.6142\n",
            "Epoch 264/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1348 - accuracy: 0.6153 - val_loss: 1.1445 - val_accuracy: 0.6302\n",
            "Epoch 265/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.1360 - accuracy: 0.6222 - val_loss: 1.1468 - val_accuracy: 0.6153\n",
            "Epoch 266/300\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 1.1141 - accuracy: 0.6255 - val_loss: 1.1116 - val_accuracy: 0.6319\n",
            "Epoch 267/300\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 1.1394 - accuracy: 0.6074 - val_loss: 1.1429 - val_accuracy: 0.6165\n",
            "Epoch 268/300\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 1.1021 - accuracy: 0.6289 - val_loss: 1.1214 - val_accuracy: 0.6377\n",
            "Epoch 269/300\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.1214 - accuracy: 0.6232 - val_loss: 1.1246 - val_accuracy: 0.6205\n",
            "Epoch 270/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1221 - accuracy: 0.6175 - val_loss: 1.1409 - val_accuracy: 0.6211\n",
            "Epoch 271/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.1245 - accuracy: 0.6229 - val_loss: 1.1251 - val_accuracy: 0.6314\n",
            "Epoch 272/300\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.1228 - accuracy: 0.6230 - val_loss: 1.1005 - val_accuracy: 0.6422\n",
            "Epoch 273/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.1235 - accuracy: 0.6130 - val_loss: 1.1562 - val_accuracy: 0.6245\n",
            "Epoch 274/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1224 - accuracy: 0.6200 - val_loss: 1.1184 - val_accuracy: 0.6400\n",
            "Epoch 275/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1266 - accuracy: 0.6180 - val_loss: 1.1418 - val_accuracy: 0.6239\n",
            "Epoch 276/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1128 - accuracy: 0.6245 - val_loss: 1.1497 - val_accuracy: 0.6188\n",
            "Epoch 277/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1345 - accuracy: 0.6113 - val_loss: 1.1470 - val_accuracy: 0.6256\n",
            "Epoch 278/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1383 - accuracy: 0.6135 - val_loss: 1.1433 - val_accuracy: 0.6205\n",
            "Epoch 279/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.1314 - accuracy: 0.6172 - val_loss: 1.1227 - val_accuracy: 0.6451\n",
            "Epoch 280/300\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.1257 - accuracy: 0.6212 - val_loss: 1.1543 - val_accuracy: 0.6136\n",
            "Epoch 281/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.1123 - accuracy: 0.6283 - val_loss: 1.1621 - val_accuracy: 0.6085\n",
            "Epoch 282/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1263 - accuracy: 0.6199 - val_loss: 1.1624 - val_accuracy: 0.6119\n",
            "Epoch 283/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.1403 - accuracy: 0.6135 - val_loss: 1.1688 - val_accuracy: 0.6102\n",
            "Epoch 284/300\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.1343 - accuracy: 0.6188 - val_loss: 1.1129 - val_accuracy: 0.6319\n",
            "Epoch 285/300\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 1.1154 - accuracy: 0.6215 - val_loss: 1.1020 - val_accuracy: 0.6428\n",
            "Epoch 286/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.1256 - accuracy: 0.6225 - val_loss: 1.1318 - val_accuracy: 0.6234\n",
            "Epoch 287/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1303 - accuracy: 0.6179 - val_loss: 1.1268 - val_accuracy: 0.6279\n",
            "Epoch 288/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.1227 - accuracy: 0.6199 - val_loss: 1.1629 - val_accuracy: 0.6108\n",
            "Epoch 289/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.1486 - accuracy: 0.6110 - val_loss: 1.1085 - val_accuracy: 0.6348\n",
            "Epoch 290/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1262 - accuracy: 0.6143 - val_loss: 1.1110 - val_accuracy: 0.6445\n",
            "Epoch 291/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1138 - accuracy: 0.6232 - val_loss: 1.1160 - val_accuracy: 0.6291\n",
            "Epoch 292/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1031 - accuracy: 0.6311 - val_loss: 1.1487 - val_accuracy: 0.6222\n",
            "Epoch 293/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1136 - accuracy: 0.6236 - val_loss: 1.1016 - val_accuracy: 0.6388\n",
            "Epoch 294/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1332 - accuracy: 0.6123 - val_loss: 1.1688 - val_accuracy: 0.6062\n",
            "Epoch 295/300\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.1146 - accuracy: 0.6219 - val_loss: 1.1331 - val_accuracy: 0.6274\n",
            "Epoch 296/300\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.1240 - accuracy: 0.6206 - val_loss: 1.1128 - val_accuracy: 0.6382\n",
            "Epoch 297/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1330 - accuracy: 0.6126 - val_loss: 1.1502 - val_accuracy: 0.6148\n",
            "Epoch 298/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1235 - accuracy: 0.6196 - val_loss: 1.1358 - val_accuracy: 0.6188\n",
            "Epoch 299/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1244 - accuracy: 0.6213 - val_loss: 1.1327 - val_accuracy: 0.6251\n",
            "Epoch 300/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1011 - accuracy: 0.6282 - val_loss: 1.1166 - val_accuracy: 0.6365\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe8061eaf50>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy') =< 0.6 and logs.get('epoch')==100): # Experiment with changing this value\n",
        "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "0WiqiYcspfSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "                                #filter sayisi #kernel_size\n",
        "model.add(tf.keras.layers.Conv1D(16,2, activation ='relu', input_shape= (20, 1)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "              #noron sayisi\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "#dropoutlar 0 ile 1 arasinda olcak\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32))\n",
        "\n",
        "            #burayi degistirmeyin\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=\"Adam\",loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])\n",
        "\n",
        "num_epochs = 300\n",
        "num_batch_size = 32\n",
        "\n",
        "model.fit(\n",
        "          x_train, \n",
        "          y_train, \n",
        "          batch_size=num_batch_size, \n",
        "          epochs=num_epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[callbacks]\n",
        "         )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYAmPq7gpfYO",
        "outputId": "2ca1ffe2-e92a-4a18-994e-f887f75f2bf5"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_13 (Conv1D)          (None, 19, 16)            48        \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 304)               0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 64)                19520     \n",
            "                                                                 \n",
            " activation_40 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " activation_41 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " activation_42 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            " activation_43 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38,554\n",
            "Trainable params: 38,554\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "219/219 [==============================] - 2s 5ms/step - loss: 1.9978 - accuracy: 0.2626 - val_loss: 1.6604 - val_accuracy: 0.3795\n",
            "Epoch 2/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.6960 - accuracy: 0.3800 - val_loss: 1.5404 - val_accuracy: 0.4602\n",
            "Epoch 3/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.6015 - accuracy: 0.4229 - val_loss: 1.4913 - val_accuracy: 0.4711\n",
            "Epoch 4/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.5438 - accuracy: 0.4454 - val_loss: 1.4338 - val_accuracy: 0.4991\n",
            "Epoch 5/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.5000 - accuracy: 0.4666 - val_loss: 1.4460 - val_accuracy: 0.4997\n",
            "Epoch 6/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4525 - accuracy: 0.4859 - val_loss: 1.3284 - val_accuracy: 0.5260\n",
            "Epoch 7/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4017 - accuracy: 0.5042 - val_loss: 1.3196 - val_accuracy: 0.5444\n",
            "Epoch 8/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3867 - accuracy: 0.5162 - val_loss: 1.2925 - val_accuracy: 0.5512\n",
            "Epoch 9/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3338 - accuracy: 0.5321 - val_loss: 1.2351 - val_accuracy: 0.5781\n",
            "Epoch 10/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2907 - accuracy: 0.5472 - val_loss: 1.2008 - val_accuracy: 0.6027\n",
            "Epoch 11/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2677 - accuracy: 0.5666 - val_loss: 1.1825 - val_accuracy: 0.6119\n",
            "Epoch 12/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2485 - accuracy: 0.5745 - val_loss: 1.1548 - val_accuracy: 0.6182\n",
            "Epoch 13/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2253 - accuracy: 0.5767 - val_loss: 1.1188 - val_accuracy: 0.6354\n",
            "Epoch 14/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1968 - accuracy: 0.5881 - val_loss: 1.1013 - val_accuracy: 0.6480\n",
            "Epoch 15/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1698 - accuracy: 0.5993 - val_loss: 1.0801 - val_accuracy: 0.6503\n",
            "Epoch 16/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1514 - accuracy: 0.6109 - val_loss: 1.0618 - val_accuracy: 0.6548\n",
            "Epoch 17/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1286 - accuracy: 0.6165 - val_loss: 1.0418 - val_accuracy: 0.6657\n",
            "Epoch 18/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1143 - accuracy: 0.6242 - val_loss: 1.0560 - val_accuracy: 0.6537\n",
            "Epoch 19/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0923 - accuracy: 0.6296 - val_loss: 1.0205 - val_accuracy: 0.6629\n",
            "Epoch 20/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0911 - accuracy: 0.6328 - val_loss: 0.9989 - val_accuracy: 0.6732\n",
            "Epoch 21/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0594 - accuracy: 0.6371 - val_loss: 0.9853 - val_accuracy: 0.6880\n",
            "Epoch 22/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0335 - accuracy: 0.6484 - val_loss: 0.9843 - val_accuracy: 0.6766\n",
            "Epoch 23/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0311 - accuracy: 0.6534 - val_loss: 0.9757 - val_accuracy: 0.6846\n",
            "Epoch 24/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0015 - accuracy: 0.6580 - val_loss: 0.9638 - val_accuracy: 0.6880\n",
            "Epoch 25/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9946 - accuracy: 0.6624 - val_loss: 0.9733 - val_accuracy: 0.6863\n",
            "Epoch 26/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9887 - accuracy: 0.6683 - val_loss: 0.9756 - val_accuracy: 0.6772\n",
            "Epoch 27/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9866 - accuracy: 0.6669 - val_loss: 0.9218 - val_accuracy: 0.7058\n",
            "Epoch 28/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9782 - accuracy: 0.6717 - val_loss: 0.9256 - val_accuracy: 0.6995\n",
            "Epoch 29/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9613 - accuracy: 0.6759 - val_loss: 0.9399 - val_accuracy: 0.6898\n",
            "Epoch 30/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9645 - accuracy: 0.6754 - val_loss: 0.9289 - val_accuracy: 0.7041\n",
            "Epoch 31/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9462 - accuracy: 0.6810 - val_loss: 0.9183 - val_accuracy: 0.7006\n",
            "Epoch 32/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9369 - accuracy: 0.6872 - val_loss: 0.9099 - val_accuracy: 0.7172\n",
            "Epoch 33/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9326 - accuracy: 0.6835 - val_loss: 0.8977 - val_accuracy: 0.7069\n",
            "Epoch 34/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9145 - accuracy: 0.6895 - val_loss: 0.8777 - val_accuracy: 0.7304\n",
            "Epoch 35/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9114 - accuracy: 0.6945 - val_loss: 0.8822 - val_accuracy: 0.7155\n",
            "Epoch 36/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8962 - accuracy: 0.7002 - val_loss: 0.8972 - val_accuracy: 0.7144\n",
            "Epoch 37/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8919 - accuracy: 0.6985 - val_loss: 0.8732 - val_accuracy: 0.7252\n",
            "Epoch 38/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8882 - accuracy: 0.7075 - val_loss: 0.8658 - val_accuracy: 0.7212\n",
            "Epoch 39/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8722 - accuracy: 0.7061 - val_loss: 0.9009 - val_accuracy: 0.7149\n",
            "Epoch 40/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8826 - accuracy: 0.6998 - val_loss: 0.8685 - val_accuracy: 0.7207\n",
            "Epoch 41/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8767 - accuracy: 0.7078 - val_loss: 0.8543 - val_accuracy: 0.7235\n",
            "Epoch 42/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8708 - accuracy: 0.7120 - val_loss: 0.8607 - val_accuracy: 0.7270\n",
            "Epoch 43/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8461 - accuracy: 0.7164 - val_loss: 0.8441 - val_accuracy: 0.7258\n",
            "Epoch 44/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8611 - accuracy: 0.7120 - val_loss: 0.8687 - val_accuracy: 0.7224\n",
            "Epoch 45/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8367 - accuracy: 0.7198 - val_loss: 0.8373 - val_accuracy: 0.7264\n",
            "Epoch 46/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8329 - accuracy: 0.7190 - val_loss: 0.8498 - val_accuracy: 0.7241\n",
            "Epoch 47/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8313 - accuracy: 0.7174 - val_loss: 0.8189 - val_accuracy: 0.7401\n",
            "Epoch 48/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8529 - accuracy: 0.7141 - val_loss: 0.8272 - val_accuracy: 0.7384\n",
            "Epoch 49/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8300 - accuracy: 0.7241 - val_loss: 0.8335 - val_accuracy: 0.7321\n",
            "Epoch 50/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8257 - accuracy: 0.7253 - val_loss: 0.8396 - val_accuracy: 0.7367\n",
            "Epoch 51/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8340 - accuracy: 0.7220 - val_loss: 0.8140 - val_accuracy: 0.7401\n",
            "Epoch 52/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8063 - accuracy: 0.7300 - val_loss: 0.8668 - val_accuracy: 0.7258\n",
            "Epoch 53/300\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8220 - accuracy: 0.7247 - val_loss: 0.8271 - val_accuracy: 0.7390\n",
            "Epoch 54/300\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8123 - accuracy: 0.7274 - val_loss: 0.8413 - val_accuracy: 0.7338\n",
            "Epoch 55/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8085 - accuracy: 0.7253 - val_loss: 0.8171 - val_accuracy: 0.7396\n",
            "Epoch 56/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8075 - accuracy: 0.7298 - val_loss: 0.8193 - val_accuracy: 0.7396\n",
            "Epoch 57/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7972 - accuracy: 0.7304 - val_loss: 0.8151 - val_accuracy: 0.7304\n",
            "Epoch 58/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8071 - accuracy: 0.7341 - val_loss: 0.8221 - val_accuracy: 0.7378\n",
            "Epoch 59/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7747 - accuracy: 0.7374 - val_loss: 0.7905 - val_accuracy: 0.7539\n",
            "Epoch 60/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7766 - accuracy: 0.7370 - val_loss: 0.8016 - val_accuracy: 0.7464\n",
            "Epoch 61/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7737 - accuracy: 0.7386 - val_loss: 0.7894 - val_accuracy: 0.7556\n",
            "Epoch 62/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7678 - accuracy: 0.7399 - val_loss: 0.8157 - val_accuracy: 0.7390\n",
            "Epoch 63/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7819 - accuracy: 0.7349 - val_loss: 0.8008 - val_accuracy: 0.7481\n",
            "Epoch 64/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7553 - accuracy: 0.7482 - val_loss: 0.8267 - val_accuracy: 0.7453\n",
            "Epoch 65/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7774 - accuracy: 0.7409 - val_loss: 0.8015 - val_accuracy: 0.7499\n",
            "Epoch 66/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7806 - accuracy: 0.7357 - val_loss: 0.7977 - val_accuracy: 0.7459\n",
            "Epoch 67/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7694 - accuracy: 0.7447 - val_loss: 0.7888 - val_accuracy: 0.7447\n",
            "Epoch 68/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7516 - accuracy: 0.7486 - val_loss: 0.7839 - val_accuracy: 0.7481\n",
            "Epoch 69/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7638 - accuracy: 0.7394 - val_loss: 0.7712 - val_accuracy: 0.7590\n",
            "Epoch 70/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7352 - accuracy: 0.7495 - val_loss: 0.7786 - val_accuracy: 0.7613\n",
            "Epoch 71/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7530 - accuracy: 0.7442 - val_loss: 0.7785 - val_accuracy: 0.7481\n",
            "Epoch 72/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7321 - accuracy: 0.7522 - val_loss: 0.7806 - val_accuracy: 0.7493\n",
            "Epoch 73/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7225 - accuracy: 0.7560 - val_loss: 0.7836 - val_accuracy: 0.7539\n",
            "Epoch 74/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7356 - accuracy: 0.7495 - val_loss: 0.7924 - val_accuracy: 0.7504\n",
            "Epoch 75/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7358 - accuracy: 0.7515 - val_loss: 0.7790 - val_accuracy: 0.7527\n",
            "Epoch 76/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7170 - accuracy: 0.7613 - val_loss: 0.7709 - val_accuracy: 0.7596\n",
            "Epoch 77/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7207 - accuracy: 0.7513 - val_loss: 0.7668 - val_accuracy: 0.7556\n",
            "Epoch 78/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7283 - accuracy: 0.7560 - val_loss: 0.7673 - val_accuracy: 0.7556\n",
            "Epoch 79/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7046 - accuracy: 0.7626 - val_loss: 0.7700 - val_accuracy: 0.7527\n",
            "Epoch 80/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7249 - accuracy: 0.7516 - val_loss: 0.7711 - val_accuracy: 0.7619\n",
            "Epoch 81/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7178 - accuracy: 0.7502 - val_loss: 0.7614 - val_accuracy: 0.7527\n",
            "Epoch 82/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7119 - accuracy: 0.7619 - val_loss: 0.7600 - val_accuracy: 0.7533\n",
            "Epoch 83/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7185 - accuracy: 0.7506 - val_loss: 0.7739 - val_accuracy: 0.7476\n",
            "Epoch 84/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7090 - accuracy: 0.7552 - val_loss: 0.7545 - val_accuracy: 0.7562\n",
            "Epoch 85/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7081 - accuracy: 0.7612 - val_loss: 0.7596 - val_accuracy: 0.7573\n",
            "Epoch 86/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7133 - accuracy: 0.7605 - val_loss: 0.7681 - val_accuracy: 0.7590\n",
            "Epoch 87/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7064 - accuracy: 0.7626 - val_loss: 0.7535 - val_accuracy: 0.7630\n",
            "Epoch 88/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7041 - accuracy: 0.7655 - val_loss: 0.7736 - val_accuracy: 0.7556\n",
            "Epoch 89/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7058 - accuracy: 0.7583 - val_loss: 0.7844 - val_accuracy: 0.7516\n",
            "Epoch 90/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6994 - accuracy: 0.7603 - val_loss: 0.7603 - val_accuracy: 0.7682\n",
            "Epoch 91/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6868 - accuracy: 0.7685 - val_loss: 0.7956 - val_accuracy: 0.7544\n",
            "Epoch 92/300\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7072 - accuracy: 0.7632 - val_loss: 0.7614 - val_accuracy: 0.7613\n",
            "Epoch 93/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.6836 - accuracy: 0.7615 - val_loss: 0.7564 - val_accuracy: 0.7607\n",
            "Epoch 94/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.6939 - accuracy: 0.7613 - val_loss: 0.7805 - val_accuracy: 0.7584\n",
            "Epoch 95/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7018 - accuracy: 0.7611 - val_loss: 0.7446 - val_accuracy: 0.7670\n",
            "Epoch 96/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6952 - accuracy: 0.7658 - val_loss: 0.7596 - val_accuracy: 0.7665\n",
            "Epoch 97/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6925 - accuracy: 0.7689 - val_loss: 0.7624 - val_accuracy: 0.7584\n",
            "Epoch 98/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7048 - accuracy: 0.7618 - val_loss: 0.7419 - val_accuracy: 0.7653\n",
            "Epoch 99/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6959 - accuracy: 0.7707 - val_loss: 0.7514 - val_accuracy: 0.7579\n",
            "Epoch 100/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6709 - accuracy: 0.7668 - val_loss: 0.7406 - val_accuracy: 0.7665\n",
            "Epoch 101/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6609 - accuracy: 0.7722 - val_loss: 0.7607 - val_accuracy: 0.7630\n",
            "Epoch 102/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6712 - accuracy: 0.7734 - val_loss: 0.7560 - val_accuracy: 0.7642\n",
            "Epoch 103/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6774 - accuracy: 0.7722 - val_loss: 0.7646 - val_accuracy: 0.7527\n",
            "Epoch 104/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6784 - accuracy: 0.7717 - val_loss: 0.7674 - val_accuracy: 0.7613\n",
            "Epoch 105/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6769 - accuracy: 0.7708 - val_loss: 0.7514 - val_accuracy: 0.7624\n",
            "Epoch 106/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6814 - accuracy: 0.7698 - val_loss: 0.7323 - val_accuracy: 0.7693\n",
            "Epoch 107/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6494 - accuracy: 0.7747 - val_loss: 0.7376 - val_accuracy: 0.7636\n",
            "Epoch 108/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6726 - accuracy: 0.7742 - val_loss: 0.7513 - val_accuracy: 0.7710\n",
            "Epoch 109/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6636 - accuracy: 0.7749 - val_loss: 0.7460 - val_accuracy: 0.7705\n",
            "Epoch 110/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6465 - accuracy: 0.7798 - val_loss: 0.7497 - val_accuracy: 0.7728\n",
            "Epoch 111/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6500 - accuracy: 0.7794 - val_loss: 0.7382 - val_accuracy: 0.7659\n",
            "Epoch 112/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6793 - accuracy: 0.7678 - val_loss: 0.7397 - val_accuracy: 0.7653\n",
            "Epoch 113/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6589 - accuracy: 0.7772 - val_loss: 0.7378 - val_accuracy: 0.7693\n",
            "Epoch 114/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6589 - accuracy: 0.7748 - val_loss: 0.7447 - val_accuracy: 0.7642\n",
            "Epoch 115/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6466 - accuracy: 0.7791 - val_loss: 0.7418 - val_accuracy: 0.7687\n",
            "Epoch 116/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6450 - accuracy: 0.7871 - val_loss: 0.7295 - val_accuracy: 0.7699\n",
            "Epoch 117/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6425 - accuracy: 0.7810 - val_loss: 0.7494 - val_accuracy: 0.7693\n",
            "Epoch 118/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6644 - accuracy: 0.7752 - val_loss: 0.7298 - val_accuracy: 0.7642\n",
            "Epoch 119/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6282 - accuracy: 0.7878 - val_loss: 0.7274 - val_accuracy: 0.7796\n",
            "Epoch 120/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6456 - accuracy: 0.7800 - val_loss: 0.7228 - val_accuracy: 0.7653\n",
            "Epoch 121/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6253 - accuracy: 0.7913 - val_loss: 0.7389 - val_accuracy: 0.7825\n",
            "Epoch 122/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6384 - accuracy: 0.7805 - val_loss: 0.7502 - val_accuracy: 0.7687\n",
            "Epoch 123/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6574 - accuracy: 0.7784 - val_loss: 0.7238 - val_accuracy: 0.7842\n",
            "Epoch 124/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6412 - accuracy: 0.7802 - val_loss: 0.7287 - val_accuracy: 0.7722\n",
            "Epoch 125/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6344 - accuracy: 0.7863 - val_loss: 0.7299 - val_accuracy: 0.7790\n",
            "Epoch 126/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6453 - accuracy: 0.7854 - val_loss: 0.7203 - val_accuracy: 0.7750\n",
            "Epoch 127/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6298 - accuracy: 0.7835 - val_loss: 0.7386 - val_accuracy: 0.7785\n",
            "Epoch 128/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6523 - accuracy: 0.7840 - val_loss: 0.7179 - val_accuracy: 0.7888\n",
            "Epoch 129/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6590 - accuracy: 0.7785 - val_loss: 0.7149 - val_accuracy: 0.7785\n",
            "Epoch 130/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6124 - accuracy: 0.7900 - val_loss: 0.7272 - val_accuracy: 0.7733\n",
            "Epoch 131/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6501 - accuracy: 0.7822 - val_loss: 0.7259 - val_accuracy: 0.7659\n",
            "Epoch 132/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6336 - accuracy: 0.7898 - val_loss: 0.7179 - val_accuracy: 0.7779\n",
            "Epoch 133/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6353 - accuracy: 0.7875 - val_loss: 0.7140 - val_accuracy: 0.7779\n",
            "Epoch 134/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6277 - accuracy: 0.7923 - val_loss: 0.7184 - val_accuracy: 0.7722\n",
            "Epoch 135/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.6397 - accuracy: 0.7844 - val_loss: 0.7184 - val_accuracy: 0.7722\n",
            "Epoch 136/300\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.6299 - accuracy: 0.7855 - val_loss: 0.7329 - val_accuracy: 0.7653\n",
            "Epoch 137/300\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.6391 - accuracy: 0.7815 - val_loss: 0.7000 - val_accuracy: 0.7831\n",
            "Epoch 138/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6248 - accuracy: 0.7887 - val_loss: 0.7368 - val_accuracy: 0.7745\n",
            "Epoch 139/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6143 - accuracy: 0.7980 - val_loss: 0.7134 - val_accuracy: 0.7808\n",
            "Epoch 140/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6378 - accuracy: 0.7900 - val_loss: 0.7164 - val_accuracy: 0.7894\n",
            "Epoch 141/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6066 - accuracy: 0.7933 - val_loss: 0.7094 - val_accuracy: 0.7796\n",
            "Epoch 142/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6176 - accuracy: 0.7918 - val_loss: 0.7307 - val_accuracy: 0.7779\n",
            "Epoch 143/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6207 - accuracy: 0.7871 - val_loss: 0.7384 - val_accuracy: 0.7699\n",
            "Epoch 144/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6283 - accuracy: 0.7927 - val_loss: 0.7231 - val_accuracy: 0.7836\n",
            "Epoch 145/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6122 - accuracy: 0.7944 - val_loss: 0.7499 - val_accuracy: 0.7682\n",
            "Epoch 146/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6037 - accuracy: 0.7951 - val_loss: 0.7240 - val_accuracy: 0.7831\n",
            "Epoch 147/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6293 - accuracy: 0.7901 - val_loss: 0.7487 - val_accuracy: 0.7762\n",
            "Epoch 148/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6102 - accuracy: 0.7884 - val_loss: 0.7194 - val_accuracy: 0.7871\n",
            "Epoch 149/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5973 - accuracy: 0.7956 - val_loss: 0.7227 - val_accuracy: 0.7785\n",
            "Epoch 150/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6093 - accuracy: 0.7903 - val_loss: 0.7348 - val_accuracy: 0.7790\n",
            "Epoch 151/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5945 - accuracy: 0.8009 - val_loss: 0.7413 - val_accuracy: 0.7808\n",
            "Epoch 152/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6103 - accuracy: 0.8001 - val_loss: 0.7598 - val_accuracy: 0.7665\n",
            "Epoch 153/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5959 - accuracy: 0.7976 - val_loss: 0.7250 - val_accuracy: 0.7733\n",
            "Epoch 154/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6119 - accuracy: 0.7980 - val_loss: 0.7100 - val_accuracy: 0.7762\n",
            "Epoch 155/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5904 - accuracy: 0.7976 - val_loss: 0.7283 - val_accuracy: 0.7745\n",
            "Epoch 156/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6080 - accuracy: 0.7969 - val_loss: 0.7101 - val_accuracy: 0.7876\n",
            "Epoch 157/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6164 - accuracy: 0.7943 - val_loss: 0.7201 - val_accuracy: 0.7859\n",
            "Epoch 158/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6083 - accuracy: 0.8030 - val_loss: 0.7345 - val_accuracy: 0.7825\n",
            "Epoch 159/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5886 - accuracy: 0.8011 - val_loss: 0.7479 - val_accuracy: 0.7790\n",
            "Epoch 160/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6127 - accuracy: 0.7916 - val_loss: 0.7247 - val_accuracy: 0.7825\n",
            "Epoch 161/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5971 - accuracy: 0.7910 - val_loss: 0.7192 - val_accuracy: 0.7888\n",
            "Epoch 162/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6028 - accuracy: 0.7997 - val_loss: 0.7328 - val_accuracy: 0.7819\n",
            "Epoch 163/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5981 - accuracy: 0.7986 - val_loss: 0.7451 - val_accuracy: 0.7785\n",
            "Epoch 164/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5847 - accuracy: 0.7921 - val_loss: 0.7214 - val_accuracy: 0.7819\n",
            "Epoch 165/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5916 - accuracy: 0.7966 - val_loss: 0.7527 - val_accuracy: 0.7768\n",
            "Epoch 166/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5683 - accuracy: 0.8092 - val_loss: 0.7371 - val_accuracy: 0.7831\n",
            "Epoch 167/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5760 - accuracy: 0.8072 - val_loss: 0.7257 - val_accuracy: 0.7813\n",
            "Epoch 168/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6045 - accuracy: 0.7950 - val_loss: 0.7326 - val_accuracy: 0.7802\n",
            "Epoch 169/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5926 - accuracy: 0.7993 - val_loss: 0.7110 - val_accuracy: 0.7848\n",
            "Epoch 170/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6004 - accuracy: 0.7938 - val_loss: 0.7338 - val_accuracy: 0.7785\n",
            "Epoch 171/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5966 - accuracy: 0.7976 - val_loss: 0.7212 - val_accuracy: 0.7876\n",
            "Epoch 172/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5979 - accuracy: 0.7947 - val_loss: 0.7181 - val_accuracy: 0.7882\n",
            "Epoch 173/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6014 - accuracy: 0.7986 - val_loss: 0.7094 - val_accuracy: 0.7951\n",
            "Epoch 174/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5844 - accuracy: 0.8056 - val_loss: 0.7160 - val_accuracy: 0.7836\n",
            "Epoch 175/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5873 - accuracy: 0.8036 - val_loss: 0.7332 - val_accuracy: 0.7762\n",
            "Epoch 176/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.5746 - accuracy: 0.8086 - val_loss: 0.7284 - val_accuracy: 0.7894\n",
            "Epoch 177/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5832 - accuracy: 0.8014 - val_loss: 0.7218 - val_accuracy: 0.7888\n",
            "Epoch 178/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5836 - accuracy: 0.8070 - val_loss: 0.7186 - val_accuracy: 0.7905\n",
            "Epoch 179/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5646 - accuracy: 0.8094 - val_loss: 0.7207 - val_accuracy: 0.7888\n",
            "Epoch 180/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5925 - accuracy: 0.7989 - val_loss: 0.7383 - val_accuracy: 0.7779\n",
            "Epoch 181/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5881 - accuracy: 0.8036 - val_loss: 0.7257 - val_accuracy: 0.7945\n",
            "Epoch 182/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5945 - accuracy: 0.7961 - val_loss: 0.7184 - val_accuracy: 0.7785\n",
            "Epoch 183/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5699 - accuracy: 0.8054 - val_loss: 0.7117 - val_accuracy: 0.7859\n",
            "Epoch 184/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5956 - accuracy: 0.8010 - val_loss: 0.7138 - val_accuracy: 0.7951\n",
            "Epoch 185/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5777 - accuracy: 0.8053 - val_loss: 0.7192 - val_accuracy: 0.7853\n",
            "Epoch 186/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5894 - accuracy: 0.8010 - val_loss: 0.7116 - val_accuracy: 0.7911\n",
            "Epoch 187/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5640 - accuracy: 0.8129 - val_loss: 0.7193 - val_accuracy: 0.7951\n",
            "Epoch 188/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5739 - accuracy: 0.8073 - val_loss: 0.7125 - val_accuracy: 0.7951\n",
            "Epoch 189/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5819 - accuracy: 0.8070 - val_loss: 0.7350 - val_accuracy: 0.7802\n",
            "Epoch 190/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5873 - accuracy: 0.8000 - val_loss: 0.7150 - val_accuracy: 0.7808\n",
            "Epoch 191/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5751 - accuracy: 0.8076 - val_loss: 0.6937 - val_accuracy: 0.7945\n",
            "Epoch 192/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5583 - accuracy: 0.8105 - val_loss: 0.7120 - val_accuracy: 0.7894\n",
            "Epoch 193/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5599 - accuracy: 0.8084 - val_loss: 0.7145 - val_accuracy: 0.7808\n",
            "Epoch 194/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5770 - accuracy: 0.8103 - val_loss: 0.7298 - val_accuracy: 0.7842\n",
            "Epoch 195/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5800 - accuracy: 0.8030 - val_loss: 0.7108 - val_accuracy: 0.7911\n",
            "Epoch 196/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5698 - accuracy: 0.8070 - val_loss: 0.7006 - val_accuracy: 0.7888\n",
            "Epoch 197/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5593 - accuracy: 0.8168 - val_loss: 0.7443 - val_accuracy: 0.7882\n",
            "Epoch 198/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5663 - accuracy: 0.8140 - val_loss: 0.7184 - val_accuracy: 0.7773\n",
            "Epoch 199/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5641 - accuracy: 0.8014 - val_loss: 0.7217 - val_accuracy: 0.7888\n",
            "Epoch 200/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5496 - accuracy: 0.8094 - val_loss: 0.7311 - val_accuracy: 0.7899\n",
            "Epoch 201/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5540 - accuracy: 0.8132 - val_loss: 0.7349 - val_accuracy: 0.7865\n",
            "Epoch 202/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5831 - accuracy: 0.8066 - val_loss: 0.7277 - val_accuracy: 0.7831\n",
            "Epoch 203/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5658 - accuracy: 0.8100 - val_loss: 0.7280 - val_accuracy: 0.7899\n",
            "Epoch 204/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5601 - accuracy: 0.8094 - val_loss: 0.7210 - val_accuracy: 0.7922\n",
            "Epoch 205/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5620 - accuracy: 0.8060 - val_loss: 0.7235 - val_accuracy: 0.7968\n",
            "Epoch 206/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5617 - accuracy: 0.8105 - val_loss: 0.7226 - val_accuracy: 0.7905\n",
            "Epoch 207/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5506 - accuracy: 0.8125 - val_loss: 0.7175 - val_accuracy: 0.7836\n",
            "Epoch 208/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5741 - accuracy: 0.8062 - val_loss: 0.7333 - val_accuracy: 0.7796\n",
            "Epoch 209/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5509 - accuracy: 0.8132 - val_loss: 0.7240 - val_accuracy: 0.7762\n",
            "Epoch 210/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5568 - accuracy: 0.8112 - val_loss: 0.7314 - val_accuracy: 0.7825\n",
            "Epoch 211/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5484 - accuracy: 0.8120 - val_loss: 0.7222 - val_accuracy: 0.7939\n",
            "Epoch 212/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5552 - accuracy: 0.8139 - val_loss: 0.7205 - val_accuracy: 0.7922\n",
            "Epoch 213/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5426 - accuracy: 0.8169 - val_loss: 0.7160 - val_accuracy: 0.7939\n",
            "Epoch 214/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5526 - accuracy: 0.8220 - val_loss: 0.7068 - val_accuracy: 0.7979\n",
            "Epoch 215/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5500 - accuracy: 0.8152 - val_loss: 0.7127 - val_accuracy: 0.7865\n",
            "Epoch 216/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5490 - accuracy: 0.8145 - val_loss: 0.7193 - val_accuracy: 0.7871\n",
            "Epoch 217/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5484 - accuracy: 0.8195 - val_loss: 0.6990 - val_accuracy: 0.7956\n",
            "Epoch 218/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5588 - accuracy: 0.8157 - val_loss: 0.7100 - val_accuracy: 0.7905\n",
            "Epoch 219/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5452 - accuracy: 0.8140 - val_loss: 0.7434 - val_accuracy: 0.7842\n",
            "Epoch 220/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5599 - accuracy: 0.8097 - val_loss: 0.7189 - val_accuracy: 0.7882\n",
            "Epoch 221/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5464 - accuracy: 0.8153 - val_loss: 0.7354 - val_accuracy: 0.7899\n",
            "Epoch 222/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5569 - accuracy: 0.8113 - val_loss: 0.7327 - val_accuracy: 0.7888\n",
            "Epoch 223/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5608 - accuracy: 0.8100 - val_loss: 0.7299 - val_accuracy: 0.7928\n",
            "Epoch 224/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5459 - accuracy: 0.8160 - val_loss: 0.7466 - val_accuracy: 0.7836\n",
            "Epoch 225/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5515 - accuracy: 0.8140 - val_loss: 0.7413 - val_accuracy: 0.7853\n",
            "Epoch 226/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5249 - accuracy: 0.8210 - val_loss: 0.7249 - val_accuracy: 0.7848\n",
            "Epoch 227/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5586 - accuracy: 0.8122 - val_loss: 0.7321 - val_accuracy: 0.7853\n",
            "Epoch 228/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5376 - accuracy: 0.8179 - val_loss: 0.7185 - val_accuracy: 0.7916\n",
            "Epoch 229/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5288 - accuracy: 0.8213 - val_loss: 0.7123 - val_accuracy: 0.7899\n",
            "Epoch 230/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5546 - accuracy: 0.8129 - val_loss: 0.7236 - val_accuracy: 0.7802\n",
            "Epoch 231/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5446 - accuracy: 0.8140 - val_loss: 0.7464 - val_accuracy: 0.7899\n",
            "Epoch 232/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5440 - accuracy: 0.8153 - val_loss: 0.7423 - val_accuracy: 0.7916\n",
            "Epoch 233/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5431 - accuracy: 0.8146 - val_loss: 0.7419 - val_accuracy: 0.7836\n",
            "Epoch 234/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5331 - accuracy: 0.8179 - val_loss: 0.7351 - val_accuracy: 0.7899\n",
            "Epoch 235/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5312 - accuracy: 0.8200 - val_loss: 0.7434 - val_accuracy: 0.7882\n",
            "Epoch 236/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5361 - accuracy: 0.8166 - val_loss: 0.7303 - val_accuracy: 0.7836\n",
            "Epoch 237/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5367 - accuracy: 0.8203 - val_loss: 0.7424 - val_accuracy: 0.7831\n",
            "Epoch 238/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5495 - accuracy: 0.8147 - val_loss: 0.7224 - val_accuracy: 0.7876\n",
            "Epoch 239/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5464 - accuracy: 0.8202 - val_loss: 0.7026 - val_accuracy: 0.7939\n",
            "Epoch 240/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5575 - accuracy: 0.8150 - val_loss: 0.7074 - val_accuracy: 0.7899\n",
            "Epoch 241/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5515 - accuracy: 0.8119 - val_loss: 0.7256 - val_accuracy: 0.7928\n",
            "Epoch 242/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5347 - accuracy: 0.8198 - val_loss: 0.7157 - val_accuracy: 0.7922\n",
            "Epoch 243/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5423 - accuracy: 0.8156 - val_loss: 0.7122 - val_accuracy: 0.7848\n",
            "Epoch 244/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5350 - accuracy: 0.8232 - val_loss: 0.6999 - val_accuracy: 0.8037\n",
            "Epoch 245/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5448 - accuracy: 0.8172 - val_loss: 0.7283 - val_accuracy: 0.7945\n",
            "Epoch 246/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5191 - accuracy: 0.8262 - val_loss: 0.7214 - val_accuracy: 0.8002\n",
            "Epoch 247/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5242 - accuracy: 0.8218 - val_loss: 0.7218 - val_accuracy: 0.7911\n",
            "Epoch 248/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5294 - accuracy: 0.8160 - val_loss: 0.7181 - val_accuracy: 0.7968\n",
            "Epoch 249/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5246 - accuracy: 0.8242 - val_loss: 0.7435 - val_accuracy: 0.7882\n",
            "Epoch 250/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.5294 - accuracy: 0.8200 - val_loss: 0.7225 - val_accuracy: 0.7911\n",
            "Epoch 251/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5497 - accuracy: 0.8133 - val_loss: 0.7044 - val_accuracy: 0.7916\n",
            "Epoch 252/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5246 - accuracy: 0.8205 - val_loss: 0.7427 - val_accuracy: 0.7859\n",
            "Epoch 253/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5395 - accuracy: 0.8139 - val_loss: 0.7028 - val_accuracy: 0.7974\n",
            "Epoch 254/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5337 - accuracy: 0.8192 - val_loss: 0.7061 - val_accuracy: 0.7974\n",
            "Epoch 255/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5287 - accuracy: 0.8275 - val_loss: 0.7198 - val_accuracy: 0.7916\n",
            "Epoch 256/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5310 - accuracy: 0.8241 - val_loss: 0.7111 - val_accuracy: 0.7979\n",
            "Epoch 257/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5320 - accuracy: 0.8159 - val_loss: 0.7137 - val_accuracy: 0.7951\n",
            "Epoch 258/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5333 - accuracy: 0.8169 - val_loss: 0.7141 - val_accuracy: 0.7939\n",
            "Epoch 259/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5320 - accuracy: 0.8189 - val_loss: 0.7430 - val_accuracy: 0.7859\n",
            "Epoch 260/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5236 - accuracy: 0.8273 - val_loss: 0.7368 - val_accuracy: 0.7836\n",
            "Epoch 261/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5373 - accuracy: 0.8168 - val_loss: 0.7263 - val_accuracy: 0.7951\n",
            "Epoch 262/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5437 - accuracy: 0.8186 - val_loss: 0.7364 - val_accuracy: 0.7939\n",
            "Epoch 263/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5385 - accuracy: 0.8190 - val_loss: 0.7466 - val_accuracy: 0.7790\n",
            "Epoch 264/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5270 - accuracy: 0.8265 - val_loss: 0.7254 - val_accuracy: 0.7922\n",
            "Epoch 265/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5437 - accuracy: 0.8202 - val_loss: 0.7107 - val_accuracy: 0.7905\n",
            "Epoch 266/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5134 - accuracy: 0.8258 - val_loss: 0.7110 - val_accuracy: 0.7888\n",
            "Epoch 267/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5259 - accuracy: 0.8205 - val_loss: 0.7182 - val_accuracy: 0.7928\n",
            "Epoch 268/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5188 - accuracy: 0.8235 - val_loss: 0.7624 - val_accuracy: 0.7859\n",
            "Epoch 269/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5267 - accuracy: 0.8301 - val_loss: 0.7375 - val_accuracy: 0.7945\n",
            "Epoch 270/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5198 - accuracy: 0.8208 - val_loss: 0.7604 - val_accuracy: 0.7836\n",
            "Epoch 271/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5245 - accuracy: 0.8268 - val_loss: 0.7136 - val_accuracy: 0.7934\n",
            "Epoch 272/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5059 - accuracy: 0.8299 - val_loss: 0.7401 - val_accuracy: 0.7911\n",
            "Epoch 273/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5233 - accuracy: 0.8196 - val_loss: 0.7331 - val_accuracy: 0.7934\n",
            "Epoch 274/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5278 - accuracy: 0.8190 - val_loss: 0.7262 - val_accuracy: 0.7882\n",
            "Epoch 275/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5147 - accuracy: 0.8301 - val_loss: 0.7611 - val_accuracy: 0.7848\n",
            "Epoch 276/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5168 - accuracy: 0.8285 - val_loss: 0.7072 - val_accuracy: 0.7916\n",
            "Epoch 277/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5070 - accuracy: 0.8282 - val_loss: 0.7186 - val_accuracy: 0.7956\n",
            "Epoch 278/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5197 - accuracy: 0.8238 - val_loss: 0.7214 - val_accuracy: 0.7956\n",
            "Epoch 279/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5391 - accuracy: 0.8180 - val_loss: 0.6940 - val_accuracy: 0.7962\n",
            "Epoch 280/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5110 - accuracy: 0.8261 - val_loss: 0.7442 - val_accuracy: 0.7951\n",
            "Epoch 281/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5138 - accuracy: 0.8342 - val_loss: 0.7261 - val_accuracy: 0.7968\n",
            "Epoch 282/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5277 - accuracy: 0.8233 - val_loss: 0.7256 - val_accuracy: 0.7997\n",
            "Epoch 283/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.5222 - accuracy: 0.8262 - val_loss: 0.7238 - val_accuracy: 0.8002\n",
            "Epoch 284/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5130 - accuracy: 0.8262 - val_loss: 0.7090 - val_accuracy: 0.7945\n",
            "Epoch 285/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5262 - accuracy: 0.8255 - val_loss: 0.7205 - val_accuracy: 0.7922\n",
            "Epoch 286/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.5339 - accuracy: 0.8205 - val_loss: 0.7100 - val_accuracy: 0.7945\n",
            "Epoch 287/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.5203 - accuracy: 0.8202 - val_loss: 0.7437 - val_accuracy: 0.7859\n",
            "Epoch 288/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5198 - accuracy: 0.8256 - val_loss: 0.7115 - val_accuracy: 0.7945\n",
            "Epoch 289/300\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.4983 - accuracy: 0.8292 - val_loss: 0.7285 - val_accuracy: 0.7951\n",
            "Epoch 290/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5168 - accuracy: 0.8266 - val_loss: 0.7244 - val_accuracy: 0.7962\n",
            "Epoch 291/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5134 - accuracy: 0.8238 - val_loss: 0.7357 - val_accuracy: 0.8002\n",
            "Epoch 292/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5224 - accuracy: 0.8266 - val_loss: 0.7347 - val_accuracy: 0.7922\n",
            "Epoch 293/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5139 - accuracy: 0.8273 - val_loss: 0.7226 - val_accuracy: 0.7945\n",
            "Epoch 294/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5175 - accuracy: 0.8285 - val_loss: 0.6924 - val_accuracy: 0.7934\n",
            "Epoch 295/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5129 - accuracy: 0.8245 - val_loss: 0.7108 - val_accuracy: 0.7956\n",
            "Epoch 296/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5230 - accuracy: 0.8295 - val_loss: 0.7135 - val_accuracy: 0.7939\n",
            "Epoch 297/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5002 - accuracy: 0.8331 - val_loss: 0.7384 - val_accuracy: 0.7939\n",
            "Epoch 298/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5079 - accuracy: 0.8286 - val_loss: 0.7293 - val_accuracy: 0.7894\n",
            "Epoch 299/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5271 - accuracy: 0.8262 - val_loss: 0.7431 - val_accuracy: 0.7853\n",
            "Epoch 300/300\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5159 - accuracy: 0.8291 - val_loss: 0.7437 - val_accuracy: 0.7888\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe80077e890>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "                                #filter sayisi #kernel_size\n",
        "model.add(tf.keras.layers.Conv1D(16,2, activation ='relu', input_shape= (20, 1)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "              #noron sayisi\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "#dropoutlar 0 ile 1 arasinda olcak\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32))\n",
        "\n",
        "            #burayi degistirmeyin\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=\"Adam\",loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])\n",
        "\n",
        "num_epochs = 300\n",
        "num_batch_size = 64\n",
        "\n",
        "model.fit(\n",
        "          x_train, \n",
        "          y_train, \n",
        "          batch_size=num_batch_size, \n",
        "          epochs=num_epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[callbacks]\n",
        "         )"
      ],
      "metadata": {
        "id": "3lMHpT8Qpfbr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb65fc52-fb3e-4595-b769-9641e94333a2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_14 (Conv1D)          (None, 19, 16)            48        \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 304)               0         \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 64)                19520     \n",
            "                                                                 \n",
            " activation_44 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " activation_45 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " activation_46 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            " activation_47 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38,554\n",
            "Trainable params: 38,554\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 2.1443 - accuracy: 0.1979 - val_loss: 1.8961 - val_accuracy: 0.3291\n",
            "Epoch 2/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8329 - accuracy: 0.3200 - val_loss: 1.6698 - val_accuracy: 0.4081\n",
            "Epoch 3/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6941 - accuracy: 0.3841 - val_loss: 1.5611 - val_accuracy: 0.4448\n",
            "Epoch 4/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6177 - accuracy: 0.4143 - val_loss: 1.5088 - val_accuracy: 0.4694\n",
            "Epoch 5/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5578 - accuracy: 0.4477 - val_loss: 1.4485 - val_accuracy: 0.5054\n",
            "Epoch 6/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5120 - accuracy: 0.4610 - val_loss: 1.3999 - val_accuracy: 0.5255\n",
            "Epoch 7/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4723 - accuracy: 0.4712 - val_loss: 1.3646 - val_accuracy: 0.5375\n",
            "Epoch 8/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4440 - accuracy: 0.4872 - val_loss: 1.3443 - val_accuracy: 0.5260\n",
            "Epoch 9/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4143 - accuracy: 0.5052 - val_loss: 1.3050 - val_accuracy: 0.5718\n",
            "Epoch 10/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3808 - accuracy: 0.5180 - val_loss: 1.2794 - val_accuracy: 0.5741\n",
            "Epoch 11/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3512 - accuracy: 0.5389 - val_loss: 1.2474 - val_accuracy: 0.5844\n",
            "Epoch 12/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3177 - accuracy: 0.5472 - val_loss: 1.2198 - val_accuracy: 0.5936\n",
            "Epoch 13/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2869 - accuracy: 0.5612 - val_loss: 1.2024 - val_accuracy: 0.5947\n",
            "Epoch 14/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2810 - accuracy: 0.5542 - val_loss: 1.1694 - val_accuracy: 0.6102\n",
            "Epoch 15/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2517 - accuracy: 0.5699 - val_loss: 1.1544 - val_accuracy: 0.6193\n",
            "Epoch 16/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2247 - accuracy: 0.5818 - val_loss: 1.1318 - val_accuracy: 0.6216\n",
            "Epoch 17/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1989 - accuracy: 0.5860 - val_loss: 1.0971 - val_accuracy: 0.6365\n",
            "Epoch 18/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.1804 - accuracy: 0.5963 - val_loss: 1.0840 - val_accuracy: 0.6365\n",
            "Epoch 19/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1698 - accuracy: 0.6009 - val_loss: 1.0691 - val_accuracy: 0.6422\n",
            "Epoch 20/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1528 - accuracy: 0.6039 - val_loss: 1.0595 - val_accuracy: 0.6566\n",
            "Epoch 21/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1483 - accuracy: 0.6093 - val_loss: 1.0371 - val_accuracy: 0.6548\n",
            "Epoch 22/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1318 - accuracy: 0.6130 - val_loss: 1.0334 - val_accuracy: 0.6560\n",
            "Epoch 23/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1149 - accuracy: 0.6165 - val_loss: 1.0223 - val_accuracy: 0.6691\n",
            "Epoch 24/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1019 - accuracy: 0.6245 - val_loss: 1.0223 - val_accuracy: 0.6611\n",
            "Epoch 25/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0839 - accuracy: 0.6335 - val_loss: 1.0038 - val_accuracy: 0.6760\n",
            "Epoch 26/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0729 - accuracy: 0.6352 - val_loss: 0.9880 - val_accuracy: 0.6777\n",
            "Epoch 27/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0706 - accuracy: 0.6339 - val_loss: 0.9930 - val_accuracy: 0.6743\n",
            "Epoch 28/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0506 - accuracy: 0.6412 - val_loss: 0.9614 - val_accuracy: 0.6880\n",
            "Epoch 29/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0321 - accuracy: 0.6521 - val_loss: 0.9530 - val_accuracy: 0.6795\n",
            "Epoch 30/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0224 - accuracy: 0.6520 - val_loss: 0.9670 - val_accuracy: 0.6806\n",
            "Epoch 31/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0208 - accuracy: 0.6570 - val_loss: 0.9505 - val_accuracy: 0.6915\n",
            "Epoch 32/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0078 - accuracy: 0.6583 - val_loss: 0.9342 - val_accuracy: 0.6949\n",
            "Epoch 33/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9915 - accuracy: 0.6636 - val_loss: 0.9252 - val_accuracy: 0.6972\n",
            "Epoch 34/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9936 - accuracy: 0.6671 - val_loss: 0.9137 - val_accuracy: 0.7086\n",
            "Epoch 35/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9822 - accuracy: 0.6626 - val_loss: 0.9185 - val_accuracy: 0.7064\n",
            "Epoch 36/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9792 - accuracy: 0.6649 - val_loss: 0.8987 - val_accuracy: 0.7195\n",
            "Epoch 37/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9696 - accuracy: 0.6732 - val_loss: 0.8935 - val_accuracy: 0.7184\n",
            "Epoch 38/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9587 - accuracy: 0.6670 - val_loss: 0.8946 - val_accuracy: 0.7149\n",
            "Epoch 39/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9598 - accuracy: 0.6686 - val_loss: 0.8977 - val_accuracy: 0.7115\n",
            "Epoch 40/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9630 - accuracy: 0.6720 - val_loss: 0.8922 - val_accuracy: 0.7218\n",
            "Epoch 41/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9392 - accuracy: 0.6819 - val_loss: 0.9009 - val_accuracy: 0.7155\n",
            "Epoch 42/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9375 - accuracy: 0.6810 - val_loss: 0.8731 - val_accuracy: 0.7218\n",
            "Epoch 43/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.9325 - accuracy: 0.6805 - val_loss: 0.8670 - val_accuracy: 0.7287\n",
            "Epoch 44/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9170 - accuracy: 0.6886 - val_loss: 0.8674 - val_accuracy: 0.7252\n",
            "Epoch 45/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9184 - accuracy: 0.6883 - val_loss: 0.8726 - val_accuracy: 0.7230\n",
            "Epoch 46/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9071 - accuracy: 0.6856 - val_loss: 0.8644 - val_accuracy: 0.7235\n",
            "Epoch 47/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8977 - accuracy: 0.6936 - val_loss: 0.8548 - val_accuracy: 0.7287\n",
            "Epoch 48/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8932 - accuracy: 0.6855 - val_loss: 0.8494 - val_accuracy: 0.7350\n",
            "Epoch 49/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8869 - accuracy: 0.7005 - val_loss: 0.8786 - val_accuracy: 0.7230\n",
            "Epoch 50/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8954 - accuracy: 0.6959 - val_loss: 0.8512 - val_accuracy: 0.7355\n",
            "Epoch 51/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8652 - accuracy: 0.7012 - val_loss: 0.8309 - val_accuracy: 0.7367\n",
            "Epoch 52/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.8751 - accuracy: 0.7032 - val_loss: 0.8499 - val_accuracy: 0.7298\n",
            "Epoch 53/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8833 - accuracy: 0.7057 - val_loss: 0.8386 - val_accuracy: 0.7350\n",
            "Epoch 54/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8727 - accuracy: 0.7037 - val_loss: 0.8380 - val_accuracy: 0.7350\n",
            "Epoch 55/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8664 - accuracy: 0.7012 - val_loss: 0.8612 - val_accuracy: 0.7293\n",
            "Epoch 56/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8560 - accuracy: 0.7058 - val_loss: 0.8263 - val_accuracy: 0.7355\n",
            "Epoch 57/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8551 - accuracy: 0.7055 - val_loss: 0.8365 - val_accuracy: 0.7430\n",
            "Epoch 58/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8459 - accuracy: 0.7162 - val_loss: 0.8286 - val_accuracy: 0.7361\n",
            "Epoch 59/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8552 - accuracy: 0.7042 - val_loss: 0.8353 - val_accuracy: 0.7327\n",
            "Epoch 60/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8559 - accuracy: 0.7108 - val_loss: 0.8180 - val_accuracy: 0.7418\n",
            "Epoch 61/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8401 - accuracy: 0.7174 - val_loss: 0.8362 - val_accuracy: 0.7378\n",
            "Epoch 62/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8265 - accuracy: 0.7140 - val_loss: 0.8325 - val_accuracy: 0.7453\n",
            "Epoch 63/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8288 - accuracy: 0.7194 - val_loss: 0.8406 - val_accuracy: 0.7378\n",
            "Epoch 64/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8071 - accuracy: 0.7231 - val_loss: 0.8344 - val_accuracy: 0.7418\n",
            "Epoch 65/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8221 - accuracy: 0.7184 - val_loss: 0.8176 - val_accuracy: 0.7481\n",
            "Epoch 66/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8240 - accuracy: 0.7171 - val_loss: 0.8222 - val_accuracy: 0.7476\n",
            "Epoch 67/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8083 - accuracy: 0.7237 - val_loss: 0.8305 - val_accuracy: 0.7407\n",
            "Epoch 68/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8139 - accuracy: 0.7247 - val_loss: 0.8014 - val_accuracy: 0.7481\n",
            "Epoch 69/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7996 - accuracy: 0.7261 - val_loss: 0.8124 - val_accuracy: 0.7447\n",
            "Epoch 70/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8034 - accuracy: 0.7273 - val_loss: 0.8056 - val_accuracy: 0.7459\n",
            "Epoch 71/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7898 - accuracy: 0.7264 - val_loss: 0.8028 - val_accuracy: 0.7441\n",
            "Epoch 72/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8029 - accuracy: 0.7204 - val_loss: 0.8192 - val_accuracy: 0.7459\n",
            "Epoch 73/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7949 - accuracy: 0.7294 - val_loss: 0.8111 - val_accuracy: 0.7453\n",
            "Epoch 74/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7924 - accuracy: 0.7280 - val_loss: 0.7973 - val_accuracy: 0.7567\n",
            "Epoch 75/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7919 - accuracy: 0.7303 - val_loss: 0.7957 - val_accuracy: 0.7499\n",
            "Epoch 76/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7860 - accuracy: 0.7316 - val_loss: 0.7979 - val_accuracy: 0.7487\n",
            "Epoch 77/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7804 - accuracy: 0.7320 - val_loss: 0.7934 - val_accuracy: 0.7584\n",
            "Epoch 78/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7751 - accuracy: 0.7400 - val_loss: 0.8008 - val_accuracy: 0.7481\n",
            "Epoch 79/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7684 - accuracy: 0.7287 - val_loss: 0.7883 - val_accuracy: 0.7510\n",
            "Epoch 80/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7757 - accuracy: 0.7376 - val_loss: 0.7885 - val_accuracy: 0.7499\n",
            "Epoch 81/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7598 - accuracy: 0.7384 - val_loss: 0.7957 - val_accuracy: 0.7476\n",
            "Epoch 82/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7742 - accuracy: 0.7344 - val_loss: 0.7756 - val_accuracy: 0.7521\n",
            "Epoch 83/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7756 - accuracy: 0.7270 - val_loss: 0.7902 - val_accuracy: 0.7544\n",
            "Epoch 84/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7735 - accuracy: 0.7429 - val_loss: 0.7832 - val_accuracy: 0.7573\n",
            "Epoch 85/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7648 - accuracy: 0.7367 - val_loss: 0.7797 - val_accuracy: 0.7533\n",
            "Epoch 86/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7611 - accuracy: 0.7399 - val_loss: 0.8002 - val_accuracy: 0.7453\n",
            "Epoch 87/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7542 - accuracy: 0.7432 - val_loss: 0.8103 - val_accuracy: 0.7470\n",
            "Epoch 88/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7587 - accuracy: 0.7337 - val_loss: 0.7910 - val_accuracy: 0.7624\n",
            "Epoch 89/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7436 - accuracy: 0.7422 - val_loss: 0.7883 - val_accuracy: 0.7539\n",
            "Epoch 90/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7564 - accuracy: 0.7369 - val_loss: 0.7849 - val_accuracy: 0.7493\n",
            "Epoch 91/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7556 - accuracy: 0.7387 - val_loss: 0.7887 - val_accuracy: 0.7567\n",
            "Epoch 92/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7578 - accuracy: 0.7420 - val_loss: 0.7830 - val_accuracy: 0.7504\n",
            "Epoch 93/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7354 - accuracy: 0.7419 - val_loss: 0.7698 - val_accuracy: 0.7596\n",
            "Epoch 94/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7334 - accuracy: 0.7497 - val_loss: 0.7878 - val_accuracy: 0.7527\n",
            "Epoch 95/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7354 - accuracy: 0.7472 - val_loss: 0.7663 - val_accuracy: 0.7716\n",
            "Epoch 96/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7429 - accuracy: 0.7487 - val_loss: 0.7641 - val_accuracy: 0.7636\n",
            "Epoch 97/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7197 - accuracy: 0.7510 - val_loss: 0.7891 - val_accuracy: 0.7567\n",
            "Epoch 98/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7453 - accuracy: 0.7493 - val_loss: 0.7679 - val_accuracy: 0.7630\n",
            "Epoch 99/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.7285 - accuracy: 0.7480 - val_loss: 0.7713 - val_accuracy: 0.7676\n",
            "Epoch 100/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7308 - accuracy: 0.7429 - val_loss: 0.7743 - val_accuracy: 0.7493\n",
            "Epoch 101/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7113 - accuracy: 0.7540 - val_loss: 0.7612 - val_accuracy: 0.7659\n",
            "Epoch 102/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7413 - accuracy: 0.7419 - val_loss: 0.7875 - val_accuracy: 0.7590\n",
            "Epoch 103/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7332 - accuracy: 0.7510 - val_loss: 0.7693 - val_accuracy: 0.7584\n",
            "Epoch 104/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7164 - accuracy: 0.7497 - val_loss: 0.7704 - val_accuracy: 0.7636\n",
            "Epoch 105/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7195 - accuracy: 0.7540 - val_loss: 0.7744 - val_accuracy: 0.7613\n",
            "Epoch 106/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7343 - accuracy: 0.7500 - val_loss: 0.7751 - val_accuracy: 0.7493\n",
            "Epoch 107/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7161 - accuracy: 0.7546 - val_loss: 0.7646 - val_accuracy: 0.7607\n",
            "Epoch 108/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7254 - accuracy: 0.7473 - val_loss: 0.7680 - val_accuracy: 0.7573\n",
            "Epoch 109/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7163 - accuracy: 0.7466 - val_loss: 0.7590 - val_accuracy: 0.7607\n",
            "Epoch 110/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.7189 - accuracy: 0.7558 - val_loss: 0.7743 - val_accuracy: 0.7630\n",
            "Epoch 111/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.7099 - accuracy: 0.7569 - val_loss: 0.7693 - val_accuracy: 0.7619\n",
            "Epoch 112/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.7045 - accuracy: 0.7582 - val_loss: 0.7723 - val_accuracy: 0.7550\n",
            "Epoch 113/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.7118 - accuracy: 0.7548 - val_loss: 0.7597 - val_accuracy: 0.7607\n",
            "Epoch 114/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.6994 - accuracy: 0.7606 - val_loss: 0.7934 - val_accuracy: 0.7521\n",
            "Epoch 115/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7086 - accuracy: 0.7568 - val_loss: 0.7620 - val_accuracy: 0.7653\n",
            "Epoch 116/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7132 - accuracy: 0.7530 - val_loss: 0.7695 - val_accuracy: 0.7670\n",
            "Epoch 117/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.7625 - val_loss: 0.7686 - val_accuracy: 0.7659\n",
            "Epoch 118/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6914 - accuracy: 0.7623 - val_loss: 0.7641 - val_accuracy: 0.7596\n",
            "Epoch 119/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6959 - accuracy: 0.7619 - val_loss: 0.7705 - val_accuracy: 0.7516\n",
            "Epoch 120/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7054 - accuracy: 0.7582 - val_loss: 0.7670 - val_accuracy: 0.7665\n",
            "Epoch 121/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6898 - accuracy: 0.7678 - val_loss: 0.7509 - val_accuracy: 0.7659\n",
            "Epoch 122/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.7688 - val_loss: 0.7513 - val_accuracy: 0.7728\n",
            "Epoch 123/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6943 - accuracy: 0.7589 - val_loss: 0.7739 - val_accuracy: 0.7630\n",
            "Epoch 124/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6922 - accuracy: 0.7581 - val_loss: 0.7531 - val_accuracy: 0.7716\n",
            "Epoch 125/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.7602 - val_loss: 0.7570 - val_accuracy: 0.7728\n",
            "Epoch 126/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6788 - accuracy: 0.7664 - val_loss: 0.7543 - val_accuracy: 0.7624\n",
            "Epoch 127/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.7641 - val_loss: 0.7656 - val_accuracy: 0.7710\n",
            "Epoch 128/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6753 - accuracy: 0.7729 - val_loss: 0.7379 - val_accuracy: 0.7813\n",
            "Epoch 129/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6705 - accuracy: 0.7689 - val_loss: 0.7419 - val_accuracy: 0.7705\n",
            "Epoch 130/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6669 - accuracy: 0.7714 - val_loss: 0.7691 - val_accuracy: 0.7584\n",
            "Epoch 131/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6676 - accuracy: 0.7709 - val_loss: 0.7631 - val_accuracy: 0.7676\n",
            "Epoch 132/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6804 - accuracy: 0.7741 - val_loss: 0.7669 - val_accuracy: 0.7630\n",
            "Epoch 133/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6729 - accuracy: 0.7692 - val_loss: 0.7383 - val_accuracy: 0.7705\n",
            "Epoch 134/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.7679 - val_loss: 0.7601 - val_accuracy: 0.7670\n",
            "Epoch 135/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6696 - accuracy: 0.7689 - val_loss: 0.7515 - val_accuracy: 0.7687\n",
            "Epoch 136/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6507 - accuracy: 0.7788 - val_loss: 0.7587 - val_accuracy: 0.7562\n",
            "Epoch 137/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.7737 - val_loss: 0.7512 - val_accuracy: 0.7630\n",
            "Epoch 138/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6542 - accuracy: 0.7738 - val_loss: 0.7530 - val_accuracy: 0.7710\n",
            "Epoch 139/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6580 - accuracy: 0.7727 - val_loss: 0.7497 - val_accuracy: 0.7624\n",
            "Epoch 140/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6704 - accuracy: 0.7737 - val_loss: 0.7464 - val_accuracy: 0.7687\n",
            "Epoch 141/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6628 - accuracy: 0.7701 - val_loss: 0.7321 - val_accuracy: 0.7693\n",
            "Epoch 142/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6667 - accuracy: 0.7692 - val_loss: 0.7419 - val_accuracy: 0.7699\n",
            "Epoch 143/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6615 - accuracy: 0.7709 - val_loss: 0.7222 - val_accuracy: 0.7693\n",
            "Epoch 144/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6644 - accuracy: 0.7714 - val_loss: 0.7392 - val_accuracy: 0.7733\n",
            "Epoch 145/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6622 - accuracy: 0.7758 - val_loss: 0.7500 - val_accuracy: 0.7647\n",
            "Epoch 146/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.7843 - val_loss: 0.7473 - val_accuracy: 0.7699\n",
            "Epoch 147/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6490 - accuracy: 0.7767 - val_loss: 0.7388 - val_accuracy: 0.7739\n",
            "Epoch 148/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.7828 - val_loss: 0.7446 - val_accuracy: 0.7722\n",
            "Epoch 149/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6591 - accuracy: 0.7739 - val_loss: 0.7516 - val_accuracy: 0.7624\n",
            "Epoch 150/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6419 - accuracy: 0.7790 - val_loss: 0.7631 - val_accuracy: 0.7613\n",
            "Epoch 151/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 0.7731 - val_loss: 0.7397 - val_accuracy: 0.7739\n",
            "Epoch 152/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6346 - accuracy: 0.7772 - val_loss: 0.7471 - val_accuracy: 0.7739\n",
            "Epoch 153/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6340 - accuracy: 0.7818 - val_loss: 0.7383 - val_accuracy: 0.7705\n",
            "Epoch 154/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6422 - accuracy: 0.7798 - val_loss: 0.7561 - val_accuracy: 0.7607\n",
            "Epoch 155/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6485 - accuracy: 0.7810 - val_loss: 0.7357 - val_accuracy: 0.7785\n",
            "Epoch 156/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6408 - accuracy: 0.7834 - val_loss: 0.7240 - val_accuracy: 0.7705\n",
            "Epoch 157/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.7847 - val_loss: 0.7195 - val_accuracy: 0.7722\n",
            "Epoch 158/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6406 - accuracy: 0.7761 - val_loss: 0.7218 - val_accuracy: 0.7773\n",
            "Epoch 159/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6537 - accuracy: 0.7764 - val_loss: 0.7353 - val_accuracy: 0.7665\n",
            "Epoch 160/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.7818 - val_loss: 0.7514 - val_accuracy: 0.7642\n",
            "Epoch 161/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6495 - accuracy: 0.7774 - val_loss: 0.7361 - val_accuracy: 0.7670\n",
            "Epoch 162/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6344 - accuracy: 0.7795 - val_loss: 0.7313 - val_accuracy: 0.7705\n",
            "Epoch 163/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6266 - accuracy: 0.7804 - val_loss: 0.7134 - val_accuracy: 0.7750\n",
            "Epoch 164/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6320 - accuracy: 0.7837 - val_loss: 0.7220 - val_accuracy: 0.7808\n",
            "Epoch 165/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6296 - accuracy: 0.7804 - val_loss: 0.7375 - val_accuracy: 0.7710\n",
            "Epoch 166/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6379 - accuracy: 0.7792 - val_loss: 0.7244 - val_accuracy: 0.7705\n",
            "Epoch 167/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.7821 - val_loss: 0.7455 - val_accuracy: 0.7728\n",
            "Epoch 168/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.7811 - val_loss: 0.7448 - val_accuracy: 0.7745\n",
            "Epoch 169/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6460 - accuracy: 0.7768 - val_loss: 0.7166 - val_accuracy: 0.7796\n",
            "Epoch 170/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6356 - accuracy: 0.7775 - val_loss: 0.7478 - val_accuracy: 0.7773\n",
            "Epoch 171/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6341 - accuracy: 0.7840 - val_loss: 0.7318 - val_accuracy: 0.7682\n",
            "Epoch 172/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6160 - accuracy: 0.7868 - val_loss: 0.7611 - val_accuracy: 0.7670\n",
            "Epoch 173/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6192 - accuracy: 0.7841 - val_loss: 0.7255 - val_accuracy: 0.7705\n",
            "Epoch 174/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6306 - accuracy: 0.7857 - val_loss: 0.7157 - val_accuracy: 0.7750\n",
            "Epoch 175/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6310 - accuracy: 0.7848 - val_loss: 0.7271 - val_accuracy: 0.7687\n",
            "Epoch 176/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6129 - accuracy: 0.7880 - val_loss: 0.7474 - val_accuracy: 0.7642\n",
            "Epoch 177/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.7928 - val_loss: 0.7408 - val_accuracy: 0.7762\n",
            "Epoch 178/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6072 - accuracy: 0.7906 - val_loss: 0.7318 - val_accuracy: 0.7768\n",
            "Epoch 179/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6282 - accuracy: 0.7798 - val_loss: 0.7146 - val_accuracy: 0.7819\n",
            "Epoch 180/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6316 - accuracy: 0.7821 - val_loss: 0.7211 - val_accuracy: 0.7808\n",
            "Epoch 181/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6201 - accuracy: 0.7877 - val_loss: 0.7149 - val_accuracy: 0.7710\n",
            "Epoch 182/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6167 - accuracy: 0.7921 - val_loss: 0.7303 - val_accuracy: 0.7768\n",
            "Epoch 183/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6066 - accuracy: 0.7916 - val_loss: 0.7239 - val_accuracy: 0.7831\n",
            "Epoch 184/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.7787 - val_loss: 0.7247 - val_accuracy: 0.7722\n",
            "Epoch 185/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.7901 - val_loss: 0.7210 - val_accuracy: 0.7733\n",
            "Epoch 186/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6077 - accuracy: 0.7870 - val_loss: 0.7225 - val_accuracy: 0.7728\n",
            "Epoch 187/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6119 - accuracy: 0.7885 - val_loss: 0.7392 - val_accuracy: 0.7733\n",
            "Epoch 188/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6263 - accuracy: 0.7780 - val_loss: 0.7285 - val_accuracy: 0.7739\n",
            "Epoch 189/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6007 - accuracy: 0.7931 - val_loss: 0.7196 - val_accuracy: 0.7785\n",
            "Epoch 190/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6276 - accuracy: 0.7792 - val_loss: 0.7150 - val_accuracy: 0.7710\n",
            "Epoch 191/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5991 - accuracy: 0.7938 - val_loss: 0.7156 - val_accuracy: 0.7779\n",
            "Epoch 192/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5945 - accuracy: 0.7938 - val_loss: 0.7120 - val_accuracy: 0.7819\n",
            "Epoch 193/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5918 - accuracy: 0.7966 - val_loss: 0.7388 - val_accuracy: 0.7705\n",
            "Epoch 194/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5929 - accuracy: 0.7943 - val_loss: 0.7368 - val_accuracy: 0.7779\n",
            "Epoch 195/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6188 - accuracy: 0.7878 - val_loss: 0.7399 - val_accuracy: 0.7687\n",
            "Epoch 196/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6203 - accuracy: 0.7860 - val_loss: 0.7268 - val_accuracy: 0.7728\n",
            "Epoch 197/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5869 - accuracy: 0.7880 - val_loss: 0.7226 - val_accuracy: 0.7762\n",
            "Epoch 198/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5923 - accuracy: 0.7973 - val_loss: 0.7264 - val_accuracy: 0.7779\n",
            "Epoch 199/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.7967 - val_loss: 0.7322 - val_accuracy: 0.7813\n",
            "Epoch 200/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6068 - accuracy: 0.7916 - val_loss: 0.7381 - val_accuracy: 0.7670\n",
            "Epoch 201/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5893 - accuracy: 0.7926 - val_loss: 0.7310 - val_accuracy: 0.7728\n",
            "Epoch 202/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.7918 - val_loss: 0.7089 - val_accuracy: 0.7750\n",
            "Epoch 203/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5803 - accuracy: 0.8044 - val_loss: 0.7398 - val_accuracy: 0.7716\n",
            "Epoch 204/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5996 - accuracy: 0.7948 - val_loss: 0.7302 - val_accuracy: 0.7802\n",
            "Epoch 205/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.7917 - val_loss: 0.7202 - val_accuracy: 0.7756\n",
            "Epoch 206/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5929 - accuracy: 0.7946 - val_loss: 0.7549 - val_accuracy: 0.7665\n",
            "Epoch 207/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6021 - accuracy: 0.7967 - val_loss: 0.7255 - val_accuracy: 0.7785\n",
            "Epoch 208/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5764 - accuracy: 0.7977 - val_loss: 0.7215 - val_accuracy: 0.7773\n",
            "Epoch 209/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5997 - accuracy: 0.7910 - val_loss: 0.7052 - val_accuracy: 0.7836\n",
            "Epoch 210/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6106 - accuracy: 0.7918 - val_loss: 0.7311 - val_accuracy: 0.7676\n",
            "Epoch 211/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5899 - accuracy: 0.7967 - val_loss: 0.7014 - val_accuracy: 0.7762\n",
            "Epoch 212/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5955 - accuracy: 0.7950 - val_loss: 0.7070 - val_accuracy: 0.7756\n",
            "Epoch 213/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5939 - accuracy: 0.8017 - val_loss: 0.7148 - val_accuracy: 0.7745\n",
            "Epoch 214/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5865 - accuracy: 0.8013 - val_loss: 0.7178 - val_accuracy: 0.7762\n",
            "Epoch 215/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5884 - accuracy: 0.7991 - val_loss: 0.7176 - val_accuracy: 0.7779\n",
            "Epoch 216/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5859 - accuracy: 0.7943 - val_loss: 0.6997 - val_accuracy: 0.7859\n",
            "Epoch 217/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5940 - accuracy: 0.7941 - val_loss: 0.7166 - val_accuracy: 0.7750\n",
            "Epoch 218/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5795 - accuracy: 0.8044 - val_loss: 0.7216 - val_accuracy: 0.7739\n",
            "Epoch 219/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5841 - accuracy: 0.8031 - val_loss: 0.7135 - val_accuracy: 0.7876\n",
            "Epoch 220/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.8060 - val_loss: 0.7144 - val_accuracy: 0.7773\n",
            "Epoch 221/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.7989 - val_loss: 0.7083 - val_accuracy: 0.7894\n",
            "Epoch 222/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5748 - accuracy: 0.8017 - val_loss: 0.7226 - val_accuracy: 0.7819\n",
            "Epoch 223/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5914 - accuracy: 0.7976 - val_loss: 0.7117 - val_accuracy: 0.7894\n",
            "Epoch 224/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5821 - accuracy: 0.7960 - val_loss: 0.7207 - val_accuracy: 0.7790\n",
            "Epoch 225/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.7967 - val_loss: 0.7283 - val_accuracy: 0.7853\n",
            "Epoch 226/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5681 - accuracy: 0.8024 - val_loss: 0.7241 - val_accuracy: 0.7859\n",
            "Epoch 227/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5750 - accuracy: 0.8036 - val_loss: 0.7259 - val_accuracy: 0.7802\n",
            "Epoch 228/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5812 - accuracy: 0.8024 - val_loss: 0.7106 - val_accuracy: 0.7819\n",
            "Epoch 229/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.7938 - val_loss: 0.7152 - val_accuracy: 0.7762\n",
            "Epoch 230/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.8057 - val_loss: 0.7453 - val_accuracy: 0.7728\n",
            "Epoch 231/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5851 - accuracy: 0.8006 - val_loss: 0.7084 - val_accuracy: 0.7842\n",
            "Epoch 232/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5463 - accuracy: 0.8139 - val_loss: 0.7300 - val_accuracy: 0.7831\n",
            "Epoch 233/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5553 - accuracy: 0.8076 - val_loss: 0.7455 - val_accuracy: 0.7745\n",
            "Epoch 234/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5958 - accuracy: 0.7931 - val_loss: 0.7419 - val_accuracy: 0.7768\n",
            "Epoch 235/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5488 - accuracy: 0.8074 - val_loss: 0.7092 - val_accuracy: 0.7785\n",
            "Epoch 236/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5580 - accuracy: 0.8067 - val_loss: 0.7392 - val_accuracy: 0.7762\n",
            "Epoch 237/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5705 - accuracy: 0.8054 - val_loss: 0.7146 - val_accuracy: 0.7853\n",
            "Epoch 238/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5579 - accuracy: 0.8072 - val_loss: 0.7205 - val_accuracy: 0.7733\n",
            "Epoch 239/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.8084 - val_loss: 0.7274 - val_accuracy: 0.7911\n",
            "Epoch 240/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5800 - accuracy: 0.7941 - val_loss: 0.7152 - val_accuracy: 0.7922\n",
            "Epoch 241/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5774 - accuracy: 0.8001 - val_loss: 0.7270 - val_accuracy: 0.7905\n",
            "Epoch 242/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5793 - accuracy: 0.8030 - val_loss: 0.7054 - val_accuracy: 0.7842\n",
            "Epoch 243/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5550 - accuracy: 0.8042 - val_loss: 0.7072 - val_accuracy: 0.7888\n",
            "Epoch 244/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5629 - accuracy: 0.8036 - val_loss: 0.7170 - val_accuracy: 0.7848\n",
            "Epoch 245/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.7950 - val_loss: 0.7326 - val_accuracy: 0.7808\n",
            "Epoch 246/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.8053 - val_loss: 0.6996 - val_accuracy: 0.7871\n",
            "Epoch 247/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5521 - accuracy: 0.8094 - val_loss: 0.7243 - val_accuracy: 0.7836\n",
            "Epoch 248/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5597 - accuracy: 0.8123 - val_loss: 0.6991 - val_accuracy: 0.7876\n",
            "Epoch 249/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5811 - accuracy: 0.8006 - val_loss: 0.6993 - val_accuracy: 0.7842\n",
            "Epoch 250/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5573 - accuracy: 0.8135 - val_loss: 0.7085 - val_accuracy: 0.7859\n",
            "Epoch 251/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5539 - accuracy: 0.8093 - val_loss: 0.7201 - val_accuracy: 0.7819\n",
            "Epoch 252/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5556 - accuracy: 0.8074 - val_loss: 0.6961 - val_accuracy: 0.7888\n",
            "Epoch 253/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.8036 - val_loss: 0.7003 - val_accuracy: 0.7899\n",
            "Epoch 254/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5580 - accuracy: 0.8119 - val_loss: 0.7046 - val_accuracy: 0.7882\n",
            "Epoch 255/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.8084 - val_loss: 0.7217 - val_accuracy: 0.7796\n",
            "Epoch 256/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.8054 - val_loss: 0.7123 - val_accuracy: 0.7773\n",
            "Epoch 257/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.8027 - val_loss: 0.7068 - val_accuracy: 0.7836\n",
            "Epoch 258/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5463 - accuracy: 0.8136 - val_loss: 0.7281 - val_accuracy: 0.7779\n",
            "Epoch 259/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.8092 - val_loss: 0.7156 - val_accuracy: 0.7728\n",
            "Epoch 260/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.8074 - val_loss: 0.7147 - val_accuracy: 0.7808\n",
            "Epoch 261/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5545 - accuracy: 0.8122 - val_loss: 0.7056 - val_accuracy: 0.7882\n",
            "Epoch 262/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.8107 - val_loss: 0.6946 - val_accuracy: 0.7876\n",
            "Epoch 263/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5486 - accuracy: 0.8135 - val_loss: 0.7159 - val_accuracy: 0.7808\n",
            "Epoch 264/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5712 - accuracy: 0.8056 - val_loss: 0.7021 - val_accuracy: 0.7836\n",
            "Epoch 265/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.8115 - val_loss: 0.7193 - val_accuracy: 0.7768\n",
            "Epoch 266/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5469 - accuracy: 0.8125 - val_loss: 0.7112 - val_accuracy: 0.7871\n",
            "Epoch 267/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5571 - accuracy: 0.8099 - val_loss: 0.7101 - val_accuracy: 0.7871\n",
            "Epoch 268/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5585 - accuracy: 0.8070 - val_loss: 0.7019 - val_accuracy: 0.7871\n",
            "Epoch 269/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.8176 - val_loss: 0.7141 - val_accuracy: 0.7808\n",
            "Epoch 270/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.8102 - val_loss: 0.7207 - val_accuracy: 0.7882\n",
            "Epoch 271/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.8107 - val_loss: 0.6974 - val_accuracy: 0.7819\n",
            "Epoch 272/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5461 - accuracy: 0.8117 - val_loss: 0.7330 - val_accuracy: 0.7882\n",
            "Epoch 273/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.8077 - val_loss: 0.7275 - val_accuracy: 0.7779\n",
            "Epoch 274/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.8166 - val_loss: 0.7106 - val_accuracy: 0.7871\n",
            "Epoch 275/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.8092 - val_loss: 0.7194 - val_accuracy: 0.7853\n",
            "Epoch 276/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5551 - accuracy: 0.8115 - val_loss: 0.7143 - val_accuracy: 0.7899\n",
            "Epoch 277/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.8183 - val_loss: 0.7276 - val_accuracy: 0.7802\n",
            "Epoch 278/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.8130 - val_loss: 0.7165 - val_accuracy: 0.7796\n",
            "Epoch 279/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.8143 - val_loss: 0.7227 - val_accuracy: 0.7745\n",
            "Epoch 280/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.8107 - val_loss: 0.7147 - val_accuracy: 0.7750\n",
            "Epoch 281/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.8119 - val_loss: 0.7099 - val_accuracy: 0.7768\n",
            "Epoch 282/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5461 - accuracy: 0.8129 - val_loss: 0.7123 - val_accuracy: 0.7779\n",
            "Epoch 283/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5480 - accuracy: 0.8100 - val_loss: 0.7147 - val_accuracy: 0.7871\n",
            "Epoch 284/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.8137 - val_loss: 0.7324 - val_accuracy: 0.7773\n",
            "Epoch 285/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5480 - accuracy: 0.8200 - val_loss: 0.7341 - val_accuracy: 0.7825\n",
            "Epoch 286/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.8206 - val_loss: 0.7429 - val_accuracy: 0.7790\n",
            "Epoch 287/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5464 - accuracy: 0.8140 - val_loss: 0.7352 - val_accuracy: 0.7825\n",
            "Epoch 288/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.8175 - val_loss: 0.7279 - val_accuracy: 0.7865\n",
            "Epoch 289/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.8149 - val_loss: 0.7185 - val_accuracy: 0.7808\n",
            "Epoch 290/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.8127 - val_loss: 0.7231 - val_accuracy: 0.7865\n",
            "Epoch 291/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.8137 - val_loss: 0.7059 - val_accuracy: 0.7825\n",
            "Epoch 292/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.8180 - val_loss: 0.7200 - val_accuracy: 0.7790\n",
            "Epoch 293/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.8125 - val_loss: 0.7101 - val_accuracy: 0.7865\n",
            "Epoch 294/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5595 - accuracy: 0.8033 - val_loss: 0.7220 - val_accuracy: 0.7768\n",
            "Epoch 295/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5375 - accuracy: 0.8112 - val_loss: 0.7401 - val_accuracy: 0.7768\n",
            "Epoch 296/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.8168 - val_loss: 0.7223 - val_accuracy: 0.7813\n",
            "Epoch 297/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.8123 - val_loss: 0.7318 - val_accuracy: 0.7802\n",
            "Epoch 298/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.8193 - val_loss: 0.7216 - val_accuracy: 0.7894\n",
            "Epoch 299/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.8155 - val_loss: 0.7149 - val_accuracy: 0.7871\n",
            "Epoch 300/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5489 - accuracy: 0.8136 - val_loss: 0.6968 - val_accuracy: 0.7905\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe800604c10>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "                                #filter sayisi #kernel_size\n",
        "model.add(tf.keras.layers.Conv1D(16,2, activation ='relu', input_shape= (20, 1)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "              #noron sayisi\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "#dropoutlar 0 ile 1 arasinda olcak\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32))\n",
        "\n",
        "            #burayi degistirmeyin\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=\"Adam\",loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])\n",
        "\n",
        "num_epochs = 300\n",
        "num_batch_size = 256\n",
        "\n",
        "model.fit(\n",
        "          x_train, \n",
        "          y_train, \n",
        "          batch_size=num_batch_size, \n",
        "          epochs=num_epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[callbacks]\n",
        "         )"
      ],
      "metadata": {
        "id": "ZXz4elNBpfha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "656dd097-e6c3-41e9-d9b5-fd7054eb54ed"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_15 (Conv1D)          (None, 19, 16)            48        \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 304)               0         \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 64)                19520     \n",
            "                                                                 \n",
            " activation_48 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " activation_49 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " activation_50 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_64 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            " activation_51 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38,554\n",
            "Trainable params: 38,554\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 11ms/step - loss: 2.2646 - accuracy: 0.1419 - val_loss: 2.1807 - val_accuracy: 0.2278\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2.1029 - accuracy: 0.2200 - val_loss: 1.9004 - val_accuracy: 0.3108\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.8898 - accuracy: 0.2870 - val_loss: 1.7525 - val_accuracy: 0.3789\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.8005 - accuracy: 0.3268 - val_loss: 1.6703 - val_accuracy: 0.3721\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.7106 - accuracy: 0.3689 - val_loss: 1.6136 - val_accuracy: 0.4196\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.6719 - accuracy: 0.3969 - val_loss: 1.5677 - val_accuracy: 0.4310\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.6199 - accuracy: 0.4072 - val_loss: 1.5358 - val_accuracy: 0.4476\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.6040 - accuracy: 0.4157 - val_loss: 1.5187 - val_accuracy: 0.4562\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.5757 - accuracy: 0.4346 - val_loss: 1.4792 - val_accuracy: 0.4717\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.5547 - accuracy: 0.4384 - val_loss: 1.4622 - val_accuracy: 0.4705\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.5339 - accuracy: 0.4545 - val_loss: 1.4504 - val_accuracy: 0.4797\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.5100 - accuracy: 0.4610 - val_loss: 1.4218 - val_accuracy: 0.5072\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.4872 - accuracy: 0.4724 - val_loss: 1.3942 - val_accuracy: 0.5180\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.4622 - accuracy: 0.4776 - val_loss: 1.3884 - val_accuracy: 0.5266\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.4517 - accuracy: 0.4868 - val_loss: 1.3709 - val_accuracy: 0.5329\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.4356 - accuracy: 0.4966 - val_loss: 1.3484 - val_accuracy: 0.5501\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.4182 - accuracy: 0.5028 - val_loss: 1.3262 - val_accuracy: 0.5381\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.3936 - accuracy: 0.5099 - val_loss: 1.3229 - val_accuracy: 0.5484\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.3785 - accuracy: 0.5183 - val_loss: 1.2935 - val_accuracy: 0.5472\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.3655 - accuracy: 0.5247 - val_loss: 1.2769 - val_accuracy: 0.5598\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.3437 - accuracy: 0.5291 - val_loss: 1.2826 - val_accuracy: 0.5661\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.3432 - accuracy: 0.5284 - val_loss: 1.2466 - val_accuracy: 0.5839\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.3258 - accuracy: 0.5424 - val_loss: 1.2373 - val_accuracy: 0.5827\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1.3140 - accuracy: 0.5399 - val_loss: 1.2150 - val_accuracy: 0.5959\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.2928 - accuracy: 0.5603 - val_loss: 1.2045 - val_accuracy: 0.5976\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.2864 - accuracy: 0.5530 - val_loss: 1.1940 - val_accuracy: 0.6033\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.2641 - accuracy: 0.5651 - val_loss: 1.1923 - val_accuracy: 0.6062\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.2511 - accuracy: 0.5702 - val_loss: 1.1760 - val_accuracy: 0.6096\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.2405 - accuracy: 0.5711 - val_loss: 1.1586 - val_accuracy: 0.6119\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.2247 - accuracy: 0.5817 - val_loss: 1.1356 - val_accuracy: 0.6279\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.2181 - accuracy: 0.5850 - val_loss: 1.1409 - val_accuracy: 0.6165\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.2131 - accuracy: 0.5794 - val_loss: 1.1249 - val_accuracy: 0.6377\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.2071 - accuracy: 0.5863 - val_loss: 1.1008 - val_accuracy: 0.6348\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 1.1937 - accuracy: 0.5943 - val_loss: 1.0989 - val_accuracy: 0.6445\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.1764 - accuracy: 0.5963 - val_loss: 1.1043 - val_accuracy: 0.6468\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.1685 - accuracy: 0.6073 - val_loss: 1.0820 - val_accuracy: 0.6503\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.1536 - accuracy: 0.6044 - val_loss: 1.0846 - val_accuracy: 0.6514\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.1487 - accuracy: 0.6170 - val_loss: 1.0608 - val_accuracy: 0.6560\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.1274 - accuracy: 0.6149 - val_loss: 1.0509 - val_accuracy: 0.6657\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.1305 - accuracy: 0.6213 - val_loss: 1.0479 - val_accuracy: 0.6606\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 1.1348 - accuracy: 0.6125 - val_loss: 1.0561 - val_accuracy: 0.6629\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.1001 - accuracy: 0.6288 - val_loss: 1.0366 - val_accuracy: 0.6651\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1.0956 - accuracy: 0.6334 - val_loss: 1.0344 - val_accuracy: 0.6680\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.0895 - accuracy: 0.6362 - val_loss: 1.0202 - val_accuracy: 0.6709\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1.0914 - accuracy: 0.6306 - val_loss: 1.0182 - val_accuracy: 0.6697\n",
            "Epoch 46/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.0889 - accuracy: 0.6342 - val_loss: 1.0096 - val_accuracy: 0.6697\n",
            "Epoch 47/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.0786 - accuracy: 0.6388 - val_loss: 1.0136 - val_accuracy: 0.6743\n",
            "Epoch 48/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.0689 - accuracy: 0.6437 - val_loss: 0.9942 - val_accuracy: 0.6777\n",
            "Epoch 49/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.0512 - accuracy: 0.6451 - val_loss: 1.0001 - val_accuracy: 0.6766\n",
            "Epoch 50/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.0503 - accuracy: 0.6418 - val_loss: 0.9823 - val_accuracy: 0.6737\n",
            "Epoch 51/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.0414 - accuracy: 0.6447 - val_loss: 0.9960 - val_accuracy: 0.6743\n",
            "Epoch 52/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1.0375 - accuracy: 0.6510 - val_loss: 0.9764 - val_accuracy: 0.6857\n",
            "Epoch 53/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.0306 - accuracy: 0.6530 - val_loss: 0.9797 - val_accuracy: 0.6749\n",
            "Epoch 54/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.0290 - accuracy: 0.6490 - val_loss: 0.9745 - val_accuracy: 0.6806\n",
            "Epoch 55/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.0090 - accuracy: 0.6573 - val_loss: 0.9686 - val_accuracy: 0.6829\n",
            "Epoch 56/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.0142 - accuracy: 0.6618 - val_loss: 0.9601 - val_accuracy: 0.6915\n",
            "Epoch 57/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.0233 - accuracy: 0.6531 - val_loss: 0.9551 - val_accuracy: 0.6926\n",
            "Epoch 58/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.9831 - accuracy: 0.6588 - val_loss: 0.9547 - val_accuracy: 0.6886\n",
            "Epoch 59/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.9976 - accuracy: 0.6616 - val_loss: 0.9483 - val_accuracy: 0.6903\n",
            "Epoch 60/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.9893 - accuracy: 0.6651 - val_loss: 0.9574 - val_accuracy: 0.6938\n",
            "Epoch 61/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.9822 - accuracy: 0.6706 - val_loss: 0.9422 - val_accuracy: 0.7012\n",
            "Epoch 62/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.9801 - accuracy: 0.6660 - val_loss: 0.9470 - val_accuracy: 0.6938\n",
            "Epoch 63/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.9781 - accuracy: 0.6713 - val_loss: 0.9328 - val_accuracy: 0.7064\n",
            "Epoch 64/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.9877 - accuracy: 0.6621 - val_loss: 0.9357 - val_accuracy: 0.7018\n",
            "Epoch 65/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.9667 - accuracy: 0.6760 - val_loss: 0.9194 - val_accuracy: 0.7041\n",
            "Epoch 66/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.9592 - accuracy: 0.6719 - val_loss: 0.9254 - val_accuracy: 0.7046\n",
            "Epoch 67/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.9711 - accuracy: 0.6732 - val_loss: 0.9309 - val_accuracy: 0.6995\n",
            "Epoch 68/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.9554 - accuracy: 0.6740 - val_loss: 0.9189 - val_accuracy: 0.7035\n",
            "Epoch 69/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.9440 - accuracy: 0.6766 - val_loss: 0.9154 - val_accuracy: 0.7081\n",
            "Epoch 70/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.9481 - accuracy: 0.6727 - val_loss: 0.9141 - val_accuracy: 0.7109\n",
            "Epoch 71/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.9516 - accuracy: 0.6752 - val_loss: 0.9125 - val_accuracy: 0.7029\n",
            "Epoch 72/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.9381 - accuracy: 0.6803 - val_loss: 0.9054 - val_accuracy: 0.7046\n",
            "Epoch 73/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.9387 - accuracy: 0.6823 - val_loss: 0.9072 - val_accuracy: 0.7035\n",
            "Epoch 74/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.9397 - accuracy: 0.6835 - val_loss: 0.8987 - val_accuracy: 0.7075\n",
            "Epoch 75/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.9282 - accuracy: 0.6863 - val_loss: 0.9108 - val_accuracy: 0.7046\n",
            "Epoch 76/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.9287 - accuracy: 0.6809 - val_loss: 0.9045 - val_accuracy: 0.7064\n",
            "Epoch 77/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.9312 - accuracy: 0.6796 - val_loss: 0.8933 - val_accuracy: 0.7127\n",
            "Epoch 78/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.9187 - accuracy: 0.6870 - val_loss: 0.9031 - val_accuracy: 0.7058\n",
            "Epoch 79/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.9242 - accuracy: 0.6911 - val_loss: 0.9079 - val_accuracy: 0.7127\n",
            "Epoch 80/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.9349 - accuracy: 0.6803 - val_loss: 0.8843 - val_accuracy: 0.7167\n",
            "Epoch 81/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.9194 - accuracy: 0.6898 - val_loss: 0.9018 - val_accuracy: 0.7046\n",
            "Epoch 82/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.9308 - accuracy: 0.6912 - val_loss: 0.8859 - val_accuracy: 0.7155\n",
            "Epoch 83/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.9164 - accuracy: 0.6890 - val_loss: 0.8923 - val_accuracy: 0.7127\n",
            "Epoch 84/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.9051 - accuracy: 0.6938 - val_loss: 0.8951 - val_accuracy: 0.7069\n",
            "Epoch 85/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.9057 - accuracy: 0.6915 - val_loss: 0.8824 - val_accuracy: 0.7144\n",
            "Epoch 86/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - accuracy: 0.6998 - val_loss: 0.8767 - val_accuracy: 0.7178\n",
            "Epoch 87/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8887 - accuracy: 0.6949 - val_loss: 0.8717 - val_accuracy: 0.7155\n",
            "Epoch 88/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - accuracy: 0.6982 - val_loss: 0.8820 - val_accuracy: 0.7167\n",
            "Epoch 89/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.8999 - accuracy: 0.6992 - val_loss: 0.8643 - val_accuracy: 0.7235\n",
            "Epoch 90/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.9060 - accuracy: 0.6949 - val_loss: 0.8675 - val_accuracy: 0.7212\n",
            "Epoch 91/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8968 - accuracy: 0.6968 - val_loss: 0.8751 - val_accuracy: 0.7212\n",
            "Epoch 92/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8610 - accuracy: 0.7092 - val_loss: 0.8554 - val_accuracy: 0.7230\n",
            "Epoch 93/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8768 - accuracy: 0.7067 - val_loss: 0.8660 - val_accuracy: 0.7235\n",
            "Epoch 94/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.8878 - accuracy: 0.6994 - val_loss: 0.8597 - val_accuracy: 0.7241\n",
            "Epoch 95/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8797 - accuracy: 0.7044 - val_loss: 0.8528 - val_accuracy: 0.7235\n",
            "Epoch 96/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8537 - accuracy: 0.7104 - val_loss: 0.8654 - val_accuracy: 0.7212\n",
            "Epoch 97/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.8664 - accuracy: 0.7095 - val_loss: 0.8629 - val_accuracy: 0.7235\n",
            "Epoch 98/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8759 - accuracy: 0.6995 - val_loss: 0.8609 - val_accuracy: 0.7167\n",
            "Epoch 99/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8771 - accuracy: 0.7022 - val_loss: 0.8550 - val_accuracy: 0.7195\n",
            "Epoch 100/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8532 - accuracy: 0.7061 - val_loss: 0.8555 - val_accuracy: 0.7172\n",
            "Epoch 101/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.8508 - accuracy: 0.7108 - val_loss: 0.8485 - val_accuracy: 0.7264\n",
            "Epoch 102/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8544 - accuracy: 0.7085 - val_loss: 0.8509 - val_accuracy: 0.7178\n",
            "Epoch 103/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.8609 - accuracy: 0.7099 - val_loss: 0.8383 - val_accuracy: 0.7333\n",
            "Epoch 104/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.8575 - accuracy: 0.7102 - val_loss: 0.8522 - val_accuracy: 0.7218\n",
            "Epoch 105/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.8375 - accuracy: 0.7147 - val_loss: 0.8654 - val_accuracy: 0.7207\n",
            "Epoch 106/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8530 - accuracy: 0.7167 - val_loss: 0.8608 - val_accuracy: 0.7218\n",
            "Epoch 107/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8424 - accuracy: 0.7111 - val_loss: 0.8374 - val_accuracy: 0.7298\n",
            "Epoch 108/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.8470 - accuracy: 0.7142 - val_loss: 0.8533 - val_accuracy: 0.7258\n",
            "Epoch 109/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8356 - accuracy: 0.7147 - val_loss: 0.8521 - val_accuracy: 0.7275\n",
            "Epoch 110/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8278 - accuracy: 0.7205 - val_loss: 0.8348 - val_accuracy: 0.7264\n",
            "Epoch 111/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8196 - accuracy: 0.7183 - val_loss: 0.8475 - val_accuracy: 0.7247\n",
            "Epoch 112/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8495 - accuracy: 0.7140 - val_loss: 0.8385 - val_accuracy: 0.7264\n",
            "Epoch 113/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8303 - accuracy: 0.7205 - val_loss: 0.8428 - val_accuracy: 0.7287\n",
            "Epoch 114/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8316 - accuracy: 0.7170 - val_loss: 0.8363 - val_accuracy: 0.7298\n",
            "Epoch 115/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8468 - accuracy: 0.7170 - val_loss: 0.8412 - val_accuracy: 0.7344\n",
            "Epoch 116/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.8290 - accuracy: 0.7251 - val_loss: 0.8399 - val_accuracy: 0.7287\n",
            "Epoch 117/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.8269 - accuracy: 0.7193 - val_loss: 0.8428 - val_accuracy: 0.7378\n",
            "Epoch 118/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8229 - accuracy: 0.7218 - val_loss: 0.8244 - val_accuracy: 0.7378\n",
            "Epoch 119/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8258 - accuracy: 0.7190 - val_loss: 0.8435 - val_accuracy: 0.7258\n",
            "Epoch 120/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8205 - accuracy: 0.7161 - val_loss: 0.8326 - val_accuracy: 0.7355\n",
            "Epoch 121/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8172 - accuracy: 0.7254 - val_loss: 0.8293 - val_accuracy: 0.7355\n",
            "Epoch 122/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8114 - accuracy: 0.7276 - val_loss: 0.8281 - val_accuracy: 0.7315\n",
            "Epoch 123/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8109 - accuracy: 0.7300 - val_loss: 0.8227 - val_accuracy: 0.7355\n",
            "Epoch 124/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8174 - accuracy: 0.7174 - val_loss: 0.8127 - val_accuracy: 0.7344\n",
            "Epoch 125/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8012 - accuracy: 0.7260 - val_loss: 0.8314 - val_accuracy: 0.7350\n",
            "Epoch 126/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7986 - accuracy: 0.7281 - val_loss: 0.8135 - val_accuracy: 0.7373\n",
            "Epoch 127/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8094 - accuracy: 0.7276 - val_loss: 0.8223 - val_accuracy: 0.7401\n",
            "Epoch 128/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8004 - accuracy: 0.7310 - val_loss: 0.8114 - val_accuracy: 0.7418\n",
            "Epoch 129/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8037 - accuracy: 0.7246 - val_loss: 0.8070 - val_accuracy: 0.7396\n",
            "Epoch 130/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8087 - accuracy: 0.7336 - val_loss: 0.8216 - val_accuracy: 0.7401\n",
            "Epoch 131/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8000 - accuracy: 0.7337 - val_loss: 0.8096 - val_accuracy: 0.7481\n",
            "Epoch 132/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7756 - accuracy: 0.7364 - val_loss: 0.8077 - val_accuracy: 0.7413\n",
            "Epoch 133/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7807 - accuracy: 0.7346 - val_loss: 0.8062 - val_accuracy: 0.7396\n",
            "Epoch 134/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7873 - accuracy: 0.7330 - val_loss: 0.8145 - val_accuracy: 0.7367\n",
            "Epoch 135/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7881 - accuracy: 0.7361 - val_loss: 0.8176 - val_accuracy: 0.7287\n",
            "Epoch 136/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7951 - accuracy: 0.7304 - val_loss: 0.8107 - val_accuracy: 0.7373\n",
            "Epoch 137/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8004 - accuracy: 0.7286 - val_loss: 0.7926 - val_accuracy: 0.7418\n",
            "Epoch 138/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7968 - accuracy: 0.7263 - val_loss: 0.8070 - val_accuracy: 0.7407\n",
            "Epoch 139/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7730 - accuracy: 0.7386 - val_loss: 0.8015 - val_accuracy: 0.7407\n",
            "Epoch 140/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7687 - accuracy: 0.7382 - val_loss: 0.8294 - val_accuracy: 0.7298\n",
            "Epoch 141/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7722 - accuracy: 0.7386 - val_loss: 0.7962 - val_accuracy: 0.7470\n",
            "Epoch 142/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7783 - accuracy: 0.7333 - val_loss: 0.7985 - val_accuracy: 0.7447\n",
            "Epoch 143/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7714 - accuracy: 0.7410 - val_loss: 0.8066 - val_accuracy: 0.7367\n",
            "Epoch 144/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7749 - accuracy: 0.7296 - val_loss: 0.8026 - val_accuracy: 0.7413\n",
            "Epoch 145/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7570 - accuracy: 0.7420 - val_loss: 0.8041 - val_accuracy: 0.7447\n",
            "Epoch 146/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7655 - accuracy: 0.7419 - val_loss: 0.7942 - val_accuracy: 0.7413\n",
            "Epoch 147/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7716 - accuracy: 0.7393 - val_loss: 0.7892 - val_accuracy: 0.7476\n",
            "Epoch 148/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7576 - accuracy: 0.7383 - val_loss: 0.7888 - val_accuracy: 0.7487\n",
            "Epoch 149/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7665 - accuracy: 0.7372 - val_loss: 0.7919 - val_accuracy: 0.7516\n",
            "Epoch 150/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7563 - accuracy: 0.7387 - val_loss: 0.7864 - val_accuracy: 0.7487\n",
            "Epoch 151/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7551 - accuracy: 0.7412 - val_loss: 0.7908 - val_accuracy: 0.7527\n",
            "Epoch 152/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7623 - accuracy: 0.7460 - val_loss: 0.7964 - val_accuracy: 0.7470\n",
            "Epoch 153/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7599 - accuracy: 0.7407 - val_loss: 0.7895 - val_accuracy: 0.7407\n",
            "Epoch 154/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7478 - accuracy: 0.7483 - val_loss: 0.8230 - val_accuracy: 0.7384\n",
            "Epoch 155/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7629 - accuracy: 0.7417 - val_loss: 0.7948 - val_accuracy: 0.7521\n",
            "Epoch 156/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7624 - accuracy: 0.7446 - val_loss: 0.7843 - val_accuracy: 0.7510\n",
            "Epoch 157/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7473 - accuracy: 0.7456 - val_loss: 0.7809 - val_accuracy: 0.7539\n",
            "Epoch 158/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7656 - accuracy: 0.7394 - val_loss: 0.8116 - val_accuracy: 0.7396\n",
            "Epoch 159/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7475 - accuracy: 0.7509 - val_loss: 0.7820 - val_accuracy: 0.7487\n",
            "Epoch 160/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7473 - accuracy: 0.7493 - val_loss: 0.7836 - val_accuracy: 0.7499\n",
            "Epoch 161/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7616 - accuracy: 0.7427 - val_loss: 0.7912 - val_accuracy: 0.7510\n",
            "Epoch 162/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7550 - accuracy: 0.7432 - val_loss: 0.7960 - val_accuracy: 0.7533\n",
            "Epoch 163/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7603 - accuracy: 0.7447 - val_loss: 0.7858 - val_accuracy: 0.7516\n",
            "Epoch 164/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7411 - accuracy: 0.7479 - val_loss: 0.7756 - val_accuracy: 0.7539\n",
            "Epoch 165/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7582 - accuracy: 0.7439 - val_loss: 0.7820 - val_accuracy: 0.7579\n",
            "Epoch 166/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7442 - accuracy: 0.7485 - val_loss: 0.7760 - val_accuracy: 0.7596\n",
            "Epoch 167/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7475 - accuracy: 0.7437 - val_loss: 0.7830 - val_accuracy: 0.7510\n",
            "Epoch 168/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7385 - accuracy: 0.7452 - val_loss: 0.7777 - val_accuracy: 0.7533\n",
            "Epoch 169/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7353 - accuracy: 0.7532 - val_loss: 0.7868 - val_accuracy: 0.7562\n",
            "Epoch 170/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7520 - accuracy: 0.7493 - val_loss: 0.7788 - val_accuracy: 0.7521\n",
            "Epoch 171/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7318 - accuracy: 0.7560 - val_loss: 0.7715 - val_accuracy: 0.7562\n",
            "Epoch 172/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7543 - accuracy: 0.7467 - val_loss: 0.7821 - val_accuracy: 0.7567\n",
            "Epoch 173/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7358 - accuracy: 0.7512 - val_loss: 0.7808 - val_accuracy: 0.7596\n",
            "Epoch 174/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7456 - accuracy: 0.7523 - val_loss: 0.7675 - val_accuracy: 0.7630\n",
            "Epoch 175/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7381 - accuracy: 0.7495 - val_loss: 0.7769 - val_accuracy: 0.7596\n",
            "Epoch 176/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7241 - accuracy: 0.7545 - val_loss: 0.7761 - val_accuracy: 0.7556\n",
            "Epoch 177/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7178 - accuracy: 0.7619 - val_loss: 0.7846 - val_accuracy: 0.7539\n",
            "Epoch 178/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7396 - accuracy: 0.7470 - val_loss: 0.7711 - val_accuracy: 0.7636\n",
            "Epoch 179/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7163 - accuracy: 0.7634 - val_loss: 0.7752 - val_accuracy: 0.7602\n",
            "Epoch 180/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7233 - accuracy: 0.7533 - val_loss: 0.7772 - val_accuracy: 0.7584\n",
            "Epoch 181/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7338 - accuracy: 0.7530 - val_loss: 0.7740 - val_accuracy: 0.7636\n",
            "Epoch 182/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7108 - accuracy: 0.7605 - val_loss: 0.7921 - val_accuracy: 0.7527\n",
            "Epoch 183/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7170 - accuracy: 0.7566 - val_loss: 0.7712 - val_accuracy: 0.7607\n",
            "Epoch 184/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7272 - accuracy: 0.7599 - val_loss: 0.7729 - val_accuracy: 0.7590\n",
            "Epoch 185/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7366 - accuracy: 0.7490 - val_loss: 0.7818 - val_accuracy: 0.7584\n",
            "Epoch 186/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7222 - accuracy: 0.7526 - val_loss: 0.7723 - val_accuracy: 0.7630\n",
            "Epoch 187/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7308 - accuracy: 0.7496 - val_loss: 0.7833 - val_accuracy: 0.7607\n",
            "Epoch 188/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7112 - accuracy: 0.7593 - val_loss: 0.7850 - val_accuracy: 0.7596\n",
            "Epoch 189/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7131 - accuracy: 0.7546 - val_loss: 0.7679 - val_accuracy: 0.7613\n",
            "Epoch 190/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7156 - accuracy: 0.7651 - val_loss: 0.7646 - val_accuracy: 0.7676\n",
            "Epoch 191/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7087 - accuracy: 0.7601 - val_loss: 0.7619 - val_accuracy: 0.7613\n",
            "Epoch 192/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7067 - accuracy: 0.7538 - val_loss: 0.7659 - val_accuracy: 0.7670\n",
            "Epoch 193/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7201 - accuracy: 0.7619 - val_loss: 0.7757 - val_accuracy: 0.7630\n",
            "Epoch 194/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7086 - accuracy: 0.7715 - val_loss: 0.7695 - val_accuracy: 0.7579\n",
            "Epoch 195/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6883 - accuracy: 0.7658 - val_loss: 0.7745 - val_accuracy: 0.7573\n",
            "Epoch 196/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6904 - accuracy: 0.7638 - val_loss: 0.7768 - val_accuracy: 0.7647\n",
            "Epoch 197/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7076 - accuracy: 0.7573 - val_loss: 0.7688 - val_accuracy: 0.7567\n",
            "Epoch 198/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7089 - accuracy: 0.7598 - val_loss: 0.7675 - val_accuracy: 0.7579\n",
            "Epoch 199/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7094 - accuracy: 0.7565 - val_loss: 0.7670 - val_accuracy: 0.7722\n",
            "Epoch 200/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7035 - accuracy: 0.7635 - val_loss: 0.7709 - val_accuracy: 0.7573\n",
            "Epoch 201/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.7616 - val_loss: 0.7676 - val_accuracy: 0.7596\n",
            "Epoch 202/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7018 - accuracy: 0.7672 - val_loss: 0.7595 - val_accuracy: 0.7647\n",
            "Epoch 203/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7091 - accuracy: 0.7626 - val_loss: 0.7646 - val_accuracy: 0.7659\n",
            "Epoch 204/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7031 - accuracy: 0.7662 - val_loss: 0.7672 - val_accuracy: 0.7624\n",
            "Epoch 205/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7067 - accuracy: 0.7579 - val_loss: 0.7731 - val_accuracy: 0.7613\n",
            "Epoch 206/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7046 - accuracy: 0.7654 - val_loss: 0.7782 - val_accuracy: 0.7636\n",
            "Epoch 207/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7138 - accuracy: 0.7589 - val_loss: 0.7605 - val_accuracy: 0.7636\n",
            "Epoch 208/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6965 - accuracy: 0.7655 - val_loss: 0.7582 - val_accuracy: 0.7613\n",
            "Epoch 209/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6887 - accuracy: 0.7631 - val_loss: 0.7586 - val_accuracy: 0.7567\n",
            "Epoch 210/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6918 - accuracy: 0.7666 - val_loss: 0.7632 - val_accuracy: 0.7665\n",
            "Epoch 211/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6855 - accuracy: 0.7721 - val_loss: 0.7619 - val_accuracy: 0.7659\n",
            "Epoch 212/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6867 - accuracy: 0.7688 - val_loss: 0.7635 - val_accuracy: 0.7653\n",
            "Epoch 213/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6851 - accuracy: 0.7666 - val_loss: 0.7653 - val_accuracy: 0.7624\n",
            "Epoch 214/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6912 - accuracy: 0.7714 - val_loss: 0.7522 - val_accuracy: 0.7630\n",
            "Epoch 215/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7023 - accuracy: 0.7591 - val_loss: 0.7627 - val_accuracy: 0.7602\n",
            "Epoch 216/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6999 - accuracy: 0.7609 - val_loss: 0.7506 - val_accuracy: 0.7676\n",
            "Epoch 217/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7078 - accuracy: 0.7608 - val_loss: 0.7577 - val_accuracy: 0.7647\n",
            "Epoch 218/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.6782 - accuracy: 0.7742 - val_loss: 0.7672 - val_accuracy: 0.7579\n",
            "Epoch 219/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.6794 - accuracy: 0.7712 - val_loss: 0.7671 - val_accuracy: 0.7636\n",
            "Epoch 220/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.6694 - accuracy: 0.7774 - val_loss: 0.7709 - val_accuracy: 0.7607\n",
            "Epoch 221/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.6822 - accuracy: 0.7727 - val_loss: 0.7628 - val_accuracy: 0.7636\n",
            "Epoch 222/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.6867 - accuracy: 0.7671 - val_loss: 0.7522 - val_accuracy: 0.7722\n",
            "Epoch 223/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6628 - accuracy: 0.7727 - val_loss: 0.7639 - val_accuracy: 0.7647\n",
            "Epoch 224/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6797 - accuracy: 0.7758 - val_loss: 0.7521 - val_accuracy: 0.7699\n",
            "Epoch 225/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6750 - accuracy: 0.7719 - val_loss: 0.7651 - val_accuracy: 0.7636\n",
            "Epoch 226/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6898 - accuracy: 0.7694 - val_loss: 0.7517 - val_accuracy: 0.7693\n",
            "Epoch 227/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6741 - accuracy: 0.7724 - val_loss: 0.7453 - val_accuracy: 0.7693\n",
            "Epoch 228/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6736 - accuracy: 0.7751 - val_loss: 0.7605 - val_accuracy: 0.7705\n",
            "Epoch 229/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6816 - accuracy: 0.7770 - val_loss: 0.7590 - val_accuracy: 0.7722\n",
            "Epoch 230/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6923 - accuracy: 0.7674 - val_loss: 0.7494 - val_accuracy: 0.7745\n",
            "Epoch 231/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6643 - accuracy: 0.7725 - val_loss: 0.7560 - val_accuracy: 0.7676\n",
            "Epoch 232/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6774 - accuracy: 0.7722 - val_loss: 0.7520 - val_accuracy: 0.7670\n",
            "Epoch 233/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6870 - accuracy: 0.7671 - val_loss: 0.7488 - val_accuracy: 0.7653\n",
            "Epoch 234/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.6768 - accuracy: 0.7741 - val_loss: 0.7543 - val_accuracy: 0.7716\n",
            "Epoch 235/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6750 - accuracy: 0.7707 - val_loss: 0.7487 - val_accuracy: 0.7676\n",
            "Epoch 236/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.6643 - accuracy: 0.7725 - val_loss: 0.7470 - val_accuracy: 0.7682\n",
            "Epoch 237/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6769 - accuracy: 0.7676 - val_loss: 0.7516 - val_accuracy: 0.7659\n",
            "Epoch 238/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6644 - accuracy: 0.7759 - val_loss: 0.7460 - val_accuracy: 0.7722\n",
            "Epoch 239/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6667 - accuracy: 0.7711 - val_loss: 0.7473 - val_accuracy: 0.7687\n",
            "Epoch 240/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6775 - accuracy: 0.7738 - val_loss: 0.7438 - val_accuracy: 0.7682\n",
            "Epoch 241/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6631 - accuracy: 0.7724 - val_loss: 0.7494 - val_accuracy: 0.7693\n",
            "Epoch 242/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6712 - accuracy: 0.7744 - val_loss: 0.7514 - val_accuracy: 0.7624\n",
            "Epoch 243/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6597 - accuracy: 0.7772 - val_loss: 0.7610 - val_accuracy: 0.7636\n",
            "Epoch 244/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6685 - accuracy: 0.7774 - val_loss: 0.7596 - val_accuracy: 0.7607\n",
            "Epoch 245/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6575 - accuracy: 0.7765 - val_loss: 0.7562 - val_accuracy: 0.7693\n",
            "Epoch 246/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6674 - accuracy: 0.7762 - val_loss: 0.7461 - val_accuracy: 0.7693\n",
            "Epoch 247/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6592 - accuracy: 0.7715 - val_loss: 0.7575 - val_accuracy: 0.7716\n",
            "Epoch 248/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6553 - accuracy: 0.7765 - val_loss: 0.7535 - val_accuracy: 0.7670\n",
            "Epoch 249/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6604 - accuracy: 0.7751 - val_loss: 0.7466 - val_accuracy: 0.7716\n",
            "Epoch 250/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.6621 - accuracy: 0.7764 - val_loss: 0.7499 - val_accuracy: 0.7682\n",
            "Epoch 251/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6665 - accuracy: 0.7741 - val_loss: 0.7496 - val_accuracy: 0.7670\n",
            "Epoch 252/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6682 - accuracy: 0.7780 - val_loss: 0.7511 - val_accuracy: 0.7670\n",
            "Epoch 253/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6692 - accuracy: 0.7744 - val_loss: 0.7458 - val_accuracy: 0.7682\n",
            "Epoch 254/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6703 - accuracy: 0.7728 - val_loss: 0.7481 - val_accuracy: 0.7596\n",
            "Epoch 255/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6767 - accuracy: 0.7721 - val_loss: 0.7555 - val_accuracy: 0.7630\n",
            "Epoch 256/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6714 - accuracy: 0.7718 - val_loss: 0.7585 - val_accuracy: 0.7665\n",
            "Epoch 257/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6640 - accuracy: 0.7780 - val_loss: 0.7546 - val_accuracy: 0.7562\n",
            "Epoch 258/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6703 - accuracy: 0.7705 - val_loss: 0.7476 - val_accuracy: 0.7728\n",
            "Epoch 259/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6672 - accuracy: 0.7694 - val_loss: 0.7382 - val_accuracy: 0.7705\n",
            "Epoch 260/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6488 - accuracy: 0.7831 - val_loss: 0.7450 - val_accuracy: 0.7659\n",
            "Epoch 261/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6682 - accuracy: 0.7759 - val_loss: 0.7408 - val_accuracy: 0.7762\n",
            "Epoch 262/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6494 - accuracy: 0.7810 - val_loss: 0.7708 - val_accuracy: 0.7596\n",
            "Epoch 263/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6661 - accuracy: 0.7752 - val_loss: 0.7363 - val_accuracy: 0.7733\n",
            "Epoch 264/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6501 - accuracy: 0.7792 - val_loss: 0.7449 - val_accuracy: 0.7670\n",
            "Epoch 265/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6526 - accuracy: 0.7761 - val_loss: 0.7457 - val_accuracy: 0.7739\n",
            "Epoch 266/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6622 - accuracy: 0.7805 - val_loss: 0.7373 - val_accuracy: 0.7716\n",
            "Epoch 267/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6491 - accuracy: 0.7794 - val_loss: 0.7548 - val_accuracy: 0.7693\n",
            "Epoch 268/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6486 - accuracy: 0.7780 - val_loss: 0.7560 - val_accuracy: 0.7653\n",
            "Epoch 269/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6378 - accuracy: 0.7854 - val_loss: 0.7386 - val_accuracy: 0.7728\n",
            "Epoch 270/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6401 - accuracy: 0.7797 - val_loss: 0.7288 - val_accuracy: 0.7687\n",
            "Epoch 271/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6579 - accuracy: 0.7747 - val_loss: 0.7402 - val_accuracy: 0.7733\n",
            "Epoch 272/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6491 - accuracy: 0.7790 - val_loss: 0.7400 - val_accuracy: 0.7670\n",
            "Epoch 273/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6632 - accuracy: 0.7784 - val_loss: 0.7376 - val_accuracy: 0.7710\n",
            "Epoch 274/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6359 - accuracy: 0.7893 - val_loss: 0.7484 - val_accuracy: 0.7699\n",
            "Epoch 275/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6537 - accuracy: 0.7785 - val_loss: 0.7487 - val_accuracy: 0.7756\n",
            "Epoch 276/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6384 - accuracy: 0.7831 - val_loss: 0.7451 - val_accuracy: 0.7728\n",
            "Epoch 277/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.6655 - accuracy: 0.7765 - val_loss: 0.7468 - val_accuracy: 0.7676\n",
            "Epoch 278/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6301 - accuracy: 0.7864 - val_loss: 0.7533 - val_accuracy: 0.7653\n",
            "Epoch 279/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.6299 - accuracy: 0.7870 - val_loss: 0.7481 - val_accuracy: 0.7619\n",
            "Epoch 280/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6386 - accuracy: 0.7812 - val_loss: 0.7552 - val_accuracy: 0.7642\n",
            "Epoch 281/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6573 - accuracy: 0.7782 - val_loss: 0.7491 - val_accuracy: 0.7710\n",
            "Epoch 282/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6384 - accuracy: 0.7822 - val_loss: 0.7694 - val_accuracy: 0.7642\n",
            "Epoch 283/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6281 - accuracy: 0.7808 - val_loss: 0.7615 - val_accuracy: 0.7705\n",
            "Epoch 284/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6573 - accuracy: 0.7800 - val_loss: 0.7369 - val_accuracy: 0.7728\n",
            "Epoch 285/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6358 - accuracy: 0.7768 - val_loss: 0.7355 - val_accuracy: 0.7762\n",
            "Epoch 286/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6208 - accuracy: 0.7910 - val_loss: 0.7601 - val_accuracy: 0.7699\n",
            "Epoch 287/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6402 - accuracy: 0.7848 - val_loss: 0.7655 - val_accuracy: 0.7670\n",
            "Epoch 288/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6459 - accuracy: 0.7861 - val_loss: 0.7480 - val_accuracy: 0.7670\n",
            "Epoch 289/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6166 - accuracy: 0.7901 - val_loss: 0.7613 - val_accuracy: 0.7756\n",
            "Epoch 290/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6322 - accuracy: 0.7861 - val_loss: 0.7460 - val_accuracy: 0.7699\n",
            "Epoch 291/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6488 - accuracy: 0.7817 - val_loss: 0.7491 - val_accuracy: 0.7670\n",
            "Epoch 292/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6328 - accuracy: 0.7900 - val_loss: 0.7432 - val_accuracy: 0.7653\n",
            "Epoch 293/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6219 - accuracy: 0.7867 - val_loss: 0.7483 - val_accuracy: 0.7659\n",
            "Epoch 294/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6284 - accuracy: 0.7835 - val_loss: 0.7439 - val_accuracy: 0.7716\n",
            "Epoch 295/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6418 - accuracy: 0.7794 - val_loss: 0.7408 - val_accuracy: 0.7745\n",
            "Epoch 296/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6264 - accuracy: 0.7895 - val_loss: 0.7414 - val_accuracy: 0.7728\n",
            "Epoch 297/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6493 - accuracy: 0.7794 - val_loss: 0.7559 - val_accuracy: 0.7642\n",
            "Epoch 298/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6371 - accuracy: 0.7808 - val_loss: 0.7518 - val_accuracy: 0.7722\n",
            "Epoch 299/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6406 - accuracy: 0.7845 - val_loss: 0.7456 - val_accuracy: 0.7756\n",
            "Epoch 300/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6345 - accuracy: 0.7901 - val_loss: 0.7497 - val_accuracy: 0.7710\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe800344950>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "                                #filter sayisi #kernel_size\n",
        "model.add(tf.keras.layers.Conv1D(16,2, activation ='relu', input_shape= (20, 1)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "              #noron sayisi\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "#dropoutlar 0 ile 1 arasinda olcak\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32))\n",
        "\n",
        "            #burayi degistirmeyin\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=\"Adam\",loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])\n",
        "\n",
        "num_epochs = 300\n",
        "num_batch_size = 128\n",
        "\n",
        "model.fit(\n",
        "          x_train, \n",
        "          y_train, \n",
        "          batch_size=num_batch_size, \n",
        "          epochs=num_epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[callbacks]\n",
        "         )"
      ],
      "metadata": {
        "id": "hyqZ_jZxpfk3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "650c26dc-5ca7-40cc-fb41-9914b7ea3da3"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_16 (Conv1D)          (None, 19, 16)            48        \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 304)               0         \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 64)                19520     \n",
            "                                                                 \n",
            " activation_52 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " activation_53 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " activation_54 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_68 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            " activation_55 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38,554\n",
            "Trainable params: 38,554\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "55/55 [==============================] - 1s 7ms/step - loss: 2.2434 - accuracy: 0.1465 - val_loss: 2.1382 - val_accuracy: 0.2891\n",
            "Epoch 2/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.9931 - accuracy: 0.2737 - val_loss: 1.7951 - val_accuracy: 0.3635\n",
            "Epoch 3/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.8075 - accuracy: 0.3340 - val_loss: 1.6768 - val_accuracy: 0.3932\n",
            "Epoch 4/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.7201 - accuracy: 0.3698 - val_loss: 1.6218 - val_accuracy: 0.4179\n",
            "Epoch 5/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.6670 - accuracy: 0.3961 - val_loss: 1.5591 - val_accuracy: 0.4230\n",
            "Epoch 6/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.6083 - accuracy: 0.4142 - val_loss: 1.5315 - val_accuracy: 0.4562\n",
            "Epoch 7/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.5870 - accuracy: 0.4262 - val_loss: 1.4813 - val_accuracy: 0.4825\n",
            "Epoch 8/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.5470 - accuracy: 0.4475 - val_loss: 1.4653 - val_accuracy: 0.4946\n",
            "Epoch 9/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.5285 - accuracy: 0.4553 - val_loss: 1.4402 - val_accuracy: 0.4997\n",
            "Epoch 10/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.5018 - accuracy: 0.4691 - val_loss: 1.4124 - val_accuracy: 0.5146\n",
            "Epoch 11/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.4778 - accuracy: 0.4770 - val_loss: 1.3888 - val_accuracy: 0.5318\n",
            "Epoch 12/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.4561 - accuracy: 0.4938 - val_loss: 1.3669 - val_accuracy: 0.5283\n",
            "Epoch 13/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.4348 - accuracy: 0.4961 - val_loss: 1.3435 - val_accuracy: 0.5358\n",
            "Epoch 14/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.4141 - accuracy: 0.5062 - val_loss: 1.3153 - val_accuracy: 0.5409\n",
            "Epoch 15/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.3786 - accuracy: 0.5258 - val_loss: 1.2912 - val_accuracy: 0.5621\n",
            "Epoch 16/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.3580 - accuracy: 0.5323 - val_loss: 1.2697 - val_accuracy: 0.5764\n",
            "Epoch 17/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.3535 - accuracy: 0.5394 - val_loss: 1.2473 - val_accuracy: 0.5770\n",
            "Epoch 18/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.3216 - accuracy: 0.5419 - val_loss: 1.2326 - val_accuracy: 0.5810\n",
            "Epoch 19/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.3185 - accuracy: 0.5427 - val_loss: 1.2235 - val_accuracy: 0.5902\n",
            "Epoch 20/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.3082 - accuracy: 0.5499 - val_loss: 1.2132 - val_accuracy: 0.5850\n",
            "Epoch 21/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.2791 - accuracy: 0.5611 - val_loss: 1.1969 - val_accuracy: 0.6010\n",
            "Epoch 22/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.2703 - accuracy: 0.5719 - val_loss: 1.1771 - val_accuracy: 0.6131\n",
            "Epoch 23/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.2455 - accuracy: 0.5715 - val_loss: 1.1579 - val_accuracy: 0.6205\n",
            "Epoch 24/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.2365 - accuracy: 0.5820 - val_loss: 1.1508 - val_accuracy: 0.6256\n",
            "Epoch 25/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.2283 - accuracy: 0.5822 - val_loss: 1.1216 - val_accuracy: 0.6331\n",
            "Epoch 26/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.2076 - accuracy: 0.5987 - val_loss: 1.1082 - val_accuracy: 0.6331\n",
            "Epoch 27/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.2060 - accuracy: 0.5937 - val_loss: 1.0991 - val_accuracy: 0.6388\n",
            "Epoch 28/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.1846 - accuracy: 0.6011 - val_loss: 1.0895 - val_accuracy: 0.6417\n",
            "Epoch 29/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.1801 - accuracy: 0.5938 - val_loss: 1.0794 - val_accuracy: 0.6382\n",
            "Epoch 30/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.1679 - accuracy: 0.6092 - val_loss: 1.0768 - val_accuracy: 0.6480\n",
            "Epoch 31/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.1511 - accuracy: 0.6162 - val_loss: 1.0468 - val_accuracy: 0.6651\n",
            "Epoch 32/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.1425 - accuracy: 0.6218 - val_loss: 1.0613 - val_accuracy: 0.6594\n",
            "Epoch 33/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.1517 - accuracy: 0.6137 - val_loss: 1.0434 - val_accuracy: 0.6514\n",
            "Epoch 34/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.1298 - accuracy: 0.6263 - val_loss: 1.0358 - val_accuracy: 0.6623\n",
            "Epoch 35/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.1092 - accuracy: 0.6282 - val_loss: 1.0291 - val_accuracy: 0.6566\n",
            "Epoch 36/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.1195 - accuracy: 0.6253 - val_loss: 1.0154 - val_accuracy: 0.6634\n",
            "Epoch 37/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.0960 - accuracy: 0.6381 - val_loss: 1.0207 - val_accuracy: 0.6634\n",
            "Epoch 38/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.1036 - accuracy: 0.6358 - val_loss: 1.0041 - val_accuracy: 0.6674\n",
            "Epoch 39/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.0778 - accuracy: 0.6362 - val_loss: 0.9893 - val_accuracy: 0.6634\n",
            "Epoch 40/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.0729 - accuracy: 0.6422 - val_loss: 0.9949 - val_accuracy: 0.6714\n",
            "Epoch 41/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.0811 - accuracy: 0.6455 - val_loss: 0.9791 - val_accuracy: 0.6760\n",
            "Epoch 42/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.0626 - accuracy: 0.6471 - val_loss: 0.9709 - val_accuracy: 0.6840\n",
            "Epoch 43/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.0539 - accuracy: 0.6474 - val_loss: 0.9801 - val_accuracy: 0.6795\n",
            "Epoch 44/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.0463 - accuracy: 0.6530 - val_loss: 0.9610 - val_accuracy: 0.6823\n",
            "Epoch 45/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.0446 - accuracy: 0.6523 - val_loss: 0.9672 - val_accuracy: 0.6846\n",
            "Epoch 46/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.0427 - accuracy: 0.6518 - val_loss: 0.9628 - val_accuracy: 0.6766\n",
            "Epoch 47/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.0367 - accuracy: 0.6495 - val_loss: 0.9540 - val_accuracy: 0.6823\n",
            "Epoch 48/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.0295 - accuracy: 0.6497 - val_loss: 0.9339 - val_accuracy: 0.6903\n",
            "Epoch 49/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.0233 - accuracy: 0.6560 - val_loss: 0.9498 - val_accuracy: 0.6852\n",
            "Epoch 50/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.0173 - accuracy: 0.6596 - val_loss: 0.9361 - val_accuracy: 0.6835\n",
            "Epoch 51/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.0069 - accuracy: 0.6588 - val_loss: 0.9263 - val_accuracy: 0.6852\n",
            "Epoch 52/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.0027 - accuracy: 0.6598 - val_loss: 0.9217 - val_accuracy: 0.6875\n",
            "Epoch 53/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.9883 - accuracy: 0.6654 - val_loss: 0.9274 - val_accuracy: 0.6863\n",
            "Epoch 54/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 1.0120 - accuracy: 0.6538 - val_loss: 0.9222 - val_accuracy: 0.6955\n",
            "Epoch 55/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.9890 - accuracy: 0.6669 - val_loss: 0.9143 - val_accuracy: 0.6926\n",
            "Epoch 56/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.9898 - accuracy: 0.6699 - val_loss: 0.9292 - val_accuracy: 0.6903\n",
            "Epoch 57/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.9726 - accuracy: 0.6749 - val_loss: 0.9106 - val_accuracy: 0.6903\n",
            "Epoch 58/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.9836 - accuracy: 0.6646 - val_loss: 0.9024 - val_accuracy: 0.7058\n",
            "Epoch 59/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.9766 - accuracy: 0.6729 - val_loss: 0.9093 - val_accuracy: 0.6966\n",
            "Epoch 60/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.9757 - accuracy: 0.6754 - val_loss: 0.9035 - val_accuracy: 0.6989\n",
            "Epoch 61/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.9663 - accuracy: 0.6687 - val_loss: 0.8957 - val_accuracy: 0.7023\n",
            "Epoch 62/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.9503 - accuracy: 0.6852 - val_loss: 0.9000 - val_accuracy: 0.6983\n",
            "Epoch 63/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.9528 - accuracy: 0.6766 - val_loss: 0.8938 - val_accuracy: 0.7035\n",
            "Epoch 64/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.9432 - accuracy: 0.6792 - val_loss: 0.8973 - val_accuracy: 0.6909\n",
            "Epoch 65/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.9426 - accuracy: 0.6869 - val_loss: 0.9046 - val_accuracy: 0.6920\n",
            "Epoch 66/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.9330 - accuracy: 0.6880 - val_loss: 0.8913 - val_accuracy: 0.6932\n",
            "Epoch 67/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.9238 - accuracy: 0.6913 - val_loss: 0.8958 - val_accuracy: 0.6932\n",
            "Epoch 68/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.9512 - accuracy: 0.6775 - val_loss: 0.8819 - val_accuracy: 0.7029\n",
            "Epoch 69/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.9380 - accuracy: 0.6832 - val_loss: 0.8755 - val_accuracy: 0.7006\n",
            "Epoch 70/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.9311 - accuracy: 0.6852 - val_loss: 0.8902 - val_accuracy: 0.6995\n",
            "Epoch 71/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.9282 - accuracy: 0.6879 - val_loss: 0.8619 - val_accuracy: 0.7075\n",
            "Epoch 72/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.9334 - accuracy: 0.6822 - val_loss: 0.8682 - val_accuracy: 0.7098\n",
            "Epoch 73/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.9166 - accuracy: 0.6885 - val_loss: 0.8803 - val_accuracy: 0.7035\n",
            "Epoch 74/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.9276 - accuracy: 0.6846 - val_loss: 0.8600 - val_accuracy: 0.7127\n",
            "Epoch 75/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.9113 - accuracy: 0.6921 - val_loss: 0.8600 - val_accuracy: 0.7132\n",
            "Epoch 76/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.9077 - accuracy: 0.6941 - val_loss: 0.8608 - val_accuracy: 0.7086\n",
            "Epoch 77/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8990 - accuracy: 0.6939 - val_loss: 0.8556 - val_accuracy: 0.7132\n",
            "Epoch 78/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.9063 - accuracy: 0.6958 - val_loss: 0.8466 - val_accuracy: 0.7109\n",
            "Epoch 79/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.9096 - accuracy: 0.6982 - val_loss: 0.8545 - val_accuracy: 0.7086\n",
            "Epoch 80/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.9009 - accuracy: 0.6982 - val_loss: 0.8432 - val_accuracy: 0.7155\n",
            "Epoch 81/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8894 - accuracy: 0.7016 - val_loss: 0.8569 - val_accuracy: 0.7184\n",
            "Epoch 82/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8896 - accuracy: 0.6981 - val_loss: 0.8674 - val_accuracy: 0.7132\n",
            "Epoch 83/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8921 - accuracy: 0.6996 - val_loss: 0.8513 - val_accuracy: 0.7293\n",
            "Epoch 84/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8802 - accuracy: 0.6989 - val_loss: 0.8494 - val_accuracy: 0.7127\n",
            "Epoch 85/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8735 - accuracy: 0.7089 - val_loss: 0.8428 - val_accuracy: 0.7184\n",
            "Epoch 86/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8882 - accuracy: 0.7009 - val_loss: 0.8357 - val_accuracy: 0.7127\n",
            "Epoch 87/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8919 - accuracy: 0.6996 - val_loss: 0.8446 - val_accuracy: 0.7201\n",
            "Epoch 88/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8670 - accuracy: 0.7055 - val_loss: 0.8419 - val_accuracy: 0.7149\n",
            "Epoch 89/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8912 - accuracy: 0.6935 - val_loss: 0.8401 - val_accuracy: 0.7201\n",
            "Epoch 90/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8814 - accuracy: 0.6958 - val_loss: 0.8387 - val_accuracy: 0.7184\n",
            "Epoch 91/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8652 - accuracy: 0.7071 - val_loss: 0.8411 - val_accuracy: 0.7127\n",
            "Epoch 92/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8792 - accuracy: 0.7028 - val_loss: 0.8230 - val_accuracy: 0.7224\n",
            "Epoch 93/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8675 - accuracy: 0.7105 - val_loss: 0.8275 - val_accuracy: 0.7258\n",
            "Epoch 94/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8852 - accuracy: 0.7031 - val_loss: 0.8309 - val_accuracy: 0.7207\n",
            "Epoch 95/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8725 - accuracy: 0.7087 - val_loss: 0.8389 - val_accuracy: 0.7138\n",
            "Epoch 96/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8570 - accuracy: 0.7112 - val_loss: 0.8337 - val_accuracy: 0.7184\n",
            "Epoch 97/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8471 - accuracy: 0.7131 - val_loss: 0.8270 - val_accuracy: 0.7275\n",
            "Epoch 98/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8729 - accuracy: 0.7047 - val_loss: 0.8101 - val_accuracy: 0.7281\n",
            "Epoch 99/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8562 - accuracy: 0.7147 - val_loss: 0.8136 - val_accuracy: 0.7293\n",
            "Epoch 100/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8609 - accuracy: 0.7101 - val_loss: 0.8194 - val_accuracy: 0.7270\n",
            "Epoch 101/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8564 - accuracy: 0.7051 - val_loss: 0.8145 - val_accuracy: 0.7207\n",
            "Epoch 102/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8494 - accuracy: 0.7117 - val_loss: 0.8247 - val_accuracy: 0.7212\n",
            "Epoch 103/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8489 - accuracy: 0.7094 - val_loss: 0.8055 - val_accuracy: 0.7321\n",
            "Epoch 104/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8392 - accuracy: 0.7140 - val_loss: 0.8035 - val_accuracy: 0.7310\n",
            "Epoch 105/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8293 - accuracy: 0.7168 - val_loss: 0.8047 - val_accuracy: 0.7355\n",
            "Epoch 106/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8362 - accuracy: 0.7118 - val_loss: 0.8103 - val_accuracy: 0.7321\n",
            "Epoch 107/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8335 - accuracy: 0.7177 - val_loss: 0.8202 - val_accuracy: 0.7315\n",
            "Epoch 108/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8468 - accuracy: 0.7160 - val_loss: 0.8088 - val_accuracy: 0.7304\n",
            "Epoch 109/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8350 - accuracy: 0.7198 - val_loss: 0.8066 - val_accuracy: 0.7310\n",
            "Epoch 110/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8350 - accuracy: 0.7151 - val_loss: 0.8179 - val_accuracy: 0.7327\n",
            "Epoch 111/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8220 - accuracy: 0.7190 - val_loss: 0.8111 - val_accuracy: 0.7304\n",
            "Epoch 112/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8401 - accuracy: 0.7142 - val_loss: 0.8033 - val_accuracy: 0.7321\n",
            "Epoch 113/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8301 - accuracy: 0.7241 - val_loss: 0.8112 - val_accuracy: 0.7338\n",
            "Epoch 114/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8217 - accuracy: 0.7251 - val_loss: 0.8170 - val_accuracy: 0.7367\n",
            "Epoch 115/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8294 - accuracy: 0.7145 - val_loss: 0.8123 - val_accuracy: 0.7298\n",
            "Epoch 116/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8412 - accuracy: 0.7148 - val_loss: 0.8017 - val_accuracy: 0.7321\n",
            "Epoch 117/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8170 - accuracy: 0.7293 - val_loss: 0.7975 - val_accuracy: 0.7413\n",
            "Epoch 118/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8158 - accuracy: 0.7270 - val_loss: 0.8005 - val_accuracy: 0.7378\n",
            "Epoch 119/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8261 - accuracy: 0.7151 - val_loss: 0.7948 - val_accuracy: 0.7373\n",
            "Epoch 120/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8050 - accuracy: 0.7287 - val_loss: 0.7887 - val_accuracy: 0.7453\n",
            "Epoch 121/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8113 - accuracy: 0.7203 - val_loss: 0.8129 - val_accuracy: 0.7367\n",
            "Epoch 122/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8387 - accuracy: 0.7158 - val_loss: 0.7991 - val_accuracy: 0.7424\n",
            "Epoch 123/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8034 - accuracy: 0.7273 - val_loss: 0.7908 - val_accuracy: 0.7373\n",
            "Epoch 124/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8220 - accuracy: 0.7294 - val_loss: 0.7972 - val_accuracy: 0.7361\n",
            "Epoch 125/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.8080 - accuracy: 0.7291 - val_loss: 0.7867 - val_accuracy: 0.7413\n",
            "Epoch 126/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8025 - accuracy: 0.7273 - val_loss: 0.7947 - val_accuracy: 0.7413\n",
            "Epoch 127/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7988 - accuracy: 0.7320 - val_loss: 0.7931 - val_accuracy: 0.7407\n",
            "Epoch 128/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8165 - accuracy: 0.7198 - val_loss: 0.7999 - val_accuracy: 0.7367\n",
            "Epoch 129/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7877 - accuracy: 0.7296 - val_loss: 0.7830 - val_accuracy: 0.7424\n",
            "Epoch 130/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7888 - accuracy: 0.7301 - val_loss: 0.8050 - val_accuracy: 0.7413\n",
            "Epoch 131/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7882 - accuracy: 0.7276 - val_loss: 0.7854 - val_accuracy: 0.7481\n",
            "Epoch 132/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8131 - accuracy: 0.7278 - val_loss: 0.7919 - val_accuracy: 0.7384\n",
            "Epoch 133/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7990 - accuracy: 0.7228 - val_loss: 0.7682 - val_accuracy: 0.7527\n",
            "Epoch 134/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7890 - accuracy: 0.7280 - val_loss: 0.7885 - val_accuracy: 0.7384\n",
            "Epoch 135/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7821 - accuracy: 0.7370 - val_loss: 0.7782 - val_accuracy: 0.7453\n",
            "Epoch 136/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8062 - accuracy: 0.7331 - val_loss: 0.7698 - val_accuracy: 0.7544\n",
            "Epoch 137/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7973 - accuracy: 0.7290 - val_loss: 0.7897 - val_accuracy: 0.7396\n",
            "Epoch 138/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7785 - accuracy: 0.7298 - val_loss: 0.7808 - val_accuracy: 0.7436\n",
            "Epoch 139/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7787 - accuracy: 0.7353 - val_loss: 0.7925 - val_accuracy: 0.7447\n",
            "Epoch 140/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7926 - accuracy: 0.7350 - val_loss: 0.7750 - val_accuracy: 0.7510\n",
            "Epoch 141/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7913 - accuracy: 0.7303 - val_loss: 0.7790 - val_accuracy: 0.7447\n",
            "Epoch 142/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7881 - accuracy: 0.7346 - val_loss: 0.7839 - val_accuracy: 0.7396\n",
            "Epoch 143/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7816 - accuracy: 0.7344 - val_loss: 0.7739 - val_accuracy: 0.7447\n",
            "Epoch 144/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7829 - accuracy: 0.7336 - val_loss: 0.7767 - val_accuracy: 0.7464\n",
            "Epoch 145/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7783 - accuracy: 0.7354 - val_loss: 0.7675 - val_accuracy: 0.7481\n",
            "Epoch 146/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7880 - accuracy: 0.7336 - val_loss: 0.7855 - val_accuracy: 0.7493\n",
            "Epoch 147/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7863 - accuracy: 0.7336 - val_loss: 0.7644 - val_accuracy: 0.7556\n",
            "Epoch 148/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7656 - accuracy: 0.7420 - val_loss: 0.7725 - val_accuracy: 0.7453\n",
            "Epoch 149/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7754 - accuracy: 0.7344 - val_loss: 0.7692 - val_accuracy: 0.7464\n",
            "Epoch 150/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7712 - accuracy: 0.7400 - val_loss: 0.7703 - val_accuracy: 0.7464\n",
            "Epoch 151/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7622 - accuracy: 0.7413 - val_loss: 0.7781 - val_accuracy: 0.7481\n",
            "Epoch 152/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7852 - accuracy: 0.7330 - val_loss: 0.7751 - val_accuracy: 0.7481\n",
            "Epoch 153/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7815 - accuracy: 0.7429 - val_loss: 0.7846 - val_accuracy: 0.7424\n",
            "Epoch 154/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7778 - accuracy: 0.7410 - val_loss: 0.7740 - val_accuracy: 0.7481\n",
            "Epoch 155/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7764 - accuracy: 0.7392 - val_loss: 0.7762 - val_accuracy: 0.7481\n",
            "Epoch 156/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7634 - accuracy: 0.7426 - val_loss: 0.7844 - val_accuracy: 0.7413\n",
            "Epoch 157/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7681 - accuracy: 0.7399 - val_loss: 0.7976 - val_accuracy: 0.7418\n",
            "Epoch 158/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7724 - accuracy: 0.7423 - val_loss: 0.7703 - val_accuracy: 0.7436\n",
            "Epoch 159/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7620 - accuracy: 0.7417 - val_loss: 0.7599 - val_accuracy: 0.7550\n",
            "Epoch 160/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7640 - accuracy: 0.7423 - val_loss: 0.7692 - val_accuracy: 0.7481\n",
            "Epoch 161/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7615 - accuracy: 0.7445 - val_loss: 0.7658 - val_accuracy: 0.7459\n",
            "Epoch 162/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7506 - accuracy: 0.7409 - val_loss: 0.7572 - val_accuracy: 0.7544\n",
            "Epoch 163/300\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7668 - accuracy: 0.7447 - val_loss: 0.7607 - val_accuracy: 0.7499\n",
            "Epoch 164/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7592 - accuracy: 0.7442 - val_loss: 0.7636 - val_accuracy: 0.7516\n",
            "Epoch 165/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7504 - accuracy: 0.7452 - val_loss: 0.7697 - val_accuracy: 0.7481\n",
            "Epoch 166/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7474 - accuracy: 0.7455 - val_loss: 0.7705 - val_accuracy: 0.7470\n",
            "Epoch 167/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7461 - accuracy: 0.7497 - val_loss: 0.7710 - val_accuracy: 0.7430\n",
            "Epoch 168/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7451 - accuracy: 0.7450 - val_loss: 0.7586 - val_accuracy: 0.7539\n",
            "Epoch 169/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7527 - accuracy: 0.7490 - val_loss: 0.7668 - val_accuracy: 0.7533\n",
            "Epoch 170/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7490 - accuracy: 0.7466 - val_loss: 0.7720 - val_accuracy: 0.7470\n",
            "Epoch 171/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7488 - accuracy: 0.7435 - val_loss: 0.7623 - val_accuracy: 0.7539\n",
            "Epoch 172/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7494 - accuracy: 0.7450 - val_loss: 0.7598 - val_accuracy: 0.7527\n",
            "Epoch 173/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7528 - accuracy: 0.7480 - val_loss: 0.7600 - val_accuracy: 0.7516\n",
            "Epoch 174/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7438 - accuracy: 0.7508 - val_loss: 0.7551 - val_accuracy: 0.7584\n",
            "Epoch 175/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7417 - accuracy: 0.7509 - val_loss: 0.7544 - val_accuracy: 0.7573\n",
            "Epoch 176/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7525 - accuracy: 0.7502 - val_loss: 0.7740 - val_accuracy: 0.7476\n",
            "Epoch 177/300\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7429 - accuracy: 0.7532 - val_loss: 0.7595 - val_accuracy: 0.7602\n",
            "Epoch 178/300\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7591 - accuracy: 0.7424 - val_loss: 0.7684 - val_accuracy: 0.7596\n",
            "Epoch 179/300\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7427 - accuracy: 0.7558 - val_loss: 0.7747 - val_accuracy: 0.7493\n",
            "Epoch 180/300\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7499 - accuracy: 0.7440 - val_loss: 0.7579 - val_accuracy: 0.7481\n",
            "Epoch 181/300\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7504 - accuracy: 0.7396 - val_loss: 0.7736 - val_accuracy: 0.7504\n",
            "Epoch 182/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7472 - accuracy: 0.7445 - val_loss: 0.7539 - val_accuracy: 0.7521\n",
            "Epoch 183/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7278 - accuracy: 0.7476 - val_loss: 0.7555 - val_accuracy: 0.7562\n",
            "Epoch 184/300\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7414 - accuracy: 0.7529 - val_loss: 0.7564 - val_accuracy: 0.7510\n",
            "Epoch 185/300\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7333 - accuracy: 0.7424 - val_loss: 0.7510 - val_accuracy: 0.7584\n",
            "Epoch 186/300\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7244 - accuracy: 0.7546 - val_loss: 0.7620 - val_accuracy: 0.7516\n",
            "Epoch 187/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7404 - accuracy: 0.7470 - val_loss: 0.7563 - val_accuracy: 0.7527\n",
            "Epoch 188/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7527 - accuracy: 0.7508 - val_loss: 0.7607 - val_accuracy: 0.7481\n",
            "Epoch 189/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7475 - accuracy: 0.7526 - val_loss: 0.7572 - val_accuracy: 0.7504\n",
            "Epoch 190/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7335 - accuracy: 0.7523 - val_loss: 0.7620 - val_accuracy: 0.7510\n",
            "Epoch 191/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7470 - accuracy: 0.7505 - val_loss: 0.7524 - val_accuracy: 0.7499\n",
            "Epoch 192/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7334 - accuracy: 0.7548 - val_loss: 0.7532 - val_accuracy: 0.7499\n",
            "Epoch 193/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7274 - accuracy: 0.7530 - val_loss: 0.7550 - val_accuracy: 0.7556\n",
            "Epoch 194/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7376 - accuracy: 0.7489 - val_loss: 0.7554 - val_accuracy: 0.7413\n",
            "Epoch 195/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7230 - accuracy: 0.7559 - val_loss: 0.7531 - val_accuracy: 0.7590\n",
            "Epoch 196/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7081 - accuracy: 0.7612 - val_loss: 0.7729 - val_accuracy: 0.7464\n",
            "Epoch 197/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7333 - accuracy: 0.7492 - val_loss: 0.7556 - val_accuracy: 0.7556\n",
            "Epoch 198/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7320 - accuracy: 0.7569 - val_loss: 0.7610 - val_accuracy: 0.7584\n",
            "Epoch 199/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7274 - accuracy: 0.7530 - val_loss: 0.7565 - val_accuracy: 0.7539\n",
            "Epoch 200/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7365 - accuracy: 0.7532 - val_loss: 0.7505 - val_accuracy: 0.7556\n",
            "Epoch 201/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7315 - accuracy: 0.7483 - val_loss: 0.7392 - val_accuracy: 0.7659\n",
            "Epoch 202/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7078 - accuracy: 0.7606 - val_loss: 0.7489 - val_accuracy: 0.7642\n",
            "Epoch 203/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7223 - accuracy: 0.7546 - val_loss: 0.7419 - val_accuracy: 0.7584\n",
            "Epoch 204/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7230 - accuracy: 0.7529 - val_loss: 0.7631 - val_accuracy: 0.7464\n",
            "Epoch 205/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7199 - accuracy: 0.7550 - val_loss: 0.7564 - val_accuracy: 0.7521\n",
            "Epoch 206/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7198 - accuracy: 0.7555 - val_loss: 0.7632 - val_accuracy: 0.7464\n",
            "Epoch 207/300\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.7216 - accuracy: 0.7563 - val_loss: 0.7567 - val_accuracy: 0.7539\n",
            "Epoch 208/300\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7181 - accuracy: 0.7526 - val_loss: 0.7628 - val_accuracy: 0.7533\n",
            "Epoch 209/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7134 - accuracy: 0.7563 - val_loss: 0.7466 - val_accuracy: 0.7619\n",
            "Epoch 210/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7130 - accuracy: 0.7589 - val_loss: 0.7601 - val_accuracy: 0.7516\n",
            "Epoch 211/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7149 - accuracy: 0.7615 - val_loss: 0.7533 - val_accuracy: 0.7544\n",
            "Epoch 212/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7050 - accuracy: 0.7648 - val_loss: 0.7623 - val_accuracy: 0.7533\n",
            "Epoch 213/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7392 - accuracy: 0.7496 - val_loss: 0.7577 - val_accuracy: 0.7493\n",
            "Epoch 214/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7085 - accuracy: 0.7572 - val_loss: 0.7564 - val_accuracy: 0.7516\n",
            "Epoch 215/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7273 - accuracy: 0.7548 - val_loss: 0.7486 - val_accuracy: 0.7533\n",
            "Epoch 216/300\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7153 - accuracy: 0.7606 - val_loss: 0.7445 - val_accuracy: 0.7607\n",
            "Epoch 217/300\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7046 - accuracy: 0.7601 - val_loss: 0.7598 - val_accuracy: 0.7516\n",
            "Epoch 218/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7217 - accuracy: 0.7518 - val_loss: 0.7486 - val_accuracy: 0.7596\n",
            "Epoch 219/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7296 - accuracy: 0.7529 - val_loss: 0.7572 - val_accuracy: 0.7539\n",
            "Epoch 220/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7013 - accuracy: 0.7601 - val_loss: 0.7567 - val_accuracy: 0.7527\n",
            "Epoch 221/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7063 - accuracy: 0.7530 - val_loss: 0.7783 - val_accuracy: 0.7516\n",
            "Epoch 222/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7081 - accuracy: 0.7598 - val_loss: 0.7553 - val_accuracy: 0.7619\n",
            "Epoch 223/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7061 - accuracy: 0.7555 - val_loss: 0.7587 - val_accuracy: 0.7562\n",
            "Epoch 224/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6990 - accuracy: 0.7611 - val_loss: 0.7521 - val_accuracy: 0.7590\n",
            "Epoch 225/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7129 - accuracy: 0.7575 - val_loss: 0.7556 - val_accuracy: 0.7584\n",
            "Epoch 226/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7213 - accuracy: 0.7545 - val_loss: 0.7559 - val_accuracy: 0.7556\n",
            "Epoch 227/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6951 - accuracy: 0.7636 - val_loss: 0.7495 - val_accuracy: 0.7579\n",
            "Epoch 228/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7280 - accuracy: 0.7538 - val_loss: 0.7496 - val_accuracy: 0.7573\n",
            "Epoch 229/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7040 - accuracy: 0.7593 - val_loss: 0.7485 - val_accuracy: 0.7573\n",
            "Epoch 230/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7170 - accuracy: 0.7588 - val_loss: 0.7479 - val_accuracy: 0.7567\n",
            "Epoch 231/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7028 - accuracy: 0.7613 - val_loss: 0.7356 - val_accuracy: 0.7624\n",
            "Epoch 232/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7069 - accuracy: 0.7601 - val_loss: 0.7408 - val_accuracy: 0.7613\n",
            "Epoch 233/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7046 - accuracy: 0.7626 - val_loss: 0.7472 - val_accuracy: 0.7579\n",
            "Epoch 234/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7071 - accuracy: 0.7622 - val_loss: 0.7621 - val_accuracy: 0.7499\n",
            "Epoch 235/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.7626 - val_loss: 0.7433 - val_accuracy: 0.7579\n",
            "Epoch 236/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6858 - accuracy: 0.7619 - val_loss: 0.7483 - val_accuracy: 0.7516\n",
            "Epoch 237/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7009 - accuracy: 0.7661 - val_loss: 0.7479 - val_accuracy: 0.7562\n",
            "Epoch 238/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.7664 - val_loss: 0.7438 - val_accuracy: 0.7567\n",
            "Epoch 239/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6889 - accuracy: 0.7623 - val_loss: 0.7666 - val_accuracy: 0.7464\n",
            "Epoch 240/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7059 - accuracy: 0.7622 - val_loss: 0.7604 - val_accuracy: 0.7493\n",
            "Epoch 241/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6975 - accuracy: 0.7593 - val_loss: 0.7429 - val_accuracy: 0.7527\n",
            "Epoch 242/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6794 - accuracy: 0.7674 - val_loss: 0.7401 - val_accuracy: 0.7556\n",
            "Epoch 243/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.7626 - val_loss: 0.7484 - val_accuracy: 0.7556\n",
            "Epoch 244/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7121 - accuracy: 0.7648 - val_loss: 0.7533 - val_accuracy: 0.7493\n",
            "Epoch 245/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6955 - accuracy: 0.7641 - val_loss: 0.7453 - val_accuracy: 0.7567\n",
            "Epoch 246/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6855 - accuracy: 0.7695 - val_loss: 0.7390 - val_accuracy: 0.7642\n",
            "Epoch 247/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6887 - accuracy: 0.7689 - val_loss: 0.7573 - val_accuracy: 0.7539\n",
            "Epoch 248/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6811 - accuracy: 0.7655 - val_loss: 0.7488 - val_accuracy: 0.7607\n",
            "Epoch 249/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6911 - accuracy: 0.7631 - val_loss: 0.7544 - val_accuracy: 0.7596\n",
            "Epoch 250/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.7072 - accuracy: 0.7623 - val_loss: 0.7393 - val_accuracy: 0.7602\n",
            "Epoch 251/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6921 - accuracy: 0.7628 - val_loss: 0.7471 - val_accuracy: 0.7527\n",
            "Epoch 252/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6950 - accuracy: 0.7619 - val_loss: 0.7385 - val_accuracy: 0.7613\n",
            "Epoch 253/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6828 - accuracy: 0.7685 - val_loss: 0.7408 - val_accuracy: 0.7573\n",
            "Epoch 254/300\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6923 - accuracy: 0.7658 - val_loss: 0.7382 - val_accuracy: 0.7613\n",
            "Epoch 255/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6828 - accuracy: 0.7719 - val_loss: 0.7269 - val_accuracy: 0.7647\n",
            "Epoch 256/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6876 - accuracy: 0.7649 - val_loss: 0.7395 - val_accuracy: 0.7624\n",
            "Epoch 257/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6906 - accuracy: 0.7694 - val_loss: 0.7455 - val_accuracy: 0.7619\n",
            "Epoch 258/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6814 - accuracy: 0.7674 - val_loss: 0.7321 - val_accuracy: 0.7562\n",
            "Epoch 259/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6682 - accuracy: 0.7742 - val_loss: 0.7415 - val_accuracy: 0.7579\n",
            "Epoch 260/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6805 - accuracy: 0.7709 - val_loss: 0.7342 - val_accuracy: 0.7647\n",
            "Epoch 261/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6752 - accuracy: 0.7692 - val_loss: 0.7363 - val_accuracy: 0.7636\n",
            "Epoch 262/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6880 - accuracy: 0.7642 - val_loss: 0.7387 - val_accuracy: 0.7527\n",
            "Epoch 263/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6827 - accuracy: 0.7692 - val_loss: 0.7519 - val_accuracy: 0.7539\n",
            "Epoch 264/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6826 - accuracy: 0.7684 - val_loss: 0.7337 - val_accuracy: 0.7676\n",
            "Epoch 265/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6843 - accuracy: 0.7717 - val_loss: 0.7359 - val_accuracy: 0.7642\n",
            "Epoch 266/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6834 - accuracy: 0.7718 - val_loss: 0.7426 - val_accuracy: 0.7550\n",
            "Epoch 267/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6831 - accuracy: 0.7686 - val_loss: 0.7301 - val_accuracy: 0.7607\n",
            "Epoch 268/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6826 - accuracy: 0.7701 - val_loss: 0.7532 - val_accuracy: 0.7527\n",
            "Epoch 269/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6831 - accuracy: 0.7669 - val_loss: 0.7476 - val_accuracy: 0.7590\n",
            "Epoch 270/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6842 - accuracy: 0.7632 - val_loss: 0.7511 - val_accuracy: 0.7653\n",
            "Epoch 271/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6683 - accuracy: 0.7729 - val_loss: 0.7338 - val_accuracy: 0.7682\n",
            "Epoch 272/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6715 - accuracy: 0.7709 - val_loss: 0.7283 - val_accuracy: 0.7687\n",
            "Epoch 273/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6767 - accuracy: 0.7658 - val_loss: 0.7371 - val_accuracy: 0.7613\n",
            "Epoch 274/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6813 - accuracy: 0.7638 - val_loss: 0.7411 - val_accuracy: 0.7613\n",
            "Epoch 275/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6813 - accuracy: 0.7649 - val_loss: 0.7498 - val_accuracy: 0.7642\n",
            "Epoch 276/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6747 - accuracy: 0.7725 - val_loss: 0.7318 - val_accuracy: 0.7596\n",
            "Epoch 277/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6603 - accuracy: 0.7774 - val_loss: 0.7404 - val_accuracy: 0.7596\n",
            "Epoch 278/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6740 - accuracy: 0.7679 - val_loss: 0.7370 - val_accuracy: 0.7642\n",
            "Epoch 279/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6899 - accuracy: 0.7714 - val_loss: 0.7657 - val_accuracy: 0.7556\n",
            "Epoch 280/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6757 - accuracy: 0.7709 - val_loss: 0.7595 - val_accuracy: 0.7579\n",
            "Epoch 281/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6892 - accuracy: 0.7648 - val_loss: 0.7269 - val_accuracy: 0.7613\n",
            "Epoch 282/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6796 - accuracy: 0.7641 - val_loss: 0.7534 - val_accuracy: 0.7533\n",
            "Epoch 283/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.7701 - val_loss: 0.7412 - val_accuracy: 0.7567\n",
            "Epoch 284/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6844 - accuracy: 0.7701 - val_loss: 0.7415 - val_accuracy: 0.7607\n",
            "Epoch 285/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6743 - accuracy: 0.7714 - val_loss: 0.7400 - val_accuracy: 0.7590\n",
            "Epoch 286/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6879 - accuracy: 0.7668 - val_loss: 0.7471 - val_accuracy: 0.7602\n",
            "Epoch 287/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6694 - accuracy: 0.7712 - val_loss: 0.7314 - val_accuracy: 0.7624\n",
            "Epoch 288/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6672 - accuracy: 0.7727 - val_loss: 0.7360 - val_accuracy: 0.7624\n",
            "Epoch 289/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6719 - accuracy: 0.7755 - val_loss: 0.7350 - val_accuracy: 0.7659\n",
            "Epoch 290/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6598 - accuracy: 0.7739 - val_loss: 0.7436 - val_accuracy: 0.7550\n",
            "Epoch 291/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6595 - accuracy: 0.7738 - val_loss: 0.7228 - val_accuracy: 0.7693\n",
            "Epoch 292/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6583 - accuracy: 0.7737 - val_loss: 0.7410 - val_accuracy: 0.7556\n",
            "Epoch 293/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6693 - accuracy: 0.7721 - val_loss: 0.7397 - val_accuracy: 0.7539\n",
            "Epoch 294/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6587 - accuracy: 0.7798 - val_loss: 0.7468 - val_accuracy: 0.7533\n",
            "Epoch 295/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6502 - accuracy: 0.7832 - val_loss: 0.7442 - val_accuracy: 0.7613\n",
            "Epoch 296/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6703 - accuracy: 0.7752 - val_loss: 0.7491 - val_accuracy: 0.7584\n",
            "Epoch 297/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6525 - accuracy: 0.7800 - val_loss: 0.7405 - val_accuracy: 0.7579\n",
            "Epoch 298/300\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6644 - accuracy: 0.7704 - val_loss: 0.7438 - val_accuracy: 0.7682\n",
            "Epoch 299/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6597 - accuracy: 0.7768 - val_loss: 0.7437 - val_accuracy: 0.7613\n",
            "Epoch 300/300\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6614 - accuracy: 0.7708 - val_loss: 0.7358 - val_accuracy: 0.7693\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe80010c390>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "                               \n",
        "model.add(tf.keras.layers.Conv1D(16,2, activation ='relu', input_shape= (20, 1)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "              \n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32))\n",
        "\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=\"Adam\",loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])\n",
        "\n",
        "num_epochs = 300\n",
        "num_batch_size = 64\n",
        "\n",
        "model.fit(\n",
        "          x_train, \n",
        "          y_train, \n",
        "          batch_size=num_batch_size, \n",
        "          epochs=num_epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[callbacks]\n",
        "         )"
      ],
      "metadata": {
        "id": "AnWryOgOpfoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9581370-04d0-4b6a-eca1-274474cdf697"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_17 (Conv1D)          (None, 19, 16)            48        \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 304)               0         \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 128)               39040     \n",
            "                                                                 \n",
            " activation_56 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " activation_57 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " activation_58 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            " activation_59 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66,266\n",
            "Trainable params: 66,266\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 2.0801 - accuracy: 0.2322 - val_loss: 1.7444 - val_accuracy: 0.3875\n",
            "Epoch 2/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.7229 - accuracy: 0.3674 - val_loss: 1.5895 - val_accuracy: 0.4419\n",
            "Epoch 3/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6168 - accuracy: 0.4198 - val_loss: 1.5023 - val_accuracy: 0.4637\n",
            "Epoch 4/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5528 - accuracy: 0.4417 - val_loss: 1.4397 - val_accuracy: 0.4860\n",
            "Epoch 5/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5042 - accuracy: 0.4626 - val_loss: 1.3909 - val_accuracy: 0.5180\n",
            "Epoch 6/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4309 - accuracy: 0.4948 - val_loss: 1.3371 - val_accuracy: 0.5386\n",
            "Epoch 7/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3879 - accuracy: 0.5144 - val_loss: 1.2844 - val_accuracy: 0.5570\n",
            "Epoch 8/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3397 - accuracy: 0.5356 - val_loss: 1.2322 - val_accuracy: 0.5764\n",
            "Epoch 9/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2755 - accuracy: 0.5560 - val_loss: 1.1752 - val_accuracy: 0.5982\n",
            "Epoch 10/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2308 - accuracy: 0.5782 - val_loss: 1.1245 - val_accuracy: 0.6199\n",
            "Epoch 11/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1890 - accuracy: 0.5948 - val_loss: 1.1118 - val_accuracy: 0.6319\n",
            "Epoch 12/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1513 - accuracy: 0.6110 - val_loss: 1.0483 - val_accuracy: 0.6566\n",
            "Epoch 13/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1177 - accuracy: 0.6175 - val_loss: 1.0430 - val_accuracy: 0.6634\n",
            "Epoch 14/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0879 - accuracy: 0.6302 - val_loss: 1.0021 - val_accuracy: 0.6732\n",
            "Epoch 15/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0559 - accuracy: 0.6442 - val_loss: 0.9748 - val_accuracy: 0.6829\n",
            "Epoch 16/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0265 - accuracy: 0.6560 - val_loss: 0.9577 - val_accuracy: 0.6812\n",
            "Epoch 17/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0091 - accuracy: 0.6654 - val_loss: 0.9221 - val_accuracy: 0.6955\n",
            "Epoch 18/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9761 - accuracy: 0.6679 - val_loss: 0.9459 - val_accuracy: 0.6800\n",
            "Epoch 19/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9680 - accuracy: 0.6700 - val_loss: 0.8930 - val_accuracy: 0.7092\n",
            "Epoch 20/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9301 - accuracy: 0.6863 - val_loss: 0.8848 - val_accuracy: 0.7023\n",
            "Epoch 21/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9280 - accuracy: 0.6893 - val_loss: 0.8942 - val_accuracy: 0.7098\n",
            "Epoch 22/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9021 - accuracy: 0.6932 - val_loss: 0.8572 - val_accuracy: 0.7258\n",
            "Epoch 23/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8786 - accuracy: 0.7072 - val_loss: 0.8565 - val_accuracy: 0.7201\n",
            "Epoch 24/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8675 - accuracy: 0.7077 - val_loss: 0.8589 - val_accuracy: 0.7178\n",
            "Epoch 25/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8665 - accuracy: 0.7145 - val_loss: 0.8420 - val_accuracy: 0.7327\n",
            "Epoch 26/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8655 - accuracy: 0.7074 - val_loss: 0.8461 - val_accuracy: 0.7264\n",
            "Epoch 27/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8205 - accuracy: 0.7211 - val_loss: 0.8209 - val_accuracy: 0.7338\n",
            "Epoch 28/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8072 - accuracy: 0.7297 - val_loss: 0.8310 - val_accuracy: 0.7378\n",
            "Epoch 29/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7925 - accuracy: 0.7326 - val_loss: 0.8176 - val_accuracy: 0.7407\n",
            "Epoch 30/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.7839 - accuracy: 0.7416 - val_loss: 0.8101 - val_accuracy: 0.7384\n",
            "Epoch 31/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7785 - accuracy: 0.7445 - val_loss: 0.8032 - val_accuracy: 0.7430\n",
            "Epoch 32/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.7668 - accuracy: 0.7452 - val_loss: 0.8168 - val_accuracy: 0.7321\n",
            "Epoch 33/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7578 - accuracy: 0.7506 - val_loss: 0.8016 - val_accuracy: 0.7481\n",
            "Epoch 34/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7266 - accuracy: 0.7581 - val_loss: 0.8108 - val_accuracy: 0.7527\n",
            "Epoch 35/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7369 - accuracy: 0.7485 - val_loss: 0.7792 - val_accuracy: 0.7567\n",
            "Epoch 36/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7220 - accuracy: 0.7631 - val_loss: 0.8046 - val_accuracy: 0.7510\n",
            "Epoch 37/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7139 - accuracy: 0.7593 - val_loss: 0.8016 - val_accuracy: 0.7527\n",
            "Epoch 38/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7187 - accuracy: 0.7631 - val_loss: 0.7759 - val_accuracy: 0.7584\n",
            "Epoch 39/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7098 - accuracy: 0.7603 - val_loss: 0.7732 - val_accuracy: 0.7544\n",
            "Epoch 40/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7033 - accuracy: 0.7655 - val_loss: 0.7809 - val_accuracy: 0.7602\n",
            "Epoch 41/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6766 - accuracy: 0.7754 - val_loss: 0.7589 - val_accuracy: 0.7630\n",
            "Epoch 42/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6808 - accuracy: 0.7711 - val_loss: 0.7508 - val_accuracy: 0.7659\n",
            "Epoch 43/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6818 - accuracy: 0.7702 - val_loss: 0.7623 - val_accuracy: 0.7624\n",
            "Epoch 44/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6693 - accuracy: 0.7729 - val_loss: 0.7470 - val_accuracy: 0.7584\n",
            "Epoch 45/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6678 - accuracy: 0.7782 - val_loss: 0.7609 - val_accuracy: 0.7613\n",
            "Epoch 46/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6376 - accuracy: 0.7837 - val_loss: 0.7390 - val_accuracy: 0.7722\n",
            "Epoch 47/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.7824 - val_loss: 0.7476 - val_accuracy: 0.7693\n",
            "Epoch 48/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6721 - accuracy: 0.7728 - val_loss: 0.7475 - val_accuracy: 0.7676\n",
            "Epoch 49/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6221 - accuracy: 0.7870 - val_loss: 0.7522 - val_accuracy: 0.7665\n",
            "Epoch 50/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6219 - accuracy: 0.7934 - val_loss: 0.7508 - val_accuracy: 0.7722\n",
            "Epoch 51/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6140 - accuracy: 0.7928 - val_loss: 0.7380 - val_accuracy: 0.7728\n",
            "Epoch 52/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6019 - accuracy: 0.7967 - val_loss: 0.7423 - val_accuracy: 0.7796\n",
            "Epoch 53/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6050 - accuracy: 0.7953 - val_loss: 0.7409 - val_accuracy: 0.7699\n",
            "Epoch 54/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6026 - accuracy: 0.7964 - val_loss: 0.7440 - val_accuracy: 0.7647\n",
            "Epoch 55/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5863 - accuracy: 0.8033 - val_loss: 0.7358 - val_accuracy: 0.7722\n",
            "Epoch 56/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6039 - accuracy: 0.7921 - val_loss: 0.7206 - val_accuracy: 0.7722\n",
            "Epoch 57/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5964 - accuracy: 0.8027 - val_loss: 0.7029 - val_accuracy: 0.7762\n",
            "Epoch 58/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5828 - accuracy: 0.8016 - val_loss: 0.7299 - val_accuracy: 0.7773\n",
            "Epoch 59/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5639 - accuracy: 0.8100 - val_loss: 0.7230 - val_accuracy: 0.7785\n",
            "Epoch 60/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.8024 - val_loss: 0.7396 - val_accuracy: 0.7722\n",
            "Epoch 61/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.8089 - val_loss: 0.7570 - val_accuracy: 0.7785\n",
            "Epoch 62/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5590 - accuracy: 0.8083 - val_loss: 0.7276 - val_accuracy: 0.7785\n",
            "Epoch 63/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.8097 - val_loss: 0.7181 - val_accuracy: 0.7773\n",
            "Epoch 64/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5519 - accuracy: 0.8146 - val_loss: 0.7159 - val_accuracy: 0.7836\n",
            "Epoch 65/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5550 - accuracy: 0.8122 - val_loss: 0.7291 - val_accuracy: 0.7831\n",
            "Epoch 66/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.8166 - val_loss: 0.7552 - val_accuracy: 0.7768\n",
            "Epoch 67/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5335 - accuracy: 0.8230 - val_loss: 0.7204 - val_accuracy: 0.7836\n",
            "Epoch 68/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.8236 - val_loss: 0.7068 - val_accuracy: 0.7819\n",
            "Epoch 69/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.8218 - val_loss: 0.7183 - val_accuracy: 0.7825\n",
            "Epoch 70/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5299 - accuracy: 0.8183 - val_loss: 0.7269 - val_accuracy: 0.7842\n",
            "Epoch 71/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.8209 - val_loss: 0.7040 - val_accuracy: 0.7859\n",
            "Epoch 72/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.8256 - val_loss: 0.7113 - val_accuracy: 0.7882\n",
            "Epoch 73/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.8302 - val_loss: 0.7055 - val_accuracy: 0.7876\n",
            "Epoch 74/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.8331 - val_loss: 0.7200 - val_accuracy: 0.7859\n",
            "Epoch 75/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5185 - accuracy: 0.8245 - val_loss: 0.7052 - val_accuracy: 0.7848\n",
            "Epoch 76/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.8268 - val_loss: 0.7157 - val_accuracy: 0.7750\n",
            "Epoch 77/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4964 - accuracy: 0.8298 - val_loss: 0.7182 - val_accuracy: 0.7882\n",
            "Epoch 78/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.8314 - val_loss: 0.7011 - val_accuracy: 0.7922\n",
            "Epoch 79/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.8379 - val_loss: 0.7144 - val_accuracy: 0.7842\n",
            "Epoch 80/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4835 - accuracy: 0.8402 - val_loss: 0.6995 - val_accuracy: 0.7865\n",
            "Epoch 81/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.8369 - val_loss: 0.7194 - val_accuracy: 0.7853\n",
            "Epoch 82/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.8252 - val_loss: 0.7108 - val_accuracy: 0.7865\n",
            "Epoch 83/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.8388 - val_loss: 0.7305 - val_accuracy: 0.7939\n",
            "Epoch 84/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.8407 - val_loss: 0.7114 - val_accuracy: 0.7876\n",
            "Epoch 85/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.8414 - val_loss: 0.7061 - val_accuracy: 0.7876\n",
            "Epoch 86/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.8427 - val_loss: 0.7115 - val_accuracy: 0.7939\n",
            "Epoch 87/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.8392 - val_loss: 0.7182 - val_accuracy: 0.7962\n",
            "Epoch 88/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.8417 - val_loss: 0.7310 - val_accuracy: 0.7905\n",
            "Epoch 89/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.8418 - val_loss: 0.7120 - val_accuracy: 0.7962\n",
            "Epoch 90/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.8481 - val_loss: 0.7335 - val_accuracy: 0.7865\n",
            "Epoch 91/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.8354 - val_loss: 0.7381 - val_accuracy: 0.7871\n",
            "Epoch 92/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.8465 - val_loss: 0.7431 - val_accuracy: 0.7836\n",
            "Epoch 93/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.8455 - val_loss: 0.7041 - val_accuracy: 0.7905\n",
            "Epoch 94/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.8488 - val_loss: 0.7284 - val_accuracy: 0.7888\n",
            "Epoch 95/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.8454 - val_loss: 0.7157 - val_accuracy: 0.7956\n",
            "Epoch 96/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8485 - val_loss: 0.7271 - val_accuracy: 0.8002\n",
            "Epoch 97/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.8471 - val_loss: 0.7302 - val_accuracy: 0.7934\n",
            "Epoch 98/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.8558 - val_loss: 0.7017 - val_accuracy: 0.8019\n",
            "Epoch 99/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.8517 - val_loss: 0.7165 - val_accuracy: 0.7991\n",
            "Epoch 100/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.8533 - val_loss: 0.7255 - val_accuracy: 0.7899\n",
            "Epoch 101/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.8474 - val_loss: 0.7093 - val_accuracy: 0.7991\n",
            "Epoch 102/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4457 - accuracy: 0.8482 - val_loss: 0.7199 - val_accuracy: 0.7876\n",
            "Epoch 103/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.8492 - val_loss: 0.7177 - val_accuracy: 0.7939\n",
            "Epoch 104/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.8515 - val_loss: 0.6924 - val_accuracy: 0.7968\n",
            "Epoch 105/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8524 - val_loss: 0.7145 - val_accuracy: 0.7939\n",
            "Epoch 106/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.8503 - val_loss: 0.6951 - val_accuracy: 0.7997\n",
            "Epoch 107/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8540 - val_loss: 0.7378 - val_accuracy: 0.8025\n",
            "Epoch 108/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.8527 - val_loss: 0.7149 - val_accuracy: 0.8008\n",
            "Epoch 109/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8601 - val_loss: 0.7499 - val_accuracy: 0.7974\n",
            "Epoch 110/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8600 - val_loss: 0.7140 - val_accuracy: 0.7974\n",
            "Epoch 111/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8537 - val_loss: 0.6977 - val_accuracy: 0.7945\n",
            "Epoch 112/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8628 - val_loss: 0.7241 - val_accuracy: 0.7916\n",
            "Epoch 113/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.8533 - val_loss: 0.7070 - val_accuracy: 0.7922\n",
            "Epoch 114/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.8567 - val_loss: 0.7105 - val_accuracy: 0.7956\n",
            "Epoch 115/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.8591 - val_loss: 0.7132 - val_accuracy: 0.7905\n",
            "Epoch 116/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8627 - val_loss: 0.7307 - val_accuracy: 0.7922\n",
            "Epoch 117/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8601 - val_loss: 0.7157 - val_accuracy: 0.8002\n",
            "Epoch 118/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8573 - val_loss: 0.7265 - val_accuracy: 0.7945\n",
            "Epoch 119/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.8676 - val_loss: 0.7046 - val_accuracy: 0.8008\n",
            "Epoch 120/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8636 - val_loss: 0.7351 - val_accuracy: 0.7997\n",
            "Epoch 121/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8657 - val_loss: 0.7449 - val_accuracy: 0.7991\n",
            "Epoch 122/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3832 - accuracy: 0.8657 - val_loss: 0.7506 - val_accuracy: 0.7968\n",
            "Epoch 123/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8664 - val_loss: 0.7563 - val_accuracy: 0.7894\n",
            "Epoch 124/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3914 - accuracy: 0.8671 - val_loss: 0.7207 - val_accuracy: 0.7991\n",
            "Epoch 125/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8706 - val_loss: 0.7199 - val_accuracy: 0.8060\n",
            "Epoch 126/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8640 - val_loss: 0.7154 - val_accuracy: 0.7962\n",
            "Epoch 127/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.8700 - val_loss: 0.7398 - val_accuracy: 0.8048\n",
            "Epoch 128/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3857 - accuracy: 0.8667 - val_loss: 0.7431 - val_accuracy: 0.7939\n",
            "Epoch 129/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8660 - val_loss: 0.7457 - val_accuracy: 0.7939\n",
            "Epoch 130/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.8674 - val_loss: 0.7495 - val_accuracy: 0.7899\n",
            "Epoch 131/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8614 - val_loss: 0.7387 - val_accuracy: 0.7956\n",
            "Epoch 132/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8746 - val_loss: 0.7499 - val_accuracy: 0.8014\n",
            "Epoch 133/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3740 - accuracy: 0.8720 - val_loss: 0.7434 - val_accuracy: 0.7974\n",
            "Epoch 134/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3796 - accuracy: 0.8743 - val_loss: 0.7391 - val_accuracy: 0.8014\n",
            "Epoch 135/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3601 - accuracy: 0.8734 - val_loss: 0.7620 - val_accuracy: 0.7934\n",
            "Epoch 136/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8663 - val_loss: 0.7275 - val_accuracy: 0.7945\n",
            "Epoch 137/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3722 - accuracy: 0.8733 - val_loss: 0.7346 - val_accuracy: 0.8031\n",
            "Epoch 138/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3804 - accuracy: 0.8676 - val_loss: 0.7476 - val_accuracy: 0.7979\n",
            "Epoch 139/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3771 - accuracy: 0.8734 - val_loss: 0.7350 - val_accuracy: 0.8048\n",
            "Epoch 140/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3669 - accuracy: 0.8750 - val_loss: 0.7560 - val_accuracy: 0.8008\n",
            "Epoch 141/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3865 - accuracy: 0.8679 - val_loss: 0.7245 - val_accuracy: 0.7974\n",
            "Epoch 142/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3765 - accuracy: 0.8759 - val_loss: 0.7537 - val_accuracy: 0.7991\n",
            "Epoch 143/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3469 - accuracy: 0.8743 - val_loss: 0.7563 - val_accuracy: 0.8014\n",
            "Epoch 144/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3751 - accuracy: 0.8707 - val_loss: 0.8094 - val_accuracy: 0.7974\n",
            "Epoch 145/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8689 - val_loss: 0.7398 - val_accuracy: 0.8060\n",
            "Epoch 146/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3872 - accuracy: 0.8693 - val_loss: 0.7451 - val_accuracy: 0.8037\n",
            "Epoch 147/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3595 - accuracy: 0.8816 - val_loss: 0.7421 - val_accuracy: 0.8014\n",
            "Epoch 148/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.8838 - val_loss: 0.7218 - val_accuracy: 0.8048\n",
            "Epoch 149/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8802 - val_loss: 0.7507 - val_accuracy: 0.8008\n",
            "Epoch 150/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3753 - accuracy: 0.8749 - val_loss: 0.7473 - val_accuracy: 0.7997\n",
            "Epoch 151/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3568 - accuracy: 0.8835 - val_loss: 0.7710 - val_accuracy: 0.8048\n",
            "Epoch 152/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3547 - accuracy: 0.8816 - val_loss: 0.7228 - val_accuracy: 0.8071\n",
            "Epoch 153/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3622 - accuracy: 0.8810 - val_loss: 0.7450 - val_accuracy: 0.8054\n",
            "Epoch 154/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.8785 - val_loss: 0.7673 - val_accuracy: 0.8054\n",
            "Epoch 155/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3581 - accuracy: 0.8868 - val_loss: 0.7484 - val_accuracy: 0.8082\n",
            "Epoch 156/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3718 - accuracy: 0.8703 - val_loss: 0.7471 - val_accuracy: 0.7979\n",
            "Epoch 157/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3519 - accuracy: 0.8795 - val_loss: 0.7441 - val_accuracy: 0.8002\n",
            "Epoch 158/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3461 - accuracy: 0.8819 - val_loss: 0.7616 - val_accuracy: 0.8014\n",
            "Epoch 159/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8825 - val_loss: 0.7567 - val_accuracy: 0.7991\n",
            "Epoch 160/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3523 - accuracy: 0.8817 - val_loss: 0.7404 - val_accuracy: 0.8054\n",
            "Epoch 161/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3485 - accuracy: 0.8792 - val_loss: 0.7457 - val_accuracy: 0.8042\n",
            "Epoch 162/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3647 - accuracy: 0.8757 - val_loss: 0.7349 - val_accuracy: 0.8065\n",
            "Epoch 163/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3719 - accuracy: 0.8763 - val_loss: 0.7558 - val_accuracy: 0.7991\n",
            "Epoch 164/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3545 - accuracy: 0.8820 - val_loss: 0.7489 - val_accuracy: 0.8071\n",
            "Epoch 165/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3487 - accuracy: 0.8853 - val_loss: 0.7486 - val_accuracy: 0.8060\n",
            "Epoch 166/300\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.3480 - accuracy: 0.8797 - val_loss: 0.7604 - val_accuracy: 0.7979\n",
            "Epoch 167/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.3508 - accuracy: 0.8756 - val_loss: 0.7465 - val_accuracy: 0.8014\n",
            "Epoch 168/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3527 - accuracy: 0.8855 - val_loss: 0.7259 - val_accuracy: 0.8105\n",
            "Epoch 169/300\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.3434 - accuracy: 0.8885 - val_loss: 0.7333 - val_accuracy: 0.8145\n",
            "Epoch 170/300\n",
            "110/110 [==============================] - 1s 4ms/step - loss: 0.3524 - accuracy: 0.8845 - val_loss: 0.7420 - val_accuracy: 0.8094\n",
            "Epoch 171/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3486 - accuracy: 0.8846 - val_loss: 0.7489 - val_accuracy: 0.8037\n",
            "Epoch 172/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3489 - accuracy: 0.8830 - val_loss: 0.7425 - val_accuracy: 0.8100\n",
            "Epoch 173/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3250 - accuracy: 0.8911 - val_loss: 0.7200 - val_accuracy: 0.8037\n",
            "Epoch 174/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3500 - accuracy: 0.8839 - val_loss: 0.7412 - val_accuracy: 0.8077\n",
            "Epoch 175/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8833 - val_loss: 0.7223 - val_accuracy: 0.8054\n",
            "Epoch 176/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3391 - accuracy: 0.8836 - val_loss: 0.7344 - val_accuracy: 0.8082\n",
            "Epoch 177/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.8805 - val_loss: 0.7551 - val_accuracy: 0.8037\n",
            "Epoch 178/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3406 - accuracy: 0.8843 - val_loss: 0.7088 - val_accuracy: 0.8060\n",
            "Epoch 179/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3256 - accuracy: 0.8889 - val_loss: 0.7711 - val_accuracy: 0.7945\n",
            "Epoch 180/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3286 - accuracy: 0.8869 - val_loss: 0.7621 - val_accuracy: 0.7997\n",
            "Epoch 181/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3383 - accuracy: 0.8870 - val_loss: 0.7510 - val_accuracy: 0.8037\n",
            "Epoch 182/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3431 - accuracy: 0.8878 - val_loss: 0.7748 - val_accuracy: 0.7979\n",
            "Epoch 183/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.8827 - val_loss: 0.7451 - val_accuracy: 0.8014\n",
            "Epoch 184/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3010 - accuracy: 0.8968 - val_loss: 0.7815 - val_accuracy: 0.8048\n",
            "Epoch 185/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3205 - accuracy: 0.8935 - val_loss: 0.7821 - val_accuracy: 0.8071\n",
            "Epoch 186/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8856 - val_loss: 0.7663 - val_accuracy: 0.8094\n",
            "Epoch 187/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3285 - accuracy: 0.8898 - val_loss: 0.7823 - val_accuracy: 0.8025\n",
            "Epoch 188/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3216 - accuracy: 0.8915 - val_loss: 0.7714 - val_accuracy: 0.8054\n",
            "Epoch 189/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3221 - accuracy: 0.8922 - val_loss: 0.7805 - val_accuracy: 0.8060\n",
            "Epoch 190/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3408 - accuracy: 0.8870 - val_loss: 0.7821 - val_accuracy: 0.8014\n",
            "Epoch 191/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3289 - accuracy: 0.8929 - val_loss: 0.7763 - val_accuracy: 0.8071\n",
            "Epoch 192/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3153 - accuracy: 0.8996 - val_loss: 0.7816 - val_accuracy: 0.8082\n",
            "Epoch 193/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3238 - accuracy: 0.8879 - val_loss: 0.7456 - val_accuracy: 0.8082\n",
            "Epoch 194/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3263 - accuracy: 0.8916 - val_loss: 0.7471 - val_accuracy: 0.8105\n",
            "Epoch 195/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3231 - accuracy: 0.8902 - val_loss: 0.7475 - val_accuracy: 0.8168\n",
            "Epoch 196/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3242 - accuracy: 0.8912 - val_loss: 0.7292 - val_accuracy: 0.8134\n",
            "Epoch 197/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.8953 - val_loss: 0.7422 - val_accuracy: 0.8071\n",
            "Epoch 198/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.8951 - val_loss: 0.7498 - val_accuracy: 0.8002\n",
            "Epoch 199/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3291 - accuracy: 0.8895 - val_loss: 0.7513 - val_accuracy: 0.8037\n",
            "Epoch 200/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3059 - accuracy: 0.8982 - val_loss: 0.7672 - val_accuracy: 0.8088\n",
            "Epoch 201/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3338 - accuracy: 0.8878 - val_loss: 0.7650 - val_accuracy: 0.8082\n",
            "Epoch 202/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3176 - accuracy: 0.8953 - val_loss: 0.7403 - val_accuracy: 0.8060\n",
            "Epoch 203/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3014 - accuracy: 0.8975 - val_loss: 0.7778 - val_accuracy: 0.8025\n",
            "Epoch 204/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3182 - accuracy: 0.8969 - val_loss: 0.7820 - val_accuracy: 0.8014\n",
            "Epoch 205/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.8945 - val_loss: 0.7698 - val_accuracy: 0.8037\n",
            "Epoch 206/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3187 - accuracy: 0.8919 - val_loss: 0.7707 - val_accuracy: 0.7997\n",
            "Epoch 207/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3040 - accuracy: 0.9002 - val_loss: 0.7916 - val_accuracy: 0.8031\n",
            "Epoch 208/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3196 - accuracy: 0.8943 - val_loss: 0.7852 - val_accuracy: 0.8100\n",
            "Epoch 209/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3161 - accuracy: 0.8955 - val_loss: 0.7692 - val_accuracy: 0.8168\n",
            "Epoch 210/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3227 - accuracy: 0.8909 - val_loss: 0.7584 - val_accuracy: 0.8094\n",
            "Epoch 211/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3137 - accuracy: 0.8956 - val_loss: 0.7754 - val_accuracy: 0.8163\n",
            "Epoch 212/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3021 - accuracy: 0.8986 - val_loss: 0.7453 - val_accuracy: 0.8180\n",
            "Epoch 213/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3046 - accuracy: 0.8992 - val_loss: 0.7767 - val_accuracy: 0.8031\n",
            "Epoch 214/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3036 - accuracy: 0.8985 - val_loss: 0.7908 - val_accuracy: 0.7974\n",
            "Epoch 215/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3183 - accuracy: 0.8943 - val_loss: 0.7299 - val_accuracy: 0.8094\n",
            "Epoch 216/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2929 - accuracy: 0.9026 - val_loss: 0.7758 - val_accuracy: 0.8145\n",
            "Epoch 217/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3124 - accuracy: 0.8974 - val_loss: 0.7749 - val_accuracy: 0.8111\n",
            "Epoch 218/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3294 - accuracy: 0.8931 - val_loss: 0.7802 - val_accuracy: 0.8065\n",
            "Epoch 219/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3000 - accuracy: 0.9002 - val_loss: 0.7923 - val_accuracy: 0.8014\n",
            "Epoch 220/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3084 - accuracy: 0.8941 - val_loss: 0.7596 - val_accuracy: 0.8048\n",
            "Epoch 221/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3116 - accuracy: 0.8981 - val_loss: 0.7824 - val_accuracy: 0.8100\n",
            "Epoch 222/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2998 - accuracy: 0.8984 - val_loss: 0.8112 - val_accuracy: 0.8111\n",
            "Epoch 223/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3096 - accuracy: 0.8975 - val_loss: 0.7869 - val_accuracy: 0.8088\n",
            "Epoch 224/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3020 - accuracy: 0.8976 - val_loss: 0.7791 - val_accuracy: 0.8077\n",
            "Epoch 225/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2966 - accuracy: 0.9032 - val_loss: 0.7768 - val_accuracy: 0.8122\n",
            "Epoch 226/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2949 - accuracy: 0.9024 - val_loss: 0.7956 - val_accuracy: 0.8071\n",
            "Epoch 227/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2838 - accuracy: 0.9051 - val_loss: 0.8183 - val_accuracy: 0.8082\n",
            "Epoch 228/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3129 - accuracy: 0.8952 - val_loss: 0.7943 - val_accuracy: 0.8100\n",
            "Epoch 229/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3180 - accuracy: 0.8938 - val_loss: 0.7574 - val_accuracy: 0.8185\n",
            "Epoch 230/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2990 - accuracy: 0.9012 - val_loss: 0.7903 - val_accuracy: 0.8094\n",
            "Epoch 231/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2951 - accuracy: 0.9001 - val_loss: 0.7734 - val_accuracy: 0.8140\n",
            "Epoch 232/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3009 - accuracy: 0.9015 - val_loss: 0.7834 - val_accuracy: 0.8065\n",
            "Epoch 233/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3034 - accuracy: 0.8974 - val_loss: 0.7558 - val_accuracy: 0.8111\n",
            "Epoch 234/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2993 - accuracy: 0.9006 - val_loss: 0.7706 - val_accuracy: 0.8117\n",
            "Epoch 235/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2902 - accuracy: 0.9062 - val_loss: 0.7763 - val_accuracy: 0.8071\n",
            "Epoch 236/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2840 - accuracy: 0.9049 - val_loss: 0.8045 - val_accuracy: 0.8082\n",
            "Epoch 237/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3053 - accuracy: 0.8991 - val_loss: 0.7987 - val_accuracy: 0.8105\n",
            "Epoch 238/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2937 - accuracy: 0.8991 - val_loss: 0.8260 - val_accuracy: 0.8002\n",
            "Epoch 239/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2953 - accuracy: 0.9042 - val_loss: 0.8078 - val_accuracy: 0.8071\n",
            "Epoch 240/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3048 - accuracy: 0.9025 - val_loss: 0.7958 - val_accuracy: 0.8082\n",
            "Epoch 241/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.3039 - accuracy: 0.9049 - val_loss: 0.8017 - val_accuracy: 0.8077\n",
            "Epoch 242/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.2900 - accuracy: 0.9039 - val_loss: 0.7906 - val_accuracy: 0.8111\n",
            "Epoch 243/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.2917 - accuracy: 0.9018 - val_loss: 0.8037 - val_accuracy: 0.8157\n",
            "Epoch 244/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.2953 - accuracy: 0.9011 - val_loss: 0.7911 - val_accuracy: 0.8042\n",
            "Epoch 245/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2871 - accuracy: 0.9085 - val_loss: 0.8048 - val_accuracy: 0.8134\n",
            "Epoch 246/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2963 - accuracy: 0.9006 - val_loss: 0.8032 - val_accuracy: 0.8014\n",
            "Epoch 247/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2953 - accuracy: 0.9031 - val_loss: 0.7644 - val_accuracy: 0.8082\n",
            "Epoch 248/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3026 - accuracy: 0.8971 - val_loss: 0.8238 - val_accuracy: 0.8134\n",
            "Epoch 249/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2794 - accuracy: 0.9059 - val_loss: 0.8383 - val_accuracy: 0.8014\n",
            "Epoch 250/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.8986 - val_loss: 0.7842 - val_accuracy: 0.8088\n",
            "Epoch 251/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2910 - accuracy: 0.8995 - val_loss: 0.7748 - val_accuracy: 0.8048\n",
            "Epoch 252/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2737 - accuracy: 0.9121 - val_loss: 0.8014 - val_accuracy: 0.8122\n",
            "Epoch 253/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2812 - accuracy: 0.9048 - val_loss: 0.8251 - val_accuracy: 0.8060\n",
            "Epoch 254/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2849 - accuracy: 0.9039 - val_loss: 0.8066 - val_accuracy: 0.8145\n",
            "Epoch 255/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2857 - accuracy: 0.9064 - val_loss: 0.7648 - val_accuracy: 0.8145\n",
            "Epoch 256/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2746 - accuracy: 0.9108 - val_loss: 0.7952 - val_accuracy: 0.8122\n",
            "Epoch 257/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2668 - accuracy: 0.9101 - val_loss: 0.7936 - val_accuracy: 0.8163\n",
            "Epoch 258/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2892 - accuracy: 0.9048 - val_loss: 0.8378 - val_accuracy: 0.8088\n",
            "Epoch 259/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3051 - accuracy: 0.9002 - val_loss: 0.7755 - val_accuracy: 0.8088\n",
            "Epoch 260/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2983 - accuracy: 0.9025 - val_loss: 0.7793 - val_accuracy: 0.8197\n",
            "Epoch 261/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2710 - accuracy: 0.9095 - val_loss: 0.7859 - val_accuracy: 0.8100\n",
            "Epoch 262/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2667 - accuracy: 0.9098 - val_loss: 0.8229 - val_accuracy: 0.8065\n",
            "Epoch 263/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2832 - accuracy: 0.9062 - val_loss: 0.8028 - val_accuracy: 0.8140\n",
            "Epoch 264/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3043 - accuracy: 0.8992 - val_loss: 0.7547 - val_accuracy: 0.8140\n",
            "Epoch 265/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2888 - accuracy: 0.9067 - val_loss: 0.7647 - val_accuracy: 0.8105\n",
            "Epoch 266/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2877 - accuracy: 0.9092 - val_loss: 0.7669 - val_accuracy: 0.8065\n",
            "Epoch 267/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2903 - accuracy: 0.9087 - val_loss: 0.7675 - val_accuracy: 0.8042\n",
            "Epoch 268/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2727 - accuracy: 0.9092 - val_loss: 0.7979 - val_accuracy: 0.8128\n",
            "Epoch 269/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2869 - accuracy: 0.9069 - val_loss: 0.7647 - val_accuracy: 0.8197\n",
            "Epoch 270/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2792 - accuracy: 0.9038 - val_loss: 0.8134 - val_accuracy: 0.8082\n",
            "Epoch 271/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2751 - accuracy: 0.9124 - val_loss: 0.7947 - val_accuracy: 0.8185\n",
            "Epoch 272/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2802 - accuracy: 0.9085 - val_loss: 0.7860 - val_accuracy: 0.8226\n",
            "Epoch 273/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2845 - accuracy: 0.9079 - val_loss: 0.7947 - val_accuracy: 0.8191\n",
            "Epoch 274/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2961 - accuracy: 0.9059 - val_loss: 0.7845 - val_accuracy: 0.8077\n",
            "Epoch 275/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2810 - accuracy: 0.9078 - val_loss: 0.7834 - val_accuracy: 0.8151\n",
            "Epoch 276/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2928 - accuracy: 0.9021 - val_loss: 0.7819 - val_accuracy: 0.8145\n",
            "Epoch 277/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2762 - accuracy: 0.9118 - val_loss: 0.7789 - val_accuracy: 0.8163\n",
            "Epoch 278/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2880 - accuracy: 0.9094 - val_loss: 0.8095 - val_accuracy: 0.8180\n",
            "Epoch 279/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2935 - accuracy: 0.9024 - val_loss: 0.7882 - val_accuracy: 0.8163\n",
            "Epoch 280/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2665 - accuracy: 0.9131 - val_loss: 0.8035 - val_accuracy: 0.8203\n",
            "Epoch 281/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2722 - accuracy: 0.9099 - val_loss: 0.8216 - val_accuracy: 0.8157\n",
            "Epoch 282/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2630 - accuracy: 0.9138 - val_loss: 0.8194 - val_accuracy: 0.8082\n",
            "Epoch 283/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2695 - accuracy: 0.9074 - val_loss: 0.7720 - val_accuracy: 0.8140\n",
            "Epoch 284/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2697 - accuracy: 0.9111 - val_loss: 0.8319 - val_accuracy: 0.8128\n",
            "Epoch 285/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2696 - accuracy: 0.9089 - val_loss: 0.8058 - val_accuracy: 0.8191\n",
            "Epoch 286/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2722 - accuracy: 0.9102 - val_loss: 0.8210 - val_accuracy: 0.8071\n",
            "Epoch 287/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2745 - accuracy: 0.9089 - val_loss: 0.8086 - val_accuracy: 0.8122\n",
            "Epoch 288/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2657 - accuracy: 0.9111 - val_loss: 0.8413 - val_accuracy: 0.8128\n",
            "Epoch 289/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2635 - accuracy: 0.9144 - val_loss: 0.8150 - val_accuracy: 0.8254\n",
            "Epoch 290/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2652 - accuracy: 0.9140 - val_loss: 0.8112 - val_accuracy: 0.8277\n",
            "Epoch 291/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2546 - accuracy: 0.9173 - val_loss: 0.7873 - val_accuracy: 0.8128\n",
            "Epoch 292/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2634 - accuracy: 0.9151 - val_loss: 0.8285 - val_accuracy: 0.8168\n",
            "Epoch 293/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2803 - accuracy: 0.9061 - val_loss: 0.8003 - val_accuracy: 0.8105\n",
            "Epoch 294/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2559 - accuracy: 0.9134 - val_loss: 0.8150 - val_accuracy: 0.8180\n",
            "Epoch 295/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2708 - accuracy: 0.9085 - val_loss: 0.8359 - val_accuracy: 0.8088\n",
            "Epoch 296/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2654 - accuracy: 0.9101 - val_loss: 0.8291 - val_accuracy: 0.8180\n",
            "Epoch 297/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2751 - accuracy: 0.9114 - val_loss: 0.8304 - val_accuracy: 0.8140\n",
            "Epoch 298/300\n",
            " 99/110 [==========================>...] - ETA: 0s - loss: 0.2400 - accuracy: 0.9212\n",
            "Reached 60% accuracy so cancelling training!\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2397 - accuracy: 0.9211 - val_loss: 0.8545 - val_accuracy: 0.8117\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe7ec4202d0>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "                                \n",
        "model.add(tf.keras.layers.Conv1D(16,2, activation ='relu', input_shape= (20, 1)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "              \n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32))\n",
        "\n",
        "            \n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=\"Adam\",loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])\n",
        "\n",
        "num_epochs = 300\n",
        "num_batch_size = 64\n",
        "\n",
        "model.fit(\n",
        "          x_train, \n",
        "          y_train, \n",
        "          batch_size=num_batch_size, \n",
        "          epochs=num_epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[callbacks]\n",
        "         )"
      ],
      "metadata": {
        "id": "Vguyylrkpf1q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b13a8bab-4457-4479-a606-830910b65b8f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_18 (Conv1D)          (None, 19, 16)            48        \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 304)               0         \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 64)                19520     \n",
            "                                                                 \n",
            " activation_60 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_45 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " activation_61 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_46 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " activation_62 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_47 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            " activation_63 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 48,858\n",
            "Trainable params: 48,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 2.0730 - accuracy: 0.2102 - val_loss: 1.7792 - val_accuracy: 0.3400\n",
            "Epoch 2/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7548 - accuracy: 0.3469 - val_loss: 1.6081 - val_accuracy: 0.4276\n",
            "Epoch 3/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6307 - accuracy: 0.4082 - val_loss: 1.5469 - val_accuracy: 0.4568\n",
            "Epoch 4/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5586 - accuracy: 0.4359 - val_loss: 1.4564 - val_accuracy: 0.4883\n",
            "Epoch 5/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5049 - accuracy: 0.4667 - val_loss: 1.4001 - val_accuracy: 0.5203\n",
            "Epoch 6/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4576 - accuracy: 0.4852 - val_loss: 1.3759 - val_accuracy: 0.5112\n",
            "Epoch 7/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4017 - accuracy: 0.5104 - val_loss: 1.3199 - val_accuracy: 0.5346\n",
            "Epoch 8/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3891 - accuracy: 0.5127 - val_loss: 1.3214 - val_accuracy: 0.5438\n",
            "Epoch 9/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3332 - accuracy: 0.5356 - val_loss: 1.2545 - val_accuracy: 0.5713\n",
            "Epoch 10/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3091 - accuracy: 0.5523 - val_loss: 1.2130 - val_accuracy: 0.5970\n",
            "Epoch 11/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2867 - accuracy: 0.5602 - val_loss: 1.1765 - val_accuracy: 0.6148\n",
            "Epoch 12/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2522 - accuracy: 0.5711 - val_loss: 1.1563 - val_accuracy: 0.6211\n",
            "Epoch 13/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2340 - accuracy: 0.5717 - val_loss: 1.1521 - val_accuracy: 0.6285\n",
            "Epoch 14/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2013 - accuracy: 0.5924 - val_loss: 1.1072 - val_accuracy: 0.6348\n",
            "Epoch 15/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1793 - accuracy: 0.6010 - val_loss: 1.1075 - val_accuracy: 0.6331\n",
            "Epoch 16/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1662 - accuracy: 0.5971 - val_loss: 1.0900 - val_accuracy: 0.6371\n",
            "Epoch 17/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1471 - accuracy: 0.6099 - val_loss: 1.0614 - val_accuracy: 0.6428\n",
            "Epoch 18/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1242 - accuracy: 0.6162 - val_loss: 1.0416 - val_accuracy: 0.6617\n",
            "Epoch 19/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1227 - accuracy: 0.6175 - val_loss: 1.0244 - val_accuracy: 0.6617\n",
            "Epoch 20/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0806 - accuracy: 0.6332 - val_loss: 1.0406 - val_accuracy: 0.6606\n",
            "Epoch 21/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0945 - accuracy: 0.6293 - val_loss: 1.0265 - val_accuracy: 0.6508\n",
            "Epoch 22/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0826 - accuracy: 0.6349 - val_loss: 1.0133 - val_accuracy: 0.6634\n",
            "Epoch 23/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0607 - accuracy: 0.6387 - val_loss: 0.9927 - val_accuracy: 0.6646\n",
            "Epoch 24/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0510 - accuracy: 0.6445 - val_loss: 0.9874 - val_accuracy: 0.6623\n",
            "Epoch 25/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0427 - accuracy: 0.6437 - val_loss: 0.9929 - val_accuracy: 0.6577\n",
            "Epoch 26/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0326 - accuracy: 0.6561 - val_loss: 0.9762 - val_accuracy: 0.6703\n",
            "Epoch 27/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0185 - accuracy: 0.6560 - val_loss: 0.9740 - val_accuracy: 0.6726\n",
            "Epoch 28/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0157 - accuracy: 0.6528 - val_loss: 0.9744 - val_accuracy: 0.6674\n",
            "Epoch 29/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0024 - accuracy: 0.6633 - val_loss: 0.9645 - val_accuracy: 0.6800\n",
            "Epoch 30/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9993 - accuracy: 0.6598 - val_loss: 0.9532 - val_accuracy: 0.6760\n",
            "Epoch 31/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9874 - accuracy: 0.6664 - val_loss: 0.9359 - val_accuracy: 0.6783\n",
            "Epoch 32/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9805 - accuracy: 0.6616 - val_loss: 0.9343 - val_accuracy: 0.6857\n",
            "Epoch 33/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9708 - accuracy: 0.6717 - val_loss: 0.9290 - val_accuracy: 0.6880\n",
            "Epoch 34/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9672 - accuracy: 0.6714 - val_loss: 0.9162 - val_accuracy: 0.6892\n",
            "Epoch 35/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9616 - accuracy: 0.6673 - val_loss: 0.9325 - val_accuracy: 0.6863\n",
            "Epoch 36/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9705 - accuracy: 0.6747 - val_loss: 0.9161 - val_accuracy: 0.6909\n",
            "Epoch 37/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9381 - accuracy: 0.6775 - val_loss: 0.9138 - val_accuracy: 0.6846\n",
            "Epoch 38/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9414 - accuracy: 0.6799 - val_loss: 0.9064 - val_accuracy: 0.6903\n",
            "Epoch 39/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9293 - accuracy: 0.6875 - val_loss: 0.8979 - val_accuracy: 0.6949\n",
            "Epoch 40/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9295 - accuracy: 0.6819 - val_loss: 0.8972 - val_accuracy: 0.6966\n",
            "Epoch 41/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9133 - accuracy: 0.6860 - val_loss: 0.8818 - val_accuracy: 0.7086\n",
            "Epoch 42/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9178 - accuracy: 0.6866 - val_loss: 0.8840 - val_accuracy: 0.7006\n",
            "Epoch 43/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9098 - accuracy: 0.6863 - val_loss: 0.8746 - val_accuracy: 0.6915\n",
            "Epoch 44/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9003 - accuracy: 0.6919 - val_loss: 0.8786 - val_accuracy: 0.6995\n",
            "Epoch 45/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9034 - accuracy: 0.6901 - val_loss: 0.8686 - val_accuracy: 0.7098\n",
            "Epoch 46/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8907 - accuracy: 0.6948 - val_loss: 0.8762 - val_accuracy: 0.6920\n",
            "Epoch 47/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8871 - accuracy: 0.6976 - val_loss: 0.8745 - val_accuracy: 0.7069\n",
            "Epoch 48/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8967 - accuracy: 0.6999 - val_loss: 0.8511 - val_accuracy: 0.7149\n",
            "Epoch 49/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8750 - accuracy: 0.7055 - val_loss: 0.8714 - val_accuracy: 0.6972\n",
            "Epoch 50/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8687 - accuracy: 0.7039 - val_loss: 0.8364 - val_accuracy: 0.7189\n",
            "Epoch 51/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8743 - accuracy: 0.7034 - val_loss: 0.8625 - val_accuracy: 0.7069\n",
            "Epoch 52/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8619 - accuracy: 0.7037 - val_loss: 0.8319 - val_accuracy: 0.7127\n",
            "Epoch 53/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8658 - accuracy: 0.7018 - val_loss: 0.8360 - val_accuracy: 0.7161\n",
            "Epoch 54/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8657 - accuracy: 0.7047 - val_loss: 0.8295 - val_accuracy: 0.7224\n",
            "Epoch 55/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8520 - accuracy: 0.7034 - val_loss: 0.8309 - val_accuracy: 0.7195\n",
            "Epoch 56/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8474 - accuracy: 0.7087 - val_loss: 0.8545 - val_accuracy: 0.7127\n",
            "Epoch 57/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8552 - accuracy: 0.7091 - val_loss: 0.8187 - val_accuracy: 0.7207\n",
            "Epoch 58/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8330 - accuracy: 0.7243 - val_loss: 0.8308 - val_accuracy: 0.7167\n",
            "Epoch 59/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8502 - accuracy: 0.7088 - val_loss: 0.8180 - val_accuracy: 0.7293\n",
            "Epoch 60/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8382 - accuracy: 0.7180 - val_loss: 0.8482 - val_accuracy: 0.7195\n",
            "Epoch 61/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8361 - accuracy: 0.7181 - val_loss: 0.8254 - val_accuracy: 0.7235\n",
            "Epoch 62/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8150 - accuracy: 0.7231 - val_loss: 0.8311 - val_accuracy: 0.7218\n",
            "Epoch 63/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8272 - accuracy: 0.7254 - val_loss: 0.8194 - val_accuracy: 0.7275\n",
            "Epoch 64/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8237 - accuracy: 0.7065 - val_loss: 0.8176 - val_accuracy: 0.7270\n",
            "Epoch 65/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8186 - accuracy: 0.7195 - val_loss: 0.7963 - val_accuracy: 0.7338\n",
            "Epoch 66/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7987 - accuracy: 0.7288 - val_loss: 0.8162 - val_accuracy: 0.7212\n",
            "Epoch 67/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8098 - accuracy: 0.7237 - val_loss: 0.8166 - val_accuracy: 0.7321\n",
            "Epoch 68/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8010 - accuracy: 0.7260 - val_loss: 0.8034 - val_accuracy: 0.7321\n",
            "Epoch 69/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8057 - accuracy: 0.7268 - val_loss: 0.7942 - val_accuracy: 0.7355\n",
            "Epoch 70/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8051 - accuracy: 0.7248 - val_loss: 0.8004 - val_accuracy: 0.7413\n",
            "Epoch 71/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7871 - accuracy: 0.7253 - val_loss: 0.8081 - val_accuracy: 0.7321\n",
            "Epoch 72/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7997 - accuracy: 0.7240 - val_loss: 0.7953 - val_accuracy: 0.7350\n",
            "Epoch 73/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7778 - accuracy: 0.7349 - val_loss: 0.8036 - val_accuracy: 0.7321\n",
            "Epoch 74/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7926 - accuracy: 0.7317 - val_loss: 0.7822 - val_accuracy: 0.7441\n",
            "Epoch 75/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7916 - accuracy: 0.7244 - val_loss: 0.7888 - val_accuracy: 0.7378\n",
            "Epoch 76/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8020 - accuracy: 0.7260 - val_loss: 0.7834 - val_accuracy: 0.7413\n",
            "Epoch 77/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8080 - accuracy: 0.7238 - val_loss: 0.7947 - val_accuracy: 0.7304\n",
            "Epoch 78/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7712 - accuracy: 0.7341 - val_loss: 0.7952 - val_accuracy: 0.7355\n",
            "Epoch 79/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7743 - accuracy: 0.7357 - val_loss: 0.7834 - val_accuracy: 0.7481\n",
            "Epoch 80/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7809 - accuracy: 0.7314 - val_loss: 0.7828 - val_accuracy: 0.7464\n",
            "Epoch 81/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7609 - accuracy: 0.7417 - val_loss: 0.7750 - val_accuracy: 0.7464\n",
            "Epoch 82/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7864 - accuracy: 0.7324 - val_loss: 0.7741 - val_accuracy: 0.7418\n",
            "Epoch 83/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7691 - accuracy: 0.7364 - val_loss: 0.7662 - val_accuracy: 0.7436\n",
            "Epoch 84/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7648 - accuracy: 0.7390 - val_loss: 0.7776 - val_accuracy: 0.7424\n",
            "Epoch 85/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7606 - accuracy: 0.7372 - val_loss: 0.7834 - val_accuracy: 0.7430\n",
            "Epoch 86/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7559 - accuracy: 0.7457 - val_loss: 0.7687 - val_accuracy: 0.7407\n",
            "Epoch 87/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7542 - accuracy: 0.7397 - val_loss: 0.7738 - val_accuracy: 0.7430\n",
            "Epoch 88/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7581 - accuracy: 0.7470 - val_loss: 0.7591 - val_accuracy: 0.7413\n",
            "Epoch 89/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7622 - accuracy: 0.7366 - val_loss: 0.7681 - val_accuracy: 0.7430\n",
            "Epoch 90/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7564 - accuracy: 0.7396 - val_loss: 0.7644 - val_accuracy: 0.7476\n",
            "Epoch 91/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7336 - accuracy: 0.7400 - val_loss: 0.7624 - val_accuracy: 0.7453\n",
            "Epoch 92/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7609 - accuracy: 0.7367 - val_loss: 0.7676 - val_accuracy: 0.7493\n",
            "Epoch 93/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7692 - accuracy: 0.7377 - val_loss: 0.7746 - val_accuracy: 0.7418\n",
            "Epoch 94/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7535 - accuracy: 0.7437 - val_loss: 0.7533 - val_accuracy: 0.7527\n",
            "Epoch 95/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7362 - accuracy: 0.7477 - val_loss: 0.7797 - val_accuracy: 0.7436\n",
            "Epoch 96/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7501 - accuracy: 0.7414 - val_loss: 0.7567 - val_accuracy: 0.7596\n",
            "Epoch 97/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7475 - accuracy: 0.7459 - val_loss: 0.7579 - val_accuracy: 0.7556\n",
            "Epoch 98/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7314 - accuracy: 0.7406 - val_loss: 0.7654 - val_accuracy: 0.7499\n",
            "Epoch 99/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7379 - accuracy: 0.7503 - val_loss: 0.7579 - val_accuracy: 0.7527\n",
            "Epoch 100/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7241 - accuracy: 0.7513 - val_loss: 0.7511 - val_accuracy: 0.7550\n",
            "Epoch 101/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7397 - accuracy: 0.7450 - val_loss: 0.7524 - val_accuracy: 0.7516\n",
            "Epoch 102/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7249 - accuracy: 0.7493 - val_loss: 0.7781 - val_accuracy: 0.7453\n",
            "Epoch 103/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.7286 - accuracy: 0.7500 - val_loss: 0.7542 - val_accuracy: 0.7521\n",
            "Epoch 104/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.7373 - accuracy: 0.7508 - val_loss: 0.7724 - val_accuracy: 0.7521\n",
            "Epoch 105/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.7217 - accuracy: 0.7533 - val_loss: 0.7594 - val_accuracy: 0.7521\n",
            "Epoch 106/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7383 - accuracy: 0.7475 - val_loss: 0.7601 - val_accuracy: 0.7527\n",
            "Epoch 107/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7255 - accuracy: 0.7540 - val_loss: 0.7507 - val_accuracy: 0.7539\n",
            "Epoch 108/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7346 - accuracy: 0.7465 - val_loss: 0.7613 - val_accuracy: 0.7476\n",
            "Epoch 109/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7190 - accuracy: 0.7509 - val_loss: 0.7516 - val_accuracy: 0.7481\n",
            "Epoch 110/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7237 - accuracy: 0.7456 - val_loss: 0.7440 - val_accuracy: 0.7533\n",
            "Epoch 111/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7298 - accuracy: 0.7499 - val_loss: 0.7794 - val_accuracy: 0.7418\n",
            "Epoch 112/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7221 - accuracy: 0.7499 - val_loss: 0.7397 - val_accuracy: 0.7682\n",
            "Epoch 113/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7262 - accuracy: 0.7470 - val_loss: 0.7587 - val_accuracy: 0.7499\n",
            "Epoch 114/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6991 - accuracy: 0.7609 - val_loss: 0.7548 - val_accuracy: 0.7527\n",
            "Epoch 115/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7085 - accuracy: 0.7542 - val_loss: 0.7298 - val_accuracy: 0.7602\n",
            "Epoch 116/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6981 - accuracy: 0.7536 - val_loss: 0.7405 - val_accuracy: 0.7607\n",
            "Epoch 117/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7114 - accuracy: 0.7555 - val_loss: 0.7464 - val_accuracy: 0.7527\n",
            "Epoch 118/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6881 - accuracy: 0.7621 - val_loss: 0.7404 - val_accuracy: 0.7556\n",
            "Epoch 119/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7107 - accuracy: 0.7525 - val_loss: 0.7236 - val_accuracy: 0.7642\n",
            "Epoch 120/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6997 - accuracy: 0.7591 - val_loss: 0.7599 - val_accuracy: 0.7573\n",
            "Epoch 121/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7171 - accuracy: 0.7545 - val_loss: 0.7464 - val_accuracy: 0.7521\n",
            "Epoch 122/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7003 - accuracy: 0.7545 - val_loss: 0.7233 - val_accuracy: 0.7619\n",
            "Epoch 123/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7099 - accuracy: 0.7575 - val_loss: 0.7367 - val_accuracy: 0.7573\n",
            "Epoch 124/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.7664 - val_loss: 0.7214 - val_accuracy: 0.7590\n",
            "Epoch 125/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6912 - accuracy: 0.7625 - val_loss: 0.7411 - val_accuracy: 0.7590\n",
            "Epoch 126/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6923 - accuracy: 0.7606 - val_loss: 0.7401 - val_accuracy: 0.7619\n",
            "Epoch 127/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6942 - accuracy: 0.7644 - val_loss: 0.7345 - val_accuracy: 0.7619\n",
            "Epoch 128/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7035 - accuracy: 0.7606 - val_loss: 0.7243 - val_accuracy: 0.7579\n",
            "Epoch 129/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6901 - accuracy: 0.7636 - val_loss: 0.7316 - val_accuracy: 0.7687\n",
            "Epoch 130/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7220 - accuracy: 0.7522 - val_loss: 0.7366 - val_accuracy: 0.7539\n",
            "Epoch 131/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6889 - accuracy: 0.7558 - val_loss: 0.7454 - val_accuracy: 0.7647\n",
            "Epoch 132/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6809 - accuracy: 0.7623 - val_loss: 0.7647 - val_accuracy: 0.7493\n",
            "Epoch 133/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6753 - accuracy: 0.7674 - val_loss: 0.7298 - val_accuracy: 0.7590\n",
            "Epoch 134/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6679 - accuracy: 0.7701 - val_loss: 0.7373 - val_accuracy: 0.7653\n",
            "Epoch 135/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.7684 - val_loss: 0.7415 - val_accuracy: 0.7516\n",
            "Epoch 136/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.7684 - val_loss: 0.7388 - val_accuracy: 0.7579\n",
            "Epoch 137/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6897 - accuracy: 0.7599 - val_loss: 0.7332 - val_accuracy: 0.7642\n",
            "Epoch 138/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6738 - accuracy: 0.7666 - val_loss: 0.7473 - val_accuracy: 0.7596\n",
            "Epoch 139/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6696 - accuracy: 0.7698 - val_loss: 0.7292 - val_accuracy: 0.7653\n",
            "Epoch 140/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6705 - accuracy: 0.7669 - val_loss: 0.7319 - val_accuracy: 0.7630\n",
            "Epoch 141/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6738 - accuracy: 0.7694 - val_loss: 0.7315 - val_accuracy: 0.7619\n",
            "Epoch 142/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6786 - accuracy: 0.7681 - val_loss: 0.7364 - val_accuracy: 0.7573\n",
            "Epoch 143/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6802 - accuracy: 0.7625 - val_loss: 0.7513 - val_accuracy: 0.7533\n",
            "Epoch 144/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.7682 - val_loss: 0.7492 - val_accuracy: 0.7487\n",
            "Epoch 145/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6719 - accuracy: 0.7622 - val_loss: 0.7417 - val_accuracy: 0.7590\n",
            "Epoch 146/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6628 - accuracy: 0.7675 - val_loss: 0.7410 - val_accuracy: 0.7624\n",
            "Epoch 147/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6593 - accuracy: 0.7704 - val_loss: 0.7479 - val_accuracy: 0.7619\n",
            "Epoch 148/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.7721 - val_loss: 0.7352 - val_accuracy: 0.7602\n",
            "Epoch 149/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6672 - accuracy: 0.7691 - val_loss: 0.7459 - val_accuracy: 0.7493\n",
            "Epoch 150/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6651 - accuracy: 0.7694 - val_loss: 0.7437 - val_accuracy: 0.7642\n",
            "Epoch 151/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6704 - accuracy: 0.7722 - val_loss: 0.7303 - val_accuracy: 0.7579\n",
            "Epoch 152/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6599 - accuracy: 0.7751 - val_loss: 0.7430 - val_accuracy: 0.7590\n",
            "Epoch 153/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6630 - accuracy: 0.7747 - val_loss: 0.7438 - val_accuracy: 0.7745\n",
            "Epoch 154/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6754 - accuracy: 0.7669 - val_loss: 0.7518 - val_accuracy: 0.7653\n",
            "Epoch 155/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6615 - accuracy: 0.7711 - val_loss: 0.7250 - val_accuracy: 0.7636\n",
            "Epoch 156/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6566 - accuracy: 0.7731 - val_loss: 0.7380 - val_accuracy: 0.7624\n",
            "Epoch 157/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6634 - accuracy: 0.7705 - val_loss: 0.7430 - val_accuracy: 0.7613\n",
            "Epoch 158/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6663 - accuracy: 0.7688 - val_loss: 0.7429 - val_accuracy: 0.7659\n",
            "Epoch 159/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6574 - accuracy: 0.7765 - val_loss: 0.7374 - val_accuracy: 0.7630\n",
            "Epoch 160/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6613 - accuracy: 0.7707 - val_loss: 0.7268 - val_accuracy: 0.7624\n",
            "Epoch 161/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6615 - accuracy: 0.7679 - val_loss: 0.7304 - val_accuracy: 0.7693\n",
            "Epoch 162/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.7717 - val_loss: 0.7453 - val_accuracy: 0.7659\n",
            "Epoch 163/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6581 - accuracy: 0.7745 - val_loss: 0.7522 - val_accuracy: 0.7527\n",
            "Epoch 164/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.7734 - val_loss: 0.7297 - val_accuracy: 0.7722\n",
            "Epoch 165/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.7742 - val_loss: 0.7421 - val_accuracy: 0.7653\n",
            "Epoch 166/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6565 - accuracy: 0.7711 - val_loss: 0.7306 - val_accuracy: 0.7630\n",
            "Epoch 167/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6487 - accuracy: 0.7735 - val_loss: 0.7322 - val_accuracy: 0.7670\n",
            "Epoch 168/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.7871 - val_loss: 0.7361 - val_accuracy: 0.7693\n",
            "Epoch 169/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.7768 - val_loss: 0.7318 - val_accuracy: 0.7596\n",
            "Epoch 170/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.7808 - val_loss: 0.7273 - val_accuracy: 0.7647\n",
            "Epoch 171/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6517 - accuracy: 0.7782 - val_loss: 0.7248 - val_accuracy: 0.7653\n",
            "Epoch 172/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6455 - accuracy: 0.7745 - val_loss: 0.7348 - val_accuracy: 0.7722\n",
            "Epoch 173/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6299 - accuracy: 0.7854 - val_loss: 0.7322 - val_accuracy: 0.7682\n",
            "Epoch 174/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6536 - accuracy: 0.7682 - val_loss: 0.7300 - val_accuracy: 0.7710\n",
            "Epoch 175/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6298 - accuracy: 0.7830 - val_loss: 0.7345 - val_accuracy: 0.7630\n",
            "Epoch 176/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6639 - accuracy: 0.7658 - val_loss: 0.7248 - val_accuracy: 0.7728\n",
            "Epoch 177/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6266 - accuracy: 0.7778 - val_loss: 0.7233 - val_accuracy: 0.7790\n",
            "Epoch 178/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.7814 - val_loss: 0.7315 - val_accuracy: 0.7687\n",
            "Epoch 179/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.7810 - val_loss: 0.7191 - val_accuracy: 0.7802\n",
            "Epoch 180/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6401 - accuracy: 0.7801 - val_loss: 0.7374 - val_accuracy: 0.7636\n",
            "Epoch 181/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6457 - accuracy: 0.7696 - val_loss: 0.7199 - val_accuracy: 0.7739\n",
            "Epoch 182/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6535 - accuracy: 0.7761 - val_loss: 0.7450 - val_accuracy: 0.7693\n",
            "Epoch 183/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6365 - accuracy: 0.7794 - val_loss: 0.7439 - val_accuracy: 0.7676\n",
            "Epoch 184/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6476 - accuracy: 0.7718 - val_loss: 0.7218 - val_accuracy: 0.7699\n",
            "Epoch 185/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6534 - accuracy: 0.7742 - val_loss: 0.7310 - val_accuracy: 0.7682\n",
            "Epoch 186/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6316 - accuracy: 0.7834 - val_loss: 0.7189 - val_accuracy: 0.7756\n",
            "Epoch 187/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6170 - accuracy: 0.7824 - val_loss: 0.7232 - val_accuracy: 0.7676\n",
            "Epoch 188/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6429 - accuracy: 0.7719 - val_loss: 0.7196 - val_accuracy: 0.7796\n",
            "Epoch 189/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6523 - accuracy: 0.7671 - val_loss: 0.7392 - val_accuracy: 0.7745\n",
            "Epoch 190/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6287 - accuracy: 0.7871 - val_loss: 0.7349 - val_accuracy: 0.7710\n",
            "Epoch 191/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6492 - accuracy: 0.7801 - val_loss: 0.7548 - val_accuracy: 0.7653\n",
            "Epoch 192/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6303 - accuracy: 0.7807 - val_loss: 0.7361 - val_accuracy: 0.7613\n",
            "Epoch 193/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6504 - accuracy: 0.7787 - val_loss: 0.7272 - val_accuracy: 0.7705\n",
            "Epoch 194/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6268 - accuracy: 0.7831 - val_loss: 0.7401 - val_accuracy: 0.7710\n",
            "Epoch 195/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6280 - accuracy: 0.7845 - val_loss: 0.7470 - val_accuracy: 0.7636\n",
            "Epoch 196/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6308 - accuracy: 0.7787 - val_loss: 0.7133 - val_accuracy: 0.7825\n",
            "Epoch 197/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.7838 - val_loss: 0.7332 - val_accuracy: 0.7653\n",
            "Epoch 198/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.7797 - val_loss: 0.7017 - val_accuracy: 0.7739\n",
            "Epoch 199/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6036 - accuracy: 0.7895 - val_loss: 0.7388 - val_accuracy: 0.7739\n",
            "Epoch 200/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6261 - accuracy: 0.7843 - val_loss: 0.7265 - val_accuracy: 0.7682\n",
            "Epoch 201/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6278 - accuracy: 0.7843 - val_loss: 0.7318 - val_accuracy: 0.7790\n",
            "Epoch 202/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6146 - accuracy: 0.7834 - val_loss: 0.7440 - val_accuracy: 0.7705\n",
            "Epoch 203/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.7788 - val_loss: 0.7338 - val_accuracy: 0.7682\n",
            "Epoch 204/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6151 - accuracy: 0.7838 - val_loss: 0.7627 - val_accuracy: 0.7693\n",
            "Epoch 205/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6153 - accuracy: 0.7883 - val_loss: 0.7375 - val_accuracy: 0.7739\n",
            "Epoch 206/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6066 - accuracy: 0.7880 - val_loss: 0.7173 - val_accuracy: 0.7802\n",
            "Epoch 207/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6230 - accuracy: 0.7864 - val_loss: 0.7250 - val_accuracy: 0.7779\n",
            "Epoch 208/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.7764 - val_loss: 0.7164 - val_accuracy: 0.7739\n",
            "Epoch 209/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6136 - accuracy: 0.7920 - val_loss: 0.7040 - val_accuracy: 0.7796\n",
            "Epoch 210/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6208 - accuracy: 0.7838 - val_loss: 0.7468 - val_accuracy: 0.7710\n",
            "Epoch 211/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5986 - accuracy: 0.7897 - val_loss: 0.7302 - val_accuracy: 0.7705\n",
            "Epoch 212/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6249 - accuracy: 0.7850 - val_loss: 0.7315 - val_accuracy: 0.7785\n",
            "Epoch 213/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6230 - accuracy: 0.7853 - val_loss: 0.7334 - val_accuracy: 0.7659\n",
            "Epoch 214/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6130 - accuracy: 0.7854 - val_loss: 0.7408 - val_accuracy: 0.7693\n",
            "Epoch 215/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.7814 - val_loss: 0.7339 - val_accuracy: 0.7739\n",
            "Epoch 216/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6027 - accuracy: 0.7895 - val_loss: 0.7496 - val_accuracy: 0.7745\n",
            "Epoch 217/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6046 - accuracy: 0.7868 - val_loss: 0.7378 - val_accuracy: 0.7739\n",
            "Epoch 218/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6091 - accuracy: 0.7888 - val_loss: 0.7387 - val_accuracy: 0.7779\n",
            "Epoch 219/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6012 - accuracy: 0.7973 - val_loss: 0.7197 - val_accuracy: 0.7779\n",
            "Epoch 220/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6002 - accuracy: 0.7891 - val_loss: 0.7292 - val_accuracy: 0.7756\n",
            "Epoch 221/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6172 - accuracy: 0.7904 - val_loss: 0.7233 - val_accuracy: 0.7756\n",
            "Epoch 222/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.7881 - val_loss: 0.7389 - val_accuracy: 0.7710\n",
            "Epoch 223/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5868 - accuracy: 0.7979 - val_loss: 0.7544 - val_accuracy: 0.7687\n",
            "Epoch 224/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5979 - accuracy: 0.7903 - val_loss: 0.7251 - val_accuracy: 0.7733\n",
            "Epoch 225/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5925 - accuracy: 0.7937 - val_loss: 0.7293 - val_accuracy: 0.7739\n",
            "Epoch 226/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.7904 - val_loss: 0.7255 - val_accuracy: 0.7682\n",
            "Epoch 227/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.7927 - val_loss: 0.7289 - val_accuracy: 0.7733\n",
            "Epoch 228/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5949 - accuracy: 0.7927 - val_loss: 0.7166 - val_accuracy: 0.7699\n",
            "Epoch 229/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6118 - accuracy: 0.7903 - val_loss: 0.7234 - val_accuracy: 0.7699\n",
            "Epoch 230/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6075 - accuracy: 0.7926 - val_loss: 0.7254 - val_accuracy: 0.7705\n",
            "Epoch 231/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6064 - accuracy: 0.7940 - val_loss: 0.7193 - val_accuracy: 0.7796\n",
            "Epoch 232/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6070 - accuracy: 0.7913 - val_loss: 0.7088 - val_accuracy: 0.7739\n",
            "Epoch 233/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.7980 - val_loss: 0.7229 - val_accuracy: 0.7728\n",
            "Epoch 234/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.7764 - val_loss: 0.7113 - val_accuracy: 0.7785\n",
            "Epoch 235/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.7980 - val_loss: 0.7080 - val_accuracy: 0.7785\n",
            "Epoch 236/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5990 - accuracy: 0.7891 - val_loss: 0.7005 - val_accuracy: 0.7894\n",
            "Epoch 237/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.8000 - val_loss: 0.7229 - val_accuracy: 0.7813\n",
            "Epoch 238/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5800 - accuracy: 0.8000 - val_loss: 0.7296 - val_accuracy: 0.7808\n",
            "Epoch 239/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5942 - accuracy: 0.7930 - val_loss: 0.7259 - val_accuracy: 0.7842\n",
            "Epoch 240/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5955 - accuracy: 0.7950 - val_loss: 0.7173 - val_accuracy: 0.7739\n",
            "Epoch 241/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6091 - accuracy: 0.7871 - val_loss: 0.7372 - val_accuracy: 0.7756\n",
            "Epoch 242/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.7927 - val_loss: 0.7198 - val_accuracy: 0.7768\n",
            "Epoch 243/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.7983 - val_loss: 0.7181 - val_accuracy: 0.7831\n",
            "Epoch 244/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6016 - accuracy: 0.7894 - val_loss: 0.7199 - val_accuracy: 0.7728\n",
            "Epoch 245/300\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.5948 - accuracy: 0.7888 - val_loss: 0.7075 - val_accuracy: 0.7808\n",
            "Epoch 246/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6297 - accuracy: 0.7831 - val_loss: 0.7152 - val_accuracy: 0.7745\n",
            "Epoch 247/300\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.5960 - accuracy: 0.7928 - val_loss: 0.6999 - val_accuracy: 0.7785\n",
            "Epoch 248/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5893 - accuracy: 0.7914 - val_loss: 0.7148 - val_accuracy: 0.7739\n",
            "Epoch 249/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5879 - accuracy: 0.7983 - val_loss: 0.7433 - val_accuracy: 0.7659\n",
            "Epoch 250/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5777 - accuracy: 0.7963 - val_loss: 0.7261 - val_accuracy: 0.7739\n",
            "Epoch 251/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.7916 - val_loss: 0.7194 - val_accuracy: 0.7710\n",
            "Epoch 252/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5950 - accuracy: 0.7928 - val_loss: 0.7304 - val_accuracy: 0.7682\n",
            "Epoch 253/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5939 - accuracy: 0.7954 - val_loss: 0.7074 - val_accuracy: 0.7831\n",
            "Epoch 254/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5899 - accuracy: 0.7991 - val_loss: 0.7183 - val_accuracy: 0.7773\n",
            "Epoch 255/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5872 - accuracy: 0.7951 - val_loss: 0.7238 - val_accuracy: 0.7716\n",
            "Epoch 256/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5999 - accuracy: 0.7933 - val_loss: 0.7138 - val_accuracy: 0.7733\n",
            "Epoch 257/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.8011 - val_loss: 0.7159 - val_accuracy: 0.7653\n",
            "Epoch 258/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5980 - accuracy: 0.7977 - val_loss: 0.7032 - val_accuracy: 0.7710\n",
            "Epoch 259/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.7989 - val_loss: 0.7165 - val_accuracy: 0.7842\n",
            "Epoch 260/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5903 - accuracy: 0.7969 - val_loss: 0.7174 - val_accuracy: 0.7745\n",
            "Epoch 261/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5865 - accuracy: 0.7926 - val_loss: 0.7234 - val_accuracy: 0.7733\n",
            "Epoch 262/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6056 - accuracy: 0.7941 - val_loss: 0.7193 - val_accuracy: 0.7762\n",
            "Epoch 263/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6023 - accuracy: 0.7904 - val_loss: 0.7181 - val_accuracy: 0.7739\n",
            "Epoch 264/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.8125 - val_loss: 0.7402 - val_accuracy: 0.7750\n",
            "Epoch 265/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5936 - accuracy: 0.7954 - val_loss: 0.7147 - val_accuracy: 0.7762\n",
            "Epoch 266/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.8034 - val_loss: 0.7217 - val_accuracy: 0.7813\n",
            "Epoch 267/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5765 - accuracy: 0.7958 - val_loss: 0.7171 - val_accuracy: 0.7802\n",
            "Epoch 268/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5692 - accuracy: 0.8057 - val_loss: 0.7236 - val_accuracy: 0.7745\n",
            "Epoch 269/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5934 - accuracy: 0.7944 - val_loss: 0.7278 - val_accuracy: 0.7762\n",
            "Epoch 270/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5934 - accuracy: 0.7980 - val_loss: 0.7399 - val_accuracy: 0.7785\n",
            "Epoch 271/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5718 - accuracy: 0.7971 - val_loss: 0.7421 - val_accuracy: 0.7653\n",
            "Epoch 272/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5764 - accuracy: 0.7990 - val_loss: 0.7414 - val_accuracy: 0.7773\n",
            "Epoch 273/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5571 - accuracy: 0.8050 - val_loss: 0.7228 - val_accuracy: 0.7790\n",
            "Epoch 274/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5904 - accuracy: 0.8011 - val_loss: 0.7333 - val_accuracy: 0.7768\n",
            "Epoch 275/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5794 - accuracy: 0.8027 - val_loss: 0.7246 - val_accuracy: 0.7699\n",
            "Epoch 276/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.8020 - val_loss: 0.7295 - val_accuracy: 0.7670\n",
            "Epoch 277/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5839 - accuracy: 0.8000 - val_loss: 0.7325 - val_accuracy: 0.7699\n",
            "Epoch 278/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.8011 - val_loss: 0.7215 - val_accuracy: 0.7705\n",
            "Epoch 279/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5647 - accuracy: 0.8029 - val_loss: 0.7336 - val_accuracy: 0.7785\n",
            "Epoch 280/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5905 - accuracy: 0.7956 - val_loss: 0.7157 - val_accuracy: 0.7790\n",
            "Epoch 281/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5699 - accuracy: 0.8056 - val_loss: 0.7520 - val_accuracy: 0.7728\n",
            "Epoch 282/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.7920 - val_loss: 0.7201 - val_accuracy: 0.7813\n",
            "Epoch 283/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5874 - accuracy: 0.7999 - val_loss: 0.7190 - val_accuracy: 0.7882\n",
            "Epoch 284/300\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.5891 - accuracy: 0.7996 - val_loss: 0.7206 - val_accuracy: 0.7796\n",
            "Epoch 285/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.8021 - val_loss: 0.7234 - val_accuracy: 0.7745\n",
            "Epoch 286/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5672 - accuracy: 0.8003 - val_loss: 0.7133 - val_accuracy: 0.7733\n",
            "Epoch 287/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.8007 - val_loss: 0.7428 - val_accuracy: 0.7728\n",
            "Epoch 288/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5810 - accuracy: 0.7961 - val_loss: 0.7294 - val_accuracy: 0.7802\n",
            "Epoch 289/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5547 - accuracy: 0.8076 - val_loss: 0.7348 - val_accuracy: 0.7699\n",
            "Epoch 290/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5584 - accuracy: 0.8112 - val_loss: 0.7287 - val_accuracy: 0.7693\n",
            "Epoch 291/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.8009 - val_loss: 0.7296 - val_accuracy: 0.7745\n",
            "Epoch 292/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.8107 - val_loss: 0.7270 - val_accuracy: 0.7802\n",
            "Epoch 293/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5733 - accuracy: 0.8050 - val_loss: 0.7313 - val_accuracy: 0.7773\n",
            "Epoch 294/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.8010 - val_loss: 0.7171 - val_accuracy: 0.7756\n",
            "Epoch 295/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5632 - accuracy: 0.8079 - val_loss: 0.7183 - val_accuracy: 0.7756\n",
            "Epoch 296/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.8000 - val_loss: 0.7233 - val_accuracy: 0.7796\n",
            "Epoch 297/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5563 - accuracy: 0.8087 - val_loss: 0.7326 - val_accuracy: 0.7716\n",
            "Epoch 298/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5756 - accuracy: 0.7944 - val_loss: 0.7279 - val_accuracy: 0.7733\n",
            "Epoch 299/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5919 - accuracy: 0.7926 - val_loss: 0.7134 - val_accuracy: 0.7785\n",
            "Epoch 300/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.7981 - val_loss: 0.7315 - val_accuracy: 0.7739\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe885110a90>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "                                \n",
        "model.add(tf.keras.layers.Conv1D(16,2, activation ='relu', input_shape= (20, 1)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "              \n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32))\n",
        "\n",
        "            \n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=\"Adam\",loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])\n",
        "\n",
        "num_epochs = 300\n",
        "num_batch_size = 64\n",
        "\n",
        "model.fit(\n",
        "          x_train, \n",
        "          y_train, \n",
        "          batch_size=num_batch_size, \n",
        "          epochs=num_epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[callbacks]\n",
        "         )"
      ],
      "metadata": {
        "id": "_l6e6QcYpf5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1b4d600-07b0-4c25-8717-4526debce95e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_19 (Conv1D)          (None, 19, 16)            48        \n",
            "                                                                 \n",
            " flatten_14 (Flatten)        (None, 304)               0         \n",
            "                                                                 \n",
            " dense_80 (Dense)            (None, 64)                19520     \n",
            "                                                                 \n",
            " activation_64 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_48 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " activation_65 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_49 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " activation_66 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_50 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_84 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            " activation_67 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 48,858\n",
            "Trainable params: 48,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 2.1762 - accuracy: 0.1791 - val_loss: 1.9301 - val_accuracy: 0.3137\n",
            "Epoch 2/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8660 - accuracy: 0.3162 - val_loss: 1.6999 - val_accuracy: 0.3915\n",
            "Epoch 3/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7203 - accuracy: 0.3678 - val_loss: 1.5953 - val_accuracy: 0.4144\n",
            "Epoch 4/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6521 - accuracy: 0.4063 - val_loss: 1.5512 - val_accuracy: 0.4602\n",
            "Epoch 5/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6036 - accuracy: 0.4263 - val_loss: 1.4830 - val_accuracy: 0.4711\n",
            "Epoch 6/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5519 - accuracy: 0.4470 - val_loss: 1.4387 - val_accuracy: 0.5100\n",
            "Epoch 7/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5213 - accuracy: 0.4613 - val_loss: 1.4163 - val_accuracy: 0.5123\n",
            "Epoch 8/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4884 - accuracy: 0.4736 - val_loss: 1.3596 - val_accuracy: 0.5386\n",
            "Epoch 9/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4522 - accuracy: 0.4865 - val_loss: 1.3344 - val_accuracy: 0.5495\n",
            "Epoch 10/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4112 - accuracy: 0.5067 - val_loss: 1.3030 - val_accuracy: 0.5684\n",
            "Epoch 11/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3798 - accuracy: 0.5241 - val_loss: 1.2807 - val_accuracy: 0.5770\n",
            "Epoch 12/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3587 - accuracy: 0.5396 - val_loss: 1.2707 - val_accuracy: 0.5741\n",
            "Epoch 13/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3256 - accuracy: 0.5429 - val_loss: 1.2083 - val_accuracy: 0.6027\n",
            "Epoch 14/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3156 - accuracy: 0.5573 - val_loss: 1.2115 - val_accuracy: 0.6045\n",
            "Epoch 15/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2874 - accuracy: 0.5659 - val_loss: 1.1952 - val_accuracy: 0.6176\n",
            "Epoch 16/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2699 - accuracy: 0.5654 - val_loss: 1.1585 - val_accuracy: 0.6188\n",
            "Epoch 17/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2534 - accuracy: 0.5814 - val_loss: 1.1480 - val_accuracy: 0.6165\n",
            "Epoch 18/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2371 - accuracy: 0.5797 - val_loss: 1.1450 - val_accuracy: 0.6222\n",
            "Epoch 19/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2054 - accuracy: 0.6003 - val_loss: 1.1121 - val_accuracy: 0.6411\n",
            "Epoch 20/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2173 - accuracy: 0.5956 - val_loss: 1.1279 - val_accuracy: 0.6331\n",
            "Epoch 21/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1981 - accuracy: 0.5951 - val_loss: 1.0886 - val_accuracy: 0.6463\n",
            "Epoch 22/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1923 - accuracy: 0.5976 - val_loss: 1.0683 - val_accuracy: 0.6600\n",
            "Epoch 23/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1636 - accuracy: 0.6110 - val_loss: 1.0614 - val_accuracy: 0.6594\n",
            "Epoch 24/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1593 - accuracy: 0.6143 - val_loss: 1.0535 - val_accuracy: 0.6623\n",
            "Epoch 25/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1333 - accuracy: 0.6223 - val_loss: 1.0325 - val_accuracy: 0.6663\n",
            "Epoch 26/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1271 - accuracy: 0.6233 - val_loss: 1.0537 - val_accuracy: 0.6594\n",
            "Epoch 27/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1122 - accuracy: 0.6305 - val_loss: 1.0156 - val_accuracy: 0.6732\n",
            "Epoch 28/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1045 - accuracy: 0.6301 - val_loss: 1.0155 - val_accuracy: 0.6737\n",
            "Epoch 29/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0899 - accuracy: 0.6345 - val_loss: 1.0014 - val_accuracy: 0.6749\n",
            "Epoch 30/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0892 - accuracy: 0.6319 - val_loss: 0.9960 - val_accuracy: 0.6789\n",
            "Epoch 31/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0904 - accuracy: 0.6392 - val_loss: 0.9887 - val_accuracy: 0.6812\n",
            "Epoch 32/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0656 - accuracy: 0.6470 - val_loss: 0.9907 - val_accuracy: 0.6795\n",
            "Epoch 33/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0710 - accuracy: 0.6451 - val_loss: 0.9794 - val_accuracy: 0.6880\n",
            "Epoch 34/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0431 - accuracy: 0.6500 - val_loss: 0.9650 - val_accuracy: 0.6835\n",
            "Epoch 35/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0561 - accuracy: 0.6490 - val_loss: 0.9823 - val_accuracy: 0.6795\n",
            "Epoch 36/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0371 - accuracy: 0.6551 - val_loss: 0.9643 - val_accuracy: 0.6812\n",
            "Epoch 37/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0230 - accuracy: 0.6606 - val_loss: 0.9653 - val_accuracy: 0.6852\n",
            "Epoch 38/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0216 - accuracy: 0.6574 - val_loss: 0.9472 - val_accuracy: 0.6938\n",
            "Epoch 39/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0117 - accuracy: 0.6567 - val_loss: 0.9494 - val_accuracy: 0.6966\n",
            "Epoch 40/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9997 - accuracy: 0.6630 - val_loss: 0.9456 - val_accuracy: 0.6909\n",
            "Epoch 41/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0010 - accuracy: 0.6636 - val_loss: 0.9474 - val_accuracy: 0.6903\n",
            "Epoch 42/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9916 - accuracy: 0.6690 - val_loss: 0.9421 - val_accuracy: 0.6995\n",
            "Epoch 43/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9849 - accuracy: 0.6680 - val_loss: 0.9220 - val_accuracy: 0.6903\n",
            "Epoch 44/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9824 - accuracy: 0.6730 - val_loss: 0.9107 - val_accuracy: 0.6972\n",
            "Epoch 45/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9679 - accuracy: 0.6744 - val_loss: 0.9024 - val_accuracy: 0.7052\n",
            "Epoch 46/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9738 - accuracy: 0.6746 - val_loss: 0.9031 - val_accuracy: 0.7064\n",
            "Epoch 47/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.9728 - accuracy: 0.6776 - val_loss: 0.9175 - val_accuracy: 0.7058\n",
            "Epoch 48/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9503 - accuracy: 0.6848 - val_loss: 0.8969 - val_accuracy: 0.6989\n",
            "Epoch 49/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9525 - accuracy: 0.6826 - val_loss: 0.8791 - val_accuracy: 0.7109\n",
            "Epoch 50/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9458 - accuracy: 0.6848 - val_loss: 0.8969 - val_accuracy: 0.7035\n",
            "Epoch 51/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9420 - accuracy: 0.6809 - val_loss: 0.8736 - val_accuracy: 0.7138\n",
            "Epoch 52/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9323 - accuracy: 0.6815 - val_loss: 0.8825 - val_accuracy: 0.7092\n",
            "Epoch 53/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9218 - accuracy: 0.6935 - val_loss: 0.8766 - val_accuracy: 0.7132\n",
            "Epoch 54/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9251 - accuracy: 0.6862 - val_loss: 0.8845 - val_accuracy: 0.7115\n",
            "Epoch 55/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9243 - accuracy: 0.6873 - val_loss: 0.8570 - val_accuracy: 0.7293\n",
            "Epoch 56/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9229 - accuracy: 0.6943 - val_loss: 0.8777 - val_accuracy: 0.7201\n",
            "Epoch 57/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9097 - accuracy: 0.6981 - val_loss: 0.8664 - val_accuracy: 0.7121\n",
            "Epoch 58/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9195 - accuracy: 0.6958 - val_loss: 0.8701 - val_accuracy: 0.7287\n",
            "Epoch 59/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8994 - accuracy: 0.6986 - val_loss: 0.8653 - val_accuracy: 0.7161\n",
            "Epoch 60/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9058 - accuracy: 0.6955 - val_loss: 0.8649 - val_accuracy: 0.7235\n",
            "Epoch 61/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8964 - accuracy: 0.6985 - val_loss: 0.8620 - val_accuracy: 0.7207\n",
            "Epoch 62/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8896 - accuracy: 0.7032 - val_loss: 0.8456 - val_accuracy: 0.7172\n",
            "Epoch 63/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8823 - accuracy: 0.7009 - val_loss: 0.8640 - val_accuracy: 0.7195\n",
            "Epoch 64/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8750 - accuracy: 0.7041 - val_loss: 0.8567 - val_accuracy: 0.7075\n",
            "Epoch 65/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8761 - accuracy: 0.7018 - val_loss: 0.8601 - val_accuracy: 0.7195\n",
            "Epoch 66/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8894 - accuracy: 0.7038 - val_loss: 0.8586 - val_accuracy: 0.7178\n",
            "Epoch 67/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.8733 - accuracy: 0.7112 - val_loss: 0.8542 - val_accuracy: 0.7218\n",
            "Epoch 68/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8590 - accuracy: 0.7120 - val_loss: 0.8393 - val_accuracy: 0.7230\n",
            "Epoch 69/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8748 - accuracy: 0.7048 - val_loss: 0.8309 - val_accuracy: 0.7310\n",
            "Epoch 70/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8639 - accuracy: 0.7044 - val_loss: 0.8238 - val_accuracy: 0.7258\n",
            "Epoch 71/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8665 - accuracy: 0.7145 - val_loss: 0.8299 - val_accuracy: 0.7310\n",
            "Epoch 72/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8432 - accuracy: 0.7187 - val_loss: 0.8177 - val_accuracy: 0.7264\n",
            "Epoch 73/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8557 - accuracy: 0.7151 - val_loss: 0.8160 - val_accuracy: 0.7315\n",
            "Epoch 74/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8533 - accuracy: 0.7154 - val_loss: 0.8285 - val_accuracy: 0.7338\n",
            "Epoch 75/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8797 - accuracy: 0.6984 - val_loss: 0.8250 - val_accuracy: 0.7230\n",
            "Epoch 76/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8364 - accuracy: 0.7190 - val_loss: 0.8099 - val_accuracy: 0.7373\n",
            "Epoch 77/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8448 - accuracy: 0.7180 - val_loss: 0.8177 - val_accuracy: 0.7355\n",
            "Epoch 78/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8412 - accuracy: 0.7198 - val_loss: 0.8042 - val_accuracy: 0.7355\n",
            "Epoch 79/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8493 - accuracy: 0.7152 - val_loss: 0.8253 - val_accuracy: 0.7281\n",
            "Epoch 80/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8414 - accuracy: 0.7181 - val_loss: 0.8346 - val_accuracy: 0.7287\n",
            "Epoch 81/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8516 - accuracy: 0.7128 - val_loss: 0.8096 - val_accuracy: 0.7378\n",
            "Epoch 82/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8187 - accuracy: 0.7278 - val_loss: 0.8173 - val_accuracy: 0.7321\n",
            "Epoch 83/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8182 - accuracy: 0.7264 - val_loss: 0.8302 - val_accuracy: 0.7287\n",
            "Epoch 84/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8265 - accuracy: 0.7207 - val_loss: 0.7898 - val_accuracy: 0.7464\n",
            "Epoch 85/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.8196 - accuracy: 0.7225 - val_loss: 0.7821 - val_accuracy: 0.7487\n",
            "Epoch 86/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8240 - accuracy: 0.7227 - val_loss: 0.7973 - val_accuracy: 0.7378\n",
            "Epoch 87/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.8113 - accuracy: 0.7301 - val_loss: 0.8002 - val_accuracy: 0.7407\n",
            "Epoch 88/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8104 - accuracy: 0.7310 - val_loss: 0.8004 - val_accuracy: 0.7361\n",
            "Epoch 89/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8044 - accuracy: 0.7276 - val_loss: 0.8036 - val_accuracy: 0.7384\n",
            "Epoch 90/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8247 - accuracy: 0.7261 - val_loss: 0.8019 - val_accuracy: 0.7361\n",
            "Epoch 91/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8099 - accuracy: 0.7298 - val_loss: 0.7960 - val_accuracy: 0.7441\n",
            "Epoch 92/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8240 - accuracy: 0.7217 - val_loss: 0.7980 - val_accuracy: 0.7384\n",
            "Epoch 93/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7913 - accuracy: 0.7324 - val_loss: 0.7983 - val_accuracy: 0.7407\n",
            "Epoch 94/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7946 - accuracy: 0.7333 - val_loss: 0.8007 - val_accuracy: 0.7367\n",
            "Epoch 95/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7997 - accuracy: 0.7321 - val_loss: 0.7804 - val_accuracy: 0.7544\n",
            "Epoch 96/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7988 - accuracy: 0.7317 - val_loss: 0.8003 - val_accuracy: 0.7413\n",
            "Epoch 97/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7948 - accuracy: 0.7351 - val_loss: 0.7849 - val_accuracy: 0.7384\n",
            "Epoch 98/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7895 - accuracy: 0.7320 - val_loss: 0.7963 - val_accuracy: 0.7413\n",
            "Epoch 99/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7853 - accuracy: 0.7399 - val_loss: 0.7765 - val_accuracy: 0.7487\n",
            "Epoch 100/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.7894 - accuracy: 0.7370 - val_loss: 0.7754 - val_accuracy: 0.7453\n",
            "Epoch 101/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7975 - accuracy: 0.7392 - val_loss: 0.7813 - val_accuracy: 0.7470\n",
            "Epoch 102/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7942 - accuracy: 0.7337 - val_loss: 0.7810 - val_accuracy: 0.7436\n",
            "Epoch 103/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8065 - accuracy: 0.7350 - val_loss: 0.7812 - val_accuracy: 0.7384\n",
            "Epoch 104/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7973 - accuracy: 0.7336 - val_loss: 0.7848 - val_accuracy: 0.7453\n",
            "Epoch 105/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.7861 - accuracy: 0.7364 - val_loss: 0.7807 - val_accuracy: 0.7441\n",
            "Epoch 106/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.7723 - accuracy: 0.7409 - val_loss: 0.7655 - val_accuracy: 0.7539\n",
            "Epoch 107/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7757 - accuracy: 0.7333 - val_loss: 0.7559 - val_accuracy: 0.7527\n",
            "Epoch 108/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7817 - accuracy: 0.7400 - val_loss: 0.7740 - val_accuracy: 0.7550\n",
            "Epoch 109/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7793 - accuracy: 0.7363 - val_loss: 0.7790 - val_accuracy: 0.7407\n",
            "Epoch 110/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7825 - accuracy: 0.7356 - val_loss: 0.7570 - val_accuracy: 0.7596\n",
            "Epoch 111/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7599 - accuracy: 0.7442 - val_loss: 0.7612 - val_accuracy: 0.7516\n",
            "Epoch 112/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7629 - accuracy: 0.7426 - val_loss: 0.7669 - val_accuracy: 0.7521\n",
            "Epoch 113/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7692 - accuracy: 0.7386 - val_loss: 0.7729 - val_accuracy: 0.7481\n",
            "Epoch 114/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7699 - accuracy: 0.7470 - val_loss: 0.7665 - val_accuracy: 0.7596\n",
            "Epoch 115/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7736 - accuracy: 0.7379 - val_loss: 0.7747 - val_accuracy: 0.7481\n",
            "Epoch 116/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7548 - accuracy: 0.7455 - val_loss: 0.7855 - val_accuracy: 0.7464\n",
            "Epoch 117/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7693 - accuracy: 0.7432 - val_loss: 0.7604 - val_accuracy: 0.7516\n",
            "Epoch 118/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7510 - accuracy: 0.7452 - val_loss: 0.7649 - val_accuracy: 0.7550\n",
            "Epoch 119/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7497 - accuracy: 0.7485 - val_loss: 0.7587 - val_accuracy: 0.7590\n",
            "Epoch 120/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7654 - accuracy: 0.7419 - val_loss: 0.7705 - val_accuracy: 0.7550\n",
            "Epoch 121/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7471 - accuracy: 0.7515 - val_loss: 0.7647 - val_accuracy: 0.7602\n",
            "Epoch 122/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7772 - accuracy: 0.7347 - val_loss: 0.7532 - val_accuracy: 0.7584\n",
            "Epoch 123/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7484 - accuracy: 0.7493 - val_loss: 0.7704 - val_accuracy: 0.7550\n",
            "Epoch 124/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7612 - accuracy: 0.7436 - val_loss: 0.7711 - val_accuracy: 0.7527\n",
            "Epoch 125/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7392 - accuracy: 0.7546 - val_loss: 0.7599 - val_accuracy: 0.7613\n",
            "Epoch 126/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7550 - accuracy: 0.7396 - val_loss: 0.7624 - val_accuracy: 0.7590\n",
            "Epoch 127/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7522 - accuracy: 0.7502 - val_loss: 0.7554 - val_accuracy: 0.7556\n",
            "Epoch 128/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7522 - accuracy: 0.7463 - val_loss: 0.7526 - val_accuracy: 0.7602\n",
            "Epoch 129/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7500 - accuracy: 0.7473 - val_loss: 0.7545 - val_accuracy: 0.7584\n",
            "Epoch 130/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7342 - accuracy: 0.7512 - val_loss: 0.7608 - val_accuracy: 0.7602\n",
            "Epoch 131/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7484 - accuracy: 0.7435 - val_loss: 0.7599 - val_accuracy: 0.7624\n",
            "Epoch 132/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7472 - accuracy: 0.7508 - val_loss: 0.7597 - val_accuracy: 0.7544\n",
            "Epoch 133/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7370 - accuracy: 0.7553 - val_loss: 0.7654 - val_accuracy: 0.7562\n",
            "Epoch 134/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7488 - accuracy: 0.7459 - val_loss: 0.7499 - val_accuracy: 0.7619\n",
            "Epoch 135/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7478 - accuracy: 0.7477 - val_loss: 0.7467 - val_accuracy: 0.7573\n",
            "Epoch 136/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7397 - accuracy: 0.7509 - val_loss: 0.7620 - val_accuracy: 0.7510\n",
            "Epoch 137/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7466 - accuracy: 0.7519 - val_loss: 0.7469 - val_accuracy: 0.7584\n",
            "Epoch 138/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7453 - accuracy: 0.7493 - val_loss: 0.7370 - val_accuracy: 0.7602\n",
            "Epoch 139/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7146 - accuracy: 0.7553 - val_loss: 0.7486 - val_accuracy: 0.7579\n",
            "Epoch 140/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7366 - accuracy: 0.7548 - val_loss: 0.7436 - val_accuracy: 0.7539\n",
            "Epoch 141/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7233 - accuracy: 0.7592 - val_loss: 0.7524 - val_accuracy: 0.7567\n",
            "Epoch 142/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7190 - accuracy: 0.7573 - val_loss: 0.7468 - val_accuracy: 0.7493\n",
            "Epoch 143/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7194 - accuracy: 0.7535 - val_loss: 0.7687 - val_accuracy: 0.7527\n",
            "Epoch 144/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7477 - accuracy: 0.7515 - val_loss: 0.7486 - val_accuracy: 0.7481\n",
            "Epoch 145/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7189 - accuracy: 0.7565 - val_loss: 0.7350 - val_accuracy: 0.7630\n",
            "Epoch 146/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7255 - accuracy: 0.7571 - val_loss: 0.7628 - val_accuracy: 0.7624\n",
            "Epoch 147/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7308 - accuracy: 0.7539 - val_loss: 0.7384 - val_accuracy: 0.7642\n",
            "Epoch 148/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7176 - accuracy: 0.7608 - val_loss: 0.7453 - val_accuracy: 0.7527\n",
            "Epoch 149/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7161 - accuracy: 0.7592 - val_loss: 0.7593 - val_accuracy: 0.7550\n",
            "Epoch 150/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7297 - accuracy: 0.7528 - val_loss: 0.7497 - val_accuracy: 0.7624\n",
            "Epoch 151/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.7290 - accuracy: 0.7542 - val_loss: 0.7334 - val_accuracy: 0.7567\n",
            "Epoch 152/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7358 - accuracy: 0.7536 - val_loss: 0.7476 - val_accuracy: 0.7619\n",
            "Epoch 153/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7261 - accuracy: 0.7522 - val_loss: 0.7468 - val_accuracy: 0.7521\n",
            "Epoch 154/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7251 - accuracy: 0.7573 - val_loss: 0.7257 - val_accuracy: 0.7676\n",
            "Epoch 155/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7102 - accuracy: 0.7611 - val_loss: 0.7474 - val_accuracy: 0.7562\n",
            "Epoch 156/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7230 - accuracy: 0.7571 - val_loss: 0.7432 - val_accuracy: 0.7630\n",
            "Epoch 157/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6956 - accuracy: 0.7646 - val_loss: 0.7381 - val_accuracy: 0.7607\n",
            "Epoch 158/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7213 - accuracy: 0.7571 - val_loss: 0.7414 - val_accuracy: 0.7607\n",
            "Epoch 159/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7201 - accuracy: 0.7582 - val_loss: 0.7608 - val_accuracy: 0.7619\n",
            "Epoch 160/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7202 - accuracy: 0.7669 - val_loss: 0.7523 - val_accuracy: 0.7613\n",
            "Epoch 161/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7168 - accuracy: 0.7596 - val_loss: 0.7367 - val_accuracy: 0.7670\n",
            "Epoch 162/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7166 - accuracy: 0.7668 - val_loss: 0.7526 - val_accuracy: 0.7682\n",
            "Epoch 163/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7026 - accuracy: 0.7588 - val_loss: 0.7511 - val_accuracy: 0.7602\n",
            "Epoch 164/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7167 - accuracy: 0.7595 - val_loss: 0.7814 - val_accuracy: 0.7516\n",
            "Epoch 165/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7209 - accuracy: 0.7566 - val_loss: 0.7288 - val_accuracy: 0.7642\n",
            "Epoch 166/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7020 - accuracy: 0.7596 - val_loss: 0.7509 - val_accuracy: 0.7579\n",
            "Epoch 167/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7142 - accuracy: 0.7618 - val_loss: 0.7304 - val_accuracy: 0.7630\n",
            "Epoch 168/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7037 - accuracy: 0.7701 - val_loss: 0.7345 - val_accuracy: 0.7590\n",
            "Epoch 169/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.7038 - accuracy: 0.7632 - val_loss: 0.7663 - val_accuracy: 0.7539\n",
            "Epoch 170/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7265 - accuracy: 0.7569 - val_loss: 0.7117 - val_accuracy: 0.7705\n",
            "Epoch 171/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7029 - accuracy: 0.7649 - val_loss: 0.7380 - val_accuracy: 0.7596\n",
            "Epoch 172/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7005 - accuracy: 0.7581 - val_loss: 0.7259 - val_accuracy: 0.7636\n",
            "Epoch 173/300\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.7008 - accuracy: 0.7629 - val_loss: 0.7243 - val_accuracy: 0.7584\n",
            "Epoch 174/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7097 - accuracy: 0.7679 - val_loss: 0.7349 - val_accuracy: 0.7619\n",
            "Epoch 175/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.7645 - val_loss: 0.7418 - val_accuracy: 0.7636\n",
            "Epoch 176/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6825 - accuracy: 0.7689 - val_loss: 0.7299 - val_accuracy: 0.7630\n",
            "Epoch 177/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6975 - accuracy: 0.7652 - val_loss: 0.7532 - val_accuracy: 0.7550\n",
            "Epoch 178/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6988 - accuracy: 0.7631 - val_loss: 0.7577 - val_accuracy: 0.7642\n",
            "Epoch 179/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.7593 - val_loss: 0.7484 - val_accuracy: 0.7619\n",
            "Epoch 180/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7044 - accuracy: 0.7601 - val_loss: 0.7458 - val_accuracy: 0.7590\n",
            "Epoch 181/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7105 - accuracy: 0.7634 - val_loss: 0.7455 - val_accuracy: 0.7619\n",
            "Epoch 182/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6742 - accuracy: 0.7741 - val_loss: 0.7479 - val_accuracy: 0.7579\n",
            "Epoch 183/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6801 - accuracy: 0.7704 - val_loss: 0.7438 - val_accuracy: 0.7630\n",
            "Epoch 184/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6952 - accuracy: 0.7655 - val_loss: 0.7533 - val_accuracy: 0.7567\n",
            "Epoch 185/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7684 - val_loss: 0.7409 - val_accuracy: 0.7596\n",
            "Epoch 186/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6838 - accuracy: 0.7691 - val_loss: 0.7496 - val_accuracy: 0.7562\n",
            "Epoch 187/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6615 - accuracy: 0.7785 - val_loss: 0.7278 - val_accuracy: 0.7613\n",
            "Epoch 188/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6847 - accuracy: 0.7698 - val_loss: 0.7270 - val_accuracy: 0.7687\n",
            "Epoch 189/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6812 - accuracy: 0.7704 - val_loss: 0.7375 - val_accuracy: 0.7670\n",
            "Epoch 190/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7061 - accuracy: 0.7662 - val_loss: 0.7169 - val_accuracy: 0.7739\n",
            "Epoch 191/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.7026 - accuracy: 0.7635 - val_loss: 0.7363 - val_accuracy: 0.7544\n",
            "Epoch 192/300\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.7018 - accuracy: 0.7646 - val_loss: 0.7201 - val_accuracy: 0.7647\n",
            "Epoch 193/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6946 - accuracy: 0.7674 - val_loss: 0.7382 - val_accuracy: 0.7630\n",
            "Epoch 194/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6728 - accuracy: 0.7742 - val_loss: 0.7347 - val_accuracy: 0.7613\n",
            "Epoch 195/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6784 - accuracy: 0.7741 - val_loss: 0.7366 - val_accuracy: 0.7636\n",
            "Epoch 196/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7018 - accuracy: 0.7629 - val_loss: 0.7153 - val_accuracy: 0.7676\n",
            "Epoch 197/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6820 - accuracy: 0.7686 - val_loss: 0.7352 - val_accuracy: 0.7665\n",
            "Epoch 198/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.7701 - val_loss: 0.7340 - val_accuracy: 0.7630\n",
            "Epoch 199/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6998 - accuracy: 0.7662 - val_loss: 0.7244 - val_accuracy: 0.7682\n",
            "Epoch 200/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6821 - accuracy: 0.7721 - val_loss: 0.7220 - val_accuracy: 0.7676\n",
            "Epoch 201/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6565 - accuracy: 0.7835 - val_loss: 0.7446 - val_accuracy: 0.7556\n",
            "Epoch 202/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6813 - accuracy: 0.7757 - val_loss: 0.7202 - val_accuracy: 0.7676\n",
            "Epoch 203/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6657 - accuracy: 0.7787 - val_loss: 0.7244 - val_accuracy: 0.7710\n",
            "Epoch 204/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.7725 - val_loss: 0.7268 - val_accuracy: 0.7659\n",
            "Epoch 205/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6733 - accuracy: 0.7791 - val_loss: 0.7207 - val_accuracy: 0.7733\n",
            "Epoch 206/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6755 - accuracy: 0.7707 - val_loss: 0.7247 - val_accuracy: 0.7716\n",
            "Epoch 207/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6734 - accuracy: 0.7694 - val_loss: 0.7318 - val_accuracy: 0.7636\n",
            "Epoch 208/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6750 - accuracy: 0.7749 - val_loss: 0.7234 - val_accuracy: 0.7699\n",
            "Epoch 209/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6739 - accuracy: 0.7807 - val_loss: 0.7217 - val_accuracy: 0.7687\n",
            "Epoch 210/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6758 - accuracy: 0.7739 - val_loss: 0.7448 - val_accuracy: 0.7642\n",
            "Epoch 211/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6700 - accuracy: 0.7729 - val_loss: 0.7117 - val_accuracy: 0.7687\n",
            "Epoch 212/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6696 - accuracy: 0.7747 - val_loss: 0.7137 - val_accuracy: 0.7693\n",
            "Epoch 213/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.7708 - val_loss: 0.7022 - val_accuracy: 0.7682\n",
            "Epoch 214/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.7701 - val_loss: 0.7219 - val_accuracy: 0.7653\n",
            "Epoch 215/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6863 - accuracy: 0.7689 - val_loss: 0.7106 - val_accuracy: 0.7687\n",
            "Epoch 216/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6722 - accuracy: 0.7699 - val_loss: 0.7214 - val_accuracy: 0.7687\n",
            "Epoch 217/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6645 - accuracy: 0.7800 - val_loss: 0.7293 - val_accuracy: 0.7710\n",
            "Epoch 218/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6625 - accuracy: 0.7699 - val_loss: 0.7199 - val_accuracy: 0.7716\n",
            "Epoch 219/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6764 - accuracy: 0.7709 - val_loss: 0.7127 - val_accuracy: 0.7682\n",
            "Epoch 220/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6570 - accuracy: 0.7837 - val_loss: 0.7239 - val_accuracy: 0.7676\n",
            "Epoch 221/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6522 - accuracy: 0.7785 - val_loss: 0.7199 - val_accuracy: 0.7665\n",
            "Epoch 222/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6809 - accuracy: 0.7762 - val_loss: 0.7375 - val_accuracy: 0.7699\n",
            "Epoch 223/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6650 - accuracy: 0.7780 - val_loss: 0.7185 - val_accuracy: 0.7739\n",
            "Epoch 224/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6683 - accuracy: 0.7770 - val_loss: 0.7174 - val_accuracy: 0.7676\n",
            "Epoch 225/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6732 - accuracy: 0.7714 - val_loss: 0.7161 - val_accuracy: 0.7716\n",
            "Epoch 226/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6689 - accuracy: 0.7732 - val_loss: 0.7141 - val_accuracy: 0.7762\n",
            "Epoch 227/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.7811 - val_loss: 0.7229 - val_accuracy: 0.7722\n",
            "Epoch 228/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6646 - accuracy: 0.7737 - val_loss: 0.7297 - val_accuracy: 0.7699\n",
            "Epoch 229/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6499 - accuracy: 0.7815 - val_loss: 0.7207 - val_accuracy: 0.7647\n",
            "Epoch 230/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6606 - accuracy: 0.7790 - val_loss: 0.7073 - val_accuracy: 0.7693\n",
            "Epoch 231/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6625 - accuracy: 0.7732 - val_loss: 0.7262 - val_accuracy: 0.7716\n",
            "Epoch 232/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6664 - accuracy: 0.7787 - val_loss: 0.7234 - val_accuracy: 0.7670\n",
            "Epoch 233/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6449 - accuracy: 0.7840 - val_loss: 0.7365 - val_accuracy: 0.7699\n",
            "Epoch 234/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.7772 - val_loss: 0.7235 - val_accuracy: 0.7733\n",
            "Epoch 235/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6551 - accuracy: 0.7782 - val_loss: 0.7366 - val_accuracy: 0.7682\n",
            "Epoch 236/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6591 - accuracy: 0.7818 - val_loss: 0.7140 - val_accuracy: 0.7722\n",
            "Epoch 237/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6486 - accuracy: 0.7751 - val_loss: 0.7128 - val_accuracy: 0.7745\n",
            "Epoch 238/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6665 - accuracy: 0.7815 - val_loss: 0.7177 - val_accuracy: 0.7739\n",
            "Epoch 239/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6604 - accuracy: 0.7815 - val_loss: 0.7135 - val_accuracy: 0.7768\n",
            "Epoch 240/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6567 - accuracy: 0.7758 - val_loss: 0.7246 - val_accuracy: 0.7733\n",
            "Epoch 241/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.7801 - val_loss: 0.7179 - val_accuracy: 0.7676\n",
            "Epoch 242/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6473 - accuracy: 0.7822 - val_loss: 0.7192 - val_accuracy: 0.7705\n",
            "Epoch 243/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6540 - accuracy: 0.7767 - val_loss: 0.7145 - val_accuracy: 0.7710\n",
            "Epoch 244/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6622 - accuracy: 0.7810 - val_loss: 0.7324 - val_accuracy: 0.7642\n",
            "Epoch 245/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6353 - accuracy: 0.7867 - val_loss: 0.7267 - val_accuracy: 0.7676\n",
            "Epoch 246/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.7810 - val_loss: 0.7162 - val_accuracy: 0.7670\n",
            "Epoch 247/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6531 - accuracy: 0.7782 - val_loss: 0.7265 - val_accuracy: 0.7750\n",
            "Epoch 248/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6552 - accuracy: 0.7714 - val_loss: 0.7377 - val_accuracy: 0.7728\n",
            "Epoch 249/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.7860 - val_loss: 0.7193 - val_accuracy: 0.7756\n",
            "Epoch 250/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6511 - accuracy: 0.7864 - val_loss: 0.7283 - val_accuracy: 0.7722\n",
            "Epoch 251/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6436 - accuracy: 0.7838 - val_loss: 0.7220 - val_accuracy: 0.7745\n",
            "Epoch 252/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6500 - accuracy: 0.7821 - val_loss: 0.7226 - val_accuracy: 0.7687\n",
            "Epoch 253/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6331 - accuracy: 0.7822 - val_loss: 0.7118 - val_accuracy: 0.7785\n",
            "Epoch 254/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6604 - accuracy: 0.7820 - val_loss: 0.7216 - val_accuracy: 0.7699\n",
            "Epoch 255/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.7863 - val_loss: 0.7344 - val_accuracy: 0.7693\n",
            "Epoch 256/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6341 - accuracy: 0.7906 - val_loss: 0.7320 - val_accuracy: 0.7630\n",
            "Epoch 257/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6727 - accuracy: 0.7734 - val_loss: 0.7033 - val_accuracy: 0.7670\n",
            "Epoch 258/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.7815 - val_loss: 0.7278 - val_accuracy: 0.7745\n",
            "Epoch 259/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6767 - accuracy: 0.7765 - val_loss: 0.7172 - val_accuracy: 0.7762\n",
            "Epoch 260/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6422 - accuracy: 0.7847 - val_loss: 0.7164 - val_accuracy: 0.7745\n",
            "Epoch 261/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6308 - accuracy: 0.7834 - val_loss: 0.7311 - val_accuracy: 0.7745\n",
            "Epoch 262/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6567 - accuracy: 0.7795 - val_loss: 0.7165 - val_accuracy: 0.7750\n",
            "Epoch 263/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6449 - accuracy: 0.7785 - val_loss: 0.7202 - val_accuracy: 0.7693\n",
            "Epoch 264/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6354 - accuracy: 0.7807 - val_loss: 0.7123 - val_accuracy: 0.7779\n",
            "Epoch 265/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6361 - accuracy: 0.7837 - val_loss: 0.7154 - val_accuracy: 0.7722\n",
            "Epoch 266/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6488 - accuracy: 0.7840 - val_loss: 0.7395 - val_accuracy: 0.7716\n",
            "Epoch 267/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.6422 - accuracy: 0.7838 - val_loss: 0.7286 - val_accuracy: 0.7693\n",
            "Epoch 268/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.6549 - accuracy: 0.7840 - val_loss: 0.7085 - val_accuracy: 0.7796\n",
            "Epoch 269/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6583 - accuracy: 0.7798 - val_loss: 0.7172 - val_accuracy: 0.7808\n",
            "Epoch 270/300\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.6538 - accuracy: 0.7767 - val_loss: 0.7203 - val_accuracy: 0.7602\n",
            "Epoch 271/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.6552 - accuracy: 0.7781 - val_loss: 0.7132 - val_accuracy: 0.7699\n",
            "Epoch 272/300\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.6335 - accuracy: 0.7841 - val_loss: 0.7094 - val_accuracy: 0.7728\n",
            "Epoch 273/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6233 - accuracy: 0.7853 - val_loss: 0.7220 - val_accuracy: 0.7682\n",
            "Epoch 274/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6430 - accuracy: 0.7857 - val_loss: 0.7239 - val_accuracy: 0.7710\n",
            "Epoch 275/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6473 - accuracy: 0.7861 - val_loss: 0.7100 - val_accuracy: 0.7653\n",
            "Epoch 276/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6246 - accuracy: 0.7904 - val_loss: 0.7327 - val_accuracy: 0.7665\n",
            "Epoch 277/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6275 - accuracy: 0.7854 - val_loss: 0.7542 - val_accuracy: 0.7624\n",
            "Epoch 278/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6322 - accuracy: 0.7848 - val_loss: 0.7244 - val_accuracy: 0.7716\n",
            "Epoch 279/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6246 - accuracy: 0.7958 - val_loss: 0.7332 - val_accuracy: 0.7676\n",
            "Epoch 280/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.7811 - val_loss: 0.7281 - val_accuracy: 0.7705\n",
            "Epoch 281/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6476 - accuracy: 0.7850 - val_loss: 0.7372 - val_accuracy: 0.7665\n",
            "Epoch 282/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.7853 - val_loss: 0.7296 - val_accuracy: 0.7670\n",
            "Epoch 283/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6314 - accuracy: 0.7881 - val_loss: 0.7203 - val_accuracy: 0.7716\n",
            "Epoch 284/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6259 - accuracy: 0.7903 - val_loss: 0.7363 - val_accuracy: 0.7624\n",
            "Epoch 285/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.7850 - val_loss: 0.7373 - val_accuracy: 0.7630\n",
            "Epoch 286/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6487 - accuracy: 0.7820 - val_loss: 0.7143 - val_accuracy: 0.7733\n",
            "Epoch 287/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6183 - accuracy: 0.7938 - val_loss: 0.7282 - val_accuracy: 0.7699\n",
            "Epoch 288/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6354 - accuracy: 0.7895 - val_loss: 0.7190 - val_accuracy: 0.7699\n",
            "Epoch 289/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.7881 - val_loss: 0.7195 - val_accuracy: 0.7653\n",
            "Epoch 290/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6325 - accuracy: 0.7855 - val_loss: 0.7114 - val_accuracy: 0.7756\n",
            "Epoch 291/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6309 - accuracy: 0.7904 - val_loss: 0.7236 - val_accuracy: 0.7796\n",
            "Epoch 292/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6276 - accuracy: 0.7907 - val_loss: 0.7207 - val_accuracy: 0.7722\n",
            "Epoch 293/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.7956 - val_loss: 0.7264 - val_accuracy: 0.7716\n",
            "Epoch 294/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6351 - accuracy: 0.7895 - val_loss: 0.7131 - val_accuracy: 0.7665\n",
            "Epoch 295/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.7888 - val_loss: 0.7210 - val_accuracy: 0.7665\n",
            "Epoch 296/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6320 - accuracy: 0.7850 - val_loss: 0.7467 - val_accuracy: 0.7550\n",
            "Epoch 297/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6306 - accuracy: 0.7888 - val_loss: 0.7112 - val_accuracy: 0.7705\n",
            "Epoch 298/300\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6309 - accuracy: 0.7878 - val_loss: 0.7180 - val_accuracy: 0.7710\n",
            "Epoch 299/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6272 - accuracy: 0.7906 - val_loss: 0.7160 - val_accuracy: 0.7733\n",
            "Epoch 300/300\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6196 - accuracy: 0.7906 - val_loss: 0.7031 - val_accuracy: 0.7768\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe7ec274fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "                                \n",
        "model.add(tf.keras.layers.Conv1D(16,2, activation ='relu', input_shape= (20, 1)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "              \n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32))\n",
        "\n",
        "            \n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=\"Adam\",loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])\n",
        "\n",
        "num_epochs = 500\n",
        "num_batch_size = 64\n",
        "\n",
        "model.fit(\n",
        "          x_train, \n",
        "          y_train, \n",
        "          batch_size=num_batch_size, \n",
        "          epochs=num_epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[callbacks]\n",
        "         )"
      ],
      "metadata": {
        "id": "_7FvTx0Wpf-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a90c14d-73e6-4151-86b3-b04bafba6b94"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_20 (Conv1D)          (None, 19, 16)            48        \n",
            "                                                                 \n",
            " flatten_15 (Flatten)        (None, 304)               0         \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 128)               39040     \n",
            "                                                                 \n",
            " activation_68 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_51 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " activation_69 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_52 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " activation_70 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_53 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            " activation_71 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66,266\n",
            "Trainable params: 66,266\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 2.0960 - accuracy: 0.2133 - val_loss: 1.8564 - val_accuracy: 0.3051\n",
            "Epoch 2/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7988 - accuracy: 0.3321 - val_loss: 1.6615 - val_accuracy: 0.3784\n",
            "Epoch 3/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6700 - accuracy: 0.3966 - val_loss: 1.5296 - val_accuracy: 0.4413\n",
            "Epoch 4/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5912 - accuracy: 0.4336 - val_loss: 1.4827 - val_accuracy: 0.4728\n",
            "Epoch 5/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5310 - accuracy: 0.4580 - val_loss: 1.4322 - val_accuracy: 0.4974\n",
            "Epoch 6/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4704 - accuracy: 0.4869 - val_loss: 1.3811 - val_accuracy: 0.5089\n",
            "Epoch 7/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4247 - accuracy: 0.5048 - val_loss: 1.3345 - val_accuracy: 0.5369\n",
            "Epoch 8/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3795 - accuracy: 0.5183 - val_loss: 1.2790 - val_accuracy: 0.5678\n",
            "Epoch 9/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.3329 - accuracy: 0.5386 - val_loss: 1.2412 - val_accuracy: 0.5839\n",
            "Epoch 10/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2885 - accuracy: 0.5566 - val_loss: 1.1938 - val_accuracy: 0.5993\n",
            "Epoch 11/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2363 - accuracy: 0.5755 - val_loss: 1.1337 - val_accuracy: 0.6428\n",
            "Epoch 12/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2101 - accuracy: 0.5864 - val_loss: 1.0783 - val_accuracy: 0.6325\n",
            "Epoch 13/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1685 - accuracy: 0.5987 - val_loss: 1.0723 - val_accuracy: 0.6417\n",
            "Epoch 14/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1428 - accuracy: 0.6155 - val_loss: 1.0566 - val_accuracy: 0.6468\n",
            "Epoch 15/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1077 - accuracy: 0.6232 - val_loss: 1.0089 - val_accuracy: 0.6594\n",
            "Epoch 16/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0881 - accuracy: 0.6356 - val_loss: 1.0029 - val_accuracy: 0.6543\n",
            "Epoch 17/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0648 - accuracy: 0.6409 - val_loss: 0.9703 - val_accuracy: 0.6857\n",
            "Epoch 18/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0423 - accuracy: 0.6441 - val_loss: 0.9705 - val_accuracy: 0.6817\n",
            "Epoch 19/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0138 - accuracy: 0.6604 - val_loss: 0.9473 - val_accuracy: 0.6875\n",
            "Epoch 20/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0010 - accuracy: 0.6646 - val_loss: 0.9315 - val_accuracy: 0.6920\n",
            "Epoch 21/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9875 - accuracy: 0.6649 - val_loss: 0.9298 - val_accuracy: 0.7035\n",
            "Epoch 22/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9786 - accuracy: 0.6677 - val_loss: 0.9260 - val_accuracy: 0.7006\n",
            "Epoch 23/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9511 - accuracy: 0.6786 - val_loss: 0.9099 - val_accuracy: 0.6966\n",
            "Epoch 24/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9208 - accuracy: 0.6901 - val_loss: 0.8925 - val_accuracy: 0.7052\n",
            "Epoch 25/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9225 - accuracy: 0.6941 - val_loss: 0.8929 - val_accuracy: 0.7029\n",
            "Epoch 26/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9154 - accuracy: 0.6936 - val_loss: 0.8693 - val_accuracy: 0.7132\n",
            "Epoch 27/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8902 - accuracy: 0.7029 - val_loss: 0.8804 - val_accuracy: 0.7155\n",
            "Epoch 28/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8932 - accuracy: 0.6979 - val_loss: 0.8501 - val_accuracy: 0.7247\n",
            "Epoch 29/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8535 - accuracy: 0.7135 - val_loss: 0.8389 - val_accuracy: 0.7321\n",
            "Epoch 30/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8503 - accuracy: 0.7137 - val_loss: 0.8442 - val_accuracy: 0.7327\n",
            "Epoch 31/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8480 - accuracy: 0.7142 - val_loss: 0.8666 - val_accuracy: 0.7195\n",
            "Epoch 32/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8434 - accuracy: 0.7210 - val_loss: 0.8147 - val_accuracy: 0.7378\n",
            "Epoch 33/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8185 - accuracy: 0.7277 - val_loss: 0.8231 - val_accuracy: 0.7344\n",
            "Epoch 34/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8139 - accuracy: 0.7286 - val_loss: 0.8155 - val_accuracy: 0.7390\n",
            "Epoch 35/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8181 - accuracy: 0.7246 - val_loss: 0.8117 - val_accuracy: 0.7436\n",
            "Epoch 36/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7942 - accuracy: 0.7402 - val_loss: 0.7960 - val_accuracy: 0.7453\n",
            "Epoch 37/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7658 - accuracy: 0.7437 - val_loss: 0.7907 - val_accuracy: 0.7527\n",
            "Epoch 38/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7810 - accuracy: 0.7383 - val_loss: 0.7981 - val_accuracy: 0.7476\n",
            "Epoch 39/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7590 - accuracy: 0.7455 - val_loss: 0.7817 - val_accuracy: 0.7493\n",
            "Epoch 40/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7694 - accuracy: 0.7420 - val_loss: 0.7875 - val_accuracy: 0.7481\n",
            "Epoch 41/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7502 - accuracy: 0.7486 - val_loss: 0.7735 - val_accuracy: 0.7499\n",
            "Epoch 42/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7501 - accuracy: 0.7486 - val_loss: 0.7929 - val_accuracy: 0.7436\n",
            "Epoch 43/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7525 - accuracy: 0.7486 - val_loss: 0.7647 - val_accuracy: 0.7590\n",
            "Epoch 44/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7385 - accuracy: 0.7493 - val_loss: 0.7550 - val_accuracy: 0.7602\n",
            "Epoch 45/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7415 - accuracy: 0.7506 - val_loss: 0.7724 - val_accuracy: 0.7550\n",
            "Epoch 46/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7255 - accuracy: 0.7548 - val_loss: 0.7616 - val_accuracy: 0.7562\n",
            "Epoch 47/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7167 - accuracy: 0.7621 - val_loss: 0.7530 - val_accuracy: 0.7579\n",
            "Epoch 48/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7182 - accuracy: 0.7569 - val_loss: 0.7422 - val_accuracy: 0.7670\n",
            "Epoch 49/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7091 - accuracy: 0.7626 - val_loss: 0.7590 - val_accuracy: 0.7602\n",
            "Epoch 50/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7112 - accuracy: 0.7629 - val_loss: 0.7492 - val_accuracy: 0.7636\n",
            "Epoch 51/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6911 - accuracy: 0.7664 - val_loss: 0.7435 - val_accuracy: 0.7659\n",
            "Epoch 52/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.7728 - val_loss: 0.7611 - val_accuracy: 0.7596\n",
            "Epoch 53/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.7682 - val_loss: 0.7354 - val_accuracy: 0.7687\n",
            "Epoch 54/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.7721 - val_loss: 0.7239 - val_accuracy: 0.7733\n",
            "Epoch 55/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6703 - accuracy: 0.7708 - val_loss: 0.7450 - val_accuracy: 0.7676\n",
            "Epoch 56/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6634 - accuracy: 0.7797 - val_loss: 0.7358 - val_accuracy: 0.7676\n",
            "Epoch 57/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6735 - accuracy: 0.7738 - val_loss: 0.7296 - val_accuracy: 0.7705\n",
            "Epoch 58/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6336 - accuracy: 0.7854 - val_loss: 0.7254 - val_accuracy: 0.7716\n",
            "Epoch 59/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6479 - accuracy: 0.7790 - val_loss: 0.7169 - val_accuracy: 0.7699\n",
            "Epoch 60/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.7898 - val_loss: 0.7201 - val_accuracy: 0.7739\n",
            "Epoch 61/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6378 - accuracy: 0.7825 - val_loss: 0.7062 - val_accuracy: 0.7779\n",
            "Epoch 62/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6446 - accuracy: 0.7843 - val_loss: 0.7163 - val_accuracy: 0.7716\n",
            "Epoch 63/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.7895 - val_loss: 0.7158 - val_accuracy: 0.7796\n",
            "Epoch 64/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6272 - accuracy: 0.7885 - val_loss: 0.7118 - val_accuracy: 0.7802\n",
            "Epoch 65/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.7961 - val_loss: 0.7465 - val_accuracy: 0.7710\n",
            "Epoch 66/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.7848 - val_loss: 0.7169 - val_accuracy: 0.7756\n",
            "Epoch 67/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.7981 - val_loss: 0.7052 - val_accuracy: 0.7728\n",
            "Epoch 68/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6257 - accuracy: 0.7924 - val_loss: 0.7078 - val_accuracy: 0.7802\n",
            "Epoch 69/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6120 - accuracy: 0.7906 - val_loss: 0.7203 - val_accuracy: 0.7802\n",
            "Epoch 70/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6010 - accuracy: 0.7937 - val_loss: 0.7130 - val_accuracy: 0.7796\n",
            "Epoch 71/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.7946 - val_loss: 0.7251 - val_accuracy: 0.7802\n",
            "Epoch 72/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6059 - accuracy: 0.7956 - val_loss: 0.6908 - val_accuracy: 0.7905\n",
            "Epoch 73/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6043 - accuracy: 0.7954 - val_loss: 0.7115 - val_accuracy: 0.7859\n",
            "Epoch 74/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5810 - accuracy: 0.7990 - val_loss: 0.7102 - val_accuracy: 0.7819\n",
            "Epoch 75/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5940 - accuracy: 0.8003 - val_loss: 0.6979 - val_accuracy: 0.7859\n",
            "Epoch 76/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5810 - accuracy: 0.7973 - val_loss: 0.6935 - val_accuracy: 0.7859\n",
            "Epoch 77/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5987 - accuracy: 0.8020 - val_loss: 0.6889 - val_accuracy: 0.7916\n",
            "Epoch 78/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.8003 - val_loss: 0.7169 - val_accuracy: 0.7848\n",
            "Epoch 79/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5809 - accuracy: 0.8060 - val_loss: 0.6870 - val_accuracy: 0.7876\n",
            "Epoch 80/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.8059 - val_loss: 0.7007 - val_accuracy: 0.7853\n",
            "Epoch 81/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5679 - accuracy: 0.8079 - val_loss: 0.6891 - val_accuracy: 0.7859\n",
            "Epoch 82/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5719 - accuracy: 0.8080 - val_loss: 0.6773 - val_accuracy: 0.7899\n",
            "Epoch 83/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5624 - accuracy: 0.8067 - val_loss: 0.6971 - val_accuracy: 0.7859\n",
            "Epoch 84/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5693 - accuracy: 0.8103 - val_loss: 0.7018 - val_accuracy: 0.7848\n",
            "Epoch 85/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5593 - accuracy: 0.8083 - val_loss: 0.6747 - val_accuracy: 0.7882\n",
            "Epoch 86/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5693 - accuracy: 0.8096 - val_loss: 0.6886 - val_accuracy: 0.7882\n",
            "Epoch 87/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.8127 - val_loss: 0.6757 - val_accuracy: 0.7939\n",
            "Epoch 88/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5478 - accuracy: 0.8119 - val_loss: 0.6747 - val_accuracy: 0.7934\n",
            "Epoch 89/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5469 - accuracy: 0.8139 - val_loss: 0.6815 - val_accuracy: 0.7916\n",
            "Epoch 90/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.8170 - val_loss: 0.6766 - val_accuracy: 0.7922\n",
            "Epoch 91/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.8146 - val_loss: 0.6921 - val_accuracy: 0.7911\n",
            "Epoch 92/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5513 - accuracy: 0.8115 - val_loss: 0.6992 - val_accuracy: 0.7888\n",
            "Epoch 93/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.8172 - val_loss: 0.6545 - val_accuracy: 0.7968\n",
            "Epoch 94/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.8229 - val_loss: 0.6569 - val_accuracy: 0.7985\n",
            "Epoch 95/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.8178 - val_loss: 0.6568 - val_accuracy: 0.7968\n",
            "Epoch 96/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5387 - accuracy: 0.8199 - val_loss: 0.6582 - val_accuracy: 0.8042\n",
            "Epoch 97/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.8251 - val_loss: 0.6686 - val_accuracy: 0.7979\n",
            "Epoch 98/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.8196 - val_loss: 0.6662 - val_accuracy: 0.7974\n",
            "Epoch 99/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.8170 - val_loss: 0.6594 - val_accuracy: 0.8002\n",
            "Epoch 100/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.8252 - val_loss: 0.6692 - val_accuracy: 0.7934\n",
            "Epoch 101/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.8232 - val_loss: 0.6938 - val_accuracy: 0.7962\n",
            "Epoch 102/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5354 - accuracy: 0.8188 - val_loss: 0.6463 - val_accuracy: 0.8031\n",
            "Epoch 103/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.8200 - val_loss: 0.6830 - val_accuracy: 0.7956\n",
            "Epoch 104/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.8216 - val_loss: 0.6649 - val_accuracy: 0.8065\n",
            "Epoch 105/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5087 - accuracy: 0.8288 - val_loss: 0.6770 - val_accuracy: 0.7962\n",
            "Epoch 106/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5192 - accuracy: 0.8218 - val_loss: 0.6531 - val_accuracy: 0.8105\n",
            "Epoch 107/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.8243 - val_loss: 0.6695 - val_accuracy: 0.7979\n",
            "Epoch 108/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.8308 - val_loss: 0.6559 - val_accuracy: 0.8014\n",
            "Epoch 109/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.8308 - val_loss: 0.6594 - val_accuracy: 0.7991\n",
            "Epoch 110/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5158 - accuracy: 0.8258 - val_loss: 0.6654 - val_accuracy: 0.8019\n",
            "Epoch 111/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.8319 - val_loss: 0.6635 - val_accuracy: 0.7997\n",
            "Epoch 112/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.8362 - val_loss: 0.6863 - val_accuracy: 0.7922\n",
            "Epoch 113/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.8308 - val_loss: 0.6588 - val_accuracy: 0.8077\n",
            "Epoch 114/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.8293 - val_loss: 0.6519 - val_accuracy: 0.8037\n",
            "Epoch 115/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.8299 - val_loss: 0.6376 - val_accuracy: 0.8065\n",
            "Epoch 116/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4827 - accuracy: 0.8366 - val_loss: 0.6629 - val_accuracy: 0.7997\n",
            "Epoch 117/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.8338 - val_loss: 0.6559 - val_accuracy: 0.7991\n",
            "Epoch 118/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.8421 - val_loss: 0.6699 - val_accuracy: 0.7997\n",
            "Epoch 119/500\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.4867 - accuracy: 0.8366 - val_loss: 0.6732 - val_accuracy: 0.7985\n",
            "Epoch 120/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4979 - accuracy: 0.8324 - val_loss: 0.6375 - val_accuracy: 0.8019\n",
            "Epoch 121/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.8366 - val_loss: 0.6744 - val_accuracy: 0.7934\n",
            "Epoch 122/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.8366 - val_loss: 0.6414 - val_accuracy: 0.8019\n",
            "Epoch 123/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.8314 - val_loss: 0.6359 - val_accuracy: 0.8065\n",
            "Epoch 124/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.8415 - val_loss: 0.6444 - val_accuracy: 0.8134\n",
            "Epoch 125/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.8407 - val_loss: 0.6693 - val_accuracy: 0.8117\n",
            "Epoch 126/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.8359 - val_loss: 0.6465 - val_accuracy: 0.8122\n",
            "Epoch 127/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.8359 - val_loss: 0.6563 - val_accuracy: 0.8002\n",
            "Epoch 128/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.8407 - val_loss: 0.6638 - val_accuracy: 0.8019\n",
            "Epoch 129/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.8415 - val_loss: 0.6543 - val_accuracy: 0.8037\n",
            "Epoch 130/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4832 - accuracy: 0.8382 - val_loss: 0.6512 - val_accuracy: 0.8128\n",
            "Epoch 131/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.8358 - val_loss: 0.6699 - val_accuracy: 0.7991\n",
            "Epoch 132/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.8475 - val_loss: 0.6592 - val_accuracy: 0.8042\n",
            "Epoch 133/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.8366 - val_loss: 0.6422 - val_accuracy: 0.8065\n",
            "Epoch 134/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.8402 - val_loss: 0.6452 - val_accuracy: 0.8048\n",
            "Epoch 135/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.8397 - val_loss: 0.6505 - val_accuracy: 0.8082\n",
            "Epoch 136/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.8425 - val_loss: 0.6584 - val_accuracy: 0.8077\n",
            "Epoch 137/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.8397 - val_loss: 0.6535 - val_accuracy: 0.8088\n",
            "Epoch 138/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.8389 - val_loss: 0.6502 - val_accuracy: 0.8008\n",
            "Epoch 139/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.8452 - val_loss: 0.6495 - val_accuracy: 0.8117\n",
            "Epoch 140/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.8462 - val_loss: 0.6313 - val_accuracy: 0.8111\n",
            "Epoch 141/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.8515 - val_loss: 0.6536 - val_accuracy: 0.8140\n",
            "Epoch 142/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.8441 - val_loss: 0.6514 - val_accuracy: 0.8094\n",
            "Epoch 143/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.8442 - val_loss: 0.6490 - val_accuracy: 0.8094\n",
            "Epoch 144/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.8482 - val_loss: 0.6266 - val_accuracy: 0.8128\n",
            "Epoch 145/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.8491 - val_loss: 0.6325 - val_accuracy: 0.8151\n",
            "Epoch 146/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.8461 - val_loss: 0.6251 - val_accuracy: 0.8134\n",
            "Epoch 147/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.8408 - val_loss: 0.6412 - val_accuracy: 0.7991\n",
            "Epoch 148/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.8461 - val_loss: 0.6766 - val_accuracy: 0.8065\n",
            "Epoch 149/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.8488 - val_loss: 0.6575 - val_accuracy: 0.8094\n",
            "Epoch 150/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.8494 - val_loss: 0.6595 - val_accuracy: 0.8088\n",
            "Epoch 151/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.8494 - val_loss: 0.6546 - val_accuracy: 0.8077\n",
            "Epoch 152/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.8530 - val_loss: 0.6844 - val_accuracy: 0.8065\n",
            "Epoch 153/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.8484 - val_loss: 0.6599 - val_accuracy: 0.8002\n",
            "Epoch 154/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.8554 - val_loss: 0.6295 - val_accuracy: 0.8168\n",
            "Epoch 155/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.8498 - val_loss: 0.6666 - val_accuracy: 0.8054\n",
            "Epoch 156/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.8514 - val_loss: 0.6492 - val_accuracy: 0.8140\n",
            "Epoch 157/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.8504 - val_loss: 0.6577 - val_accuracy: 0.8140\n",
            "Epoch 158/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.8584 - val_loss: 0.6594 - val_accuracy: 0.8094\n",
            "Epoch 159/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.8460 - val_loss: 0.6646 - val_accuracy: 0.8122\n",
            "Epoch 160/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8555 - val_loss: 0.6598 - val_accuracy: 0.8111\n",
            "Epoch 161/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.8613 - val_loss: 0.6331 - val_accuracy: 0.8151\n",
            "Epoch 162/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.8517 - val_loss: 0.6736 - val_accuracy: 0.8077\n",
            "Epoch 163/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.8551 - val_loss: 0.6508 - val_accuracy: 0.8128\n",
            "Epoch 164/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.8554 - val_loss: 0.6416 - val_accuracy: 0.8128\n",
            "Epoch 165/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.8535 - val_loss: 0.6737 - val_accuracy: 0.8025\n",
            "Epoch 166/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.8534 - val_loss: 0.6831 - val_accuracy: 0.8105\n",
            "Epoch 167/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.8515 - val_loss: 0.6203 - val_accuracy: 0.8174\n",
            "Epoch 168/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.8564 - val_loss: 0.6445 - val_accuracy: 0.8082\n",
            "Epoch 169/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8578 - val_loss: 0.6364 - val_accuracy: 0.8145\n",
            "Epoch 170/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.8538 - val_loss: 0.6490 - val_accuracy: 0.8082\n",
            "Epoch 171/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.8488 - val_loss: 0.6459 - val_accuracy: 0.8054\n",
            "Epoch 172/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8617 - val_loss: 0.6501 - val_accuracy: 0.8174\n",
            "Epoch 173/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4293 - accuracy: 0.8534 - val_loss: 0.6684 - val_accuracy: 0.8042\n",
            "Epoch 174/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4066 - accuracy: 0.8649 - val_loss: 0.6653 - val_accuracy: 0.8122\n",
            "Epoch 175/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4145 - accuracy: 0.8630 - val_loss: 0.6666 - val_accuracy: 0.8088\n",
            "Epoch 176/500\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4244 - accuracy: 0.8584 - val_loss: 0.6736 - val_accuracy: 0.8008\n",
            "Epoch 177/500\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4280 - accuracy: 0.8561 - val_loss: 0.6607 - val_accuracy: 0.8065\n",
            "Epoch 178/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4542 - accuracy: 0.8511 - val_loss: 0.6646 - val_accuracy: 0.8060\n",
            "Epoch 179/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8610 - val_loss: 0.6659 - val_accuracy: 0.8088\n",
            "Epoch 180/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.8561 - val_loss: 0.6570 - val_accuracy: 0.8134\n",
            "Epoch 181/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8574 - val_loss: 0.6892 - val_accuracy: 0.8042\n",
            "Epoch 182/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.8596 - val_loss: 0.6633 - val_accuracy: 0.8054\n",
            "Epoch 183/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8608 - val_loss: 0.6311 - val_accuracy: 0.8163\n",
            "Epoch 184/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.8594 - val_loss: 0.6686 - val_accuracy: 0.8088\n",
            "Epoch 185/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8677 - val_loss: 0.6653 - val_accuracy: 0.8054\n",
            "Epoch 186/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8603 - val_loss: 0.6670 - val_accuracy: 0.8157\n",
            "Epoch 187/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3947 - accuracy: 0.8676 - val_loss: 0.6588 - val_accuracy: 0.8168\n",
            "Epoch 188/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.8580 - val_loss: 0.6832 - val_accuracy: 0.8060\n",
            "Epoch 189/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8656 - val_loss: 0.6618 - val_accuracy: 0.8145\n",
            "Epoch 190/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8624 - val_loss: 0.6482 - val_accuracy: 0.8128\n",
            "Epoch 191/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8563 - val_loss: 0.6628 - val_accuracy: 0.8105\n",
            "Epoch 192/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8649 - val_loss: 0.6747 - val_accuracy: 0.8094\n",
            "Epoch 193/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8623 - val_loss: 0.6436 - val_accuracy: 0.8191\n",
            "Epoch 194/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8687 - val_loss: 0.6642 - val_accuracy: 0.8191\n",
            "Epoch 195/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8634 - val_loss: 0.6451 - val_accuracy: 0.8128\n",
            "Epoch 196/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.8646 - val_loss: 0.6739 - val_accuracy: 0.8060\n",
            "Epoch 197/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.8633 - val_loss: 0.6530 - val_accuracy: 0.8140\n",
            "Epoch 198/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8722 - val_loss: 0.6536 - val_accuracy: 0.8203\n",
            "Epoch 199/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8650 - val_loss: 0.6524 - val_accuracy: 0.8134\n",
            "Epoch 200/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8621 - val_loss: 0.6479 - val_accuracy: 0.8128\n",
            "Epoch 201/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3875 - accuracy: 0.8713 - val_loss: 0.6780 - val_accuracy: 0.8145\n",
            "Epoch 202/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8603 - val_loss: 0.6486 - val_accuracy: 0.8145\n",
            "Epoch 203/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8660 - val_loss: 0.6442 - val_accuracy: 0.8088\n",
            "Epoch 204/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8646 - val_loss: 0.6777 - val_accuracy: 0.8122\n",
            "Epoch 205/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3851 - accuracy: 0.8704 - val_loss: 0.6401 - val_accuracy: 0.8122\n",
            "Epoch 206/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.8664 - val_loss: 0.6545 - val_accuracy: 0.8094\n",
            "Epoch 207/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.8730 - val_loss: 0.6514 - val_accuracy: 0.8145\n",
            "Epoch 208/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8690 - val_loss: 0.7011 - val_accuracy: 0.8065\n",
            "Epoch 209/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 0.8676 - val_loss: 0.6817 - val_accuracy: 0.8077\n",
            "Epoch 210/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8687 - val_loss: 0.6636 - val_accuracy: 0.8237\n",
            "Epoch 211/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3959 - accuracy: 0.8689 - val_loss: 0.6771 - val_accuracy: 0.8065\n",
            "Epoch 212/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8600 - val_loss: 0.6417 - val_accuracy: 0.8157\n",
            "Epoch 213/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8676 - val_loss: 0.6468 - val_accuracy: 0.8191\n",
            "Epoch 214/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3900 - accuracy: 0.8724 - val_loss: 0.6530 - val_accuracy: 0.8145\n",
            "Epoch 215/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8646 - val_loss: 0.6661 - val_accuracy: 0.8163\n",
            "Epoch 216/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.8686 - val_loss: 0.6674 - val_accuracy: 0.8134\n",
            "Epoch 217/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3836 - accuracy: 0.8694 - val_loss: 0.6653 - val_accuracy: 0.8145\n",
            "Epoch 218/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8666 - val_loss: 0.6493 - val_accuracy: 0.8208\n",
            "Epoch 219/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3815 - accuracy: 0.8727 - val_loss: 0.6417 - val_accuracy: 0.8128\n",
            "Epoch 220/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3925 - accuracy: 0.8686 - val_loss: 0.6443 - val_accuracy: 0.8151\n",
            "Epoch 221/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8671 - val_loss: 0.6480 - val_accuracy: 0.8231\n",
            "Epoch 222/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3873 - accuracy: 0.8693 - val_loss: 0.6616 - val_accuracy: 0.8105\n",
            "Epoch 223/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3794 - accuracy: 0.8729 - val_loss: 0.6488 - val_accuracy: 0.8145\n",
            "Epoch 224/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3874 - accuracy: 0.8700 - val_loss: 0.6778 - val_accuracy: 0.8163\n",
            "Epoch 225/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.8573 - val_loss: 0.6516 - val_accuracy: 0.8117\n",
            "Epoch 226/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.8713 - val_loss: 0.6356 - val_accuracy: 0.8191\n",
            "Epoch 227/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3917 - accuracy: 0.8691 - val_loss: 0.6605 - val_accuracy: 0.8163\n",
            "Epoch 228/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3725 - accuracy: 0.8733 - val_loss: 0.6311 - val_accuracy: 0.8197\n",
            "Epoch 229/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8653 - val_loss: 0.6550 - val_accuracy: 0.8226\n",
            "Epoch 230/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3728 - accuracy: 0.8764 - val_loss: 0.6591 - val_accuracy: 0.8214\n",
            "Epoch 231/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3732 - accuracy: 0.8779 - val_loss: 0.6543 - val_accuracy: 0.8208\n",
            "Epoch 232/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3786 - accuracy: 0.8717 - val_loss: 0.6441 - val_accuracy: 0.8288\n",
            "Epoch 233/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3646 - accuracy: 0.8790 - val_loss: 0.6534 - val_accuracy: 0.8203\n",
            "Epoch 234/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3777 - accuracy: 0.8772 - val_loss: 0.6674 - val_accuracy: 0.8140\n",
            "Epoch 235/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8683 - val_loss: 0.6540 - val_accuracy: 0.8180\n",
            "Epoch 236/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3809 - accuracy: 0.8730 - val_loss: 0.6489 - val_accuracy: 0.8197\n",
            "Epoch 237/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3706 - accuracy: 0.8752 - val_loss: 0.6603 - val_accuracy: 0.8243\n",
            "Epoch 238/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.8720 - val_loss: 0.6633 - val_accuracy: 0.8151\n",
            "Epoch 239/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3927 - accuracy: 0.8726 - val_loss: 0.6455 - val_accuracy: 0.8243\n",
            "Epoch 240/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3633 - accuracy: 0.8789 - val_loss: 0.6835 - val_accuracy: 0.8174\n",
            "Epoch 241/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3631 - accuracy: 0.8795 - val_loss: 0.6609 - val_accuracy: 0.8185\n",
            "Epoch 242/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3822 - accuracy: 0.8773 - val_loss: 0.6454 - val_accuracy: 0.8300\n",
            "Epoch 243/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3833 - accuracy: 0.8742 - val_loss: 0.6756 - val_accuracy: 0.8157\n",
            "Epoch 244/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3603 - accuracy: 0.8796 - val_loss: 0.6593 - val_accuracy: 0.8220\n",
            "Epoch 245/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3663 - accuracy: 0.8772 - val_loss: 0.6565 - val_accuracy: 0.8128\n",
            "Epoch 246/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3807 - accuracy: 0.8775 - val_loss: 0.6698 - val_accuracy: 0.8180\n",
            "Epoch 247/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3637 - accuracy: 0.8764 - val_loss: 0.6742 - val_accuracy: 0.8180\n",
            "Epoch 248/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3692 - accuracy: 0.8759 - val_loss: 0.6783 - val_accuracy: 0.8174\n",
            "Epoch 249/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3648 - accuracy: 0.8754 - val_loss: 0.6757 - val_accuracy: 0.8151\n",
            "Epoch 250/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3473 - accuracy: 0.8829 - val_loss: 0.6570 - val_accuracy: 0.8168\n",
            "Epoch 251/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3780 - accuracy: 0.8769 - val_loss: 0.6607 - val_accuracy: 0.8191\n",
            "Epoch 252/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3746 - accuracy: 0.8736 - val_loss: 0.6519 - val_accuracy: 0.8254\n",
            "Epoch 253/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8833 - val_loss: 0.6680 - val_accuracy: 0.8163\n",
            "Epoch 254/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3848 - accuracy: 0.8744 - val_loss: 0.6648 - val_accuracy: 0.8151\n",
            "Epoch 255/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3782 - accuracy: 0.8709 - val_loss: 0.6460 - val_accuracy: 0.8140\n",
            "Epoch 256/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3755 - accuracy: 0.8764 - val_loss: 0.6671 - val_accuracy: 0.8100\n",
            "Epoch 257/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3795 - accuracy: 0.8723 - val_loss: 0.6708 - val_accuracy: 0.8197\n",
            "Epoch 258/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3664 - accuracy: 0.8780 - val_loss: 0.6640 - val_accuracy: 0.8140\n",
            "Epoch 259/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3647 - accuracy: 0.8793 - val_loss: 0.6541 - val_accuracy: 0.8185\n",
            "Epoch 260/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3647 - accuracy: 0.8800 - val_loss: 0.6673 - val_accuracy: 0.8122\n",
            "Epoch 261/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8694 - val_loss: 0.6468 - val_accuracy: 0.8248\n",
            "Epoch 262/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3657 - accuracy: 0.8775 - val_loss: 0.6493 - val_accuracy: 0.8220\n",
            "Epoch 263/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3675 - accuracy: 0.8766 - val_loss: 0.6476 - val_accuracy: 0.8226\n",
            "Epoch 264/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3714 - accuracy: 0.8757 - val_loss: 0.6689 - val_accuracy: 0.8163\n",
            "Epoch 265/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3671 - accuracy: 0.8792 - val_loss: 0.6778 - val_accuracy: 0.8088\n",
            "Epoch 266/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3532 - accuracy: 0.8888 - val_loss: 0.6686 - val_accuracy: 0.8237\n",
            "Epoch 267/500\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8809 - val_loss: 0.6704 - val_accuracy: 0.8163\n",
            "Epoch 268/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3641 - accuracy: 0.8820 - val_loss: 0.6782 - val_accuracy: 0.8266\n",
            "Epoch 269/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3609 - accuracy: 0.8796 - val_loss: 0.6642 - val_accuracy: 0.8185\n",
            "Epoch 270/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3588 - accuracy: 0.8815 - val_loss: 0.6637 - val_accuracy: 0.8168\n",
            "Epoch 271/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3626 - accuracy: 0.8742 - val_loss: 0.6722 - val_accuracy: 0.8163\n",
            "Epoch 272/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3644 - accuracy: 0.8830 - val_loss: 0.6486 - val_accuracy: 0.8237\n",
            "Epoch 273/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3663 - accuracy: 0.8759 - val_loss: 0.6419 - val_accuracy: 0.8237\n",
            "Epoch 274/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3595 - accuracy: 0.8777 - val_loss: 0.6816 - val_accuracy: 0.8105\n",
            "Epoch 275/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3735 - accuracy: 0.8803 - val_loss: 0.6679 - val_accuracy: 0.8185\n",
            "Epoch 276/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8802 - val_loss: 0.6650 - val_accuracy: 0.8243\n",
            "Epoch 277/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3611 - accuracy: 0.8816 - val_loss: 0.6475 - val_accuracy: 0.8243\n",
            "Epoch 278/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3804 - accuracy: 0.8752 - val_loss: 0.6724 - val_accuracy: 0.8237\n",
            "Epoch 279/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3551 - accuracy: 0.8845 - val_loss: 0.6574 - val_accuracy: 0.8145\n",
            "Epoch 280/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3473 - accuracy: 0.8866 - val_loss: 0.6680 - val_accuracy: 0.8203\n",
            "Epoch 281/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3574 - accuracy: 0.8799 - val_loss: 0.6465 - val_accuracy: 0.8203\n",
            "Epoch 282/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3589 - accuracy: 0.8786 - val_loss: 0.6561 - val_accuracy: 0.8174\n",
            "Epoch 283/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3875 - accuracy: 0.8727 - val_loss: 0.6643 - val_accuracy: 0.8197\n",
            "Epoch 284/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3514 - accuracy: 0.8809 - val_loss: 0.6787 - val_accuracy: 0.8088\n",
            "Epoch 285/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3365 - accuracy: 0.8868 - val_loss: 0.6681 - val_accuracy: 0.8271\n",
            "Epoch 286/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.8826 - val_loss: 0.6753 - val_accuracy: 0.8237\n",
            "Epoch 287/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3686 - accuracy: 0.8764 - val_loss: 0.6630 - val_accuracy: 0.8243\n",
            "Epoch 288/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3497 - accuracy: 0.8826 - val_loss: 0.6729 - val_accuracy: 0.8243\n",
            "Epoch 289/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3375 - accuracy: 0.8878 - val_loss: 0.6859 - val_accuracy: 0.8163\n",
            "Epoch 290/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3658 - accuracy: 0.8785 - val_loss: 0.6685 - val_accuracy: 0.8288\n",
            "Epoch 291/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3353 - accuracy: 0.8901 - val_loss: 0.6695 - val_accuracy: 0.8191\n",
            "Epoch 292/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3489 - accuracy: 0.8850 - val_loss: 0.6659 - val_accuracy: 0.8168\n",
            "Epoch 293/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3390 - accuracy: 0.8895 - val_loss: 0.6627 - val_accuracy: 0.8168\n",
            "Epoch 294/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8858 - val_loss: 0.6556 - val_accuracy: 0.8191\n",
            "Epoch 295/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3593 - accuracy: 0.8815 - val_loss: 0.6882 - val_accuracy: 0.8208\n",
            "Epoch 296/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3337 - accuracy: 0.8895 - val_loss: 0.6734 - val_accuracy: 0.8185\n",
            "Epoch 297/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3516 - accuracy: 0.8862 - val_loss: 0.6714 - val_accuracy: 0.8174\n",
            "Epoch 298/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3396 - accuracy: 0.8885 - val_loss: 0.6616 - val_accuracy: 0.8317\n",
            "Epoch 299/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3405 - accuracy: 0.8856 - val_loss: 0.6705 - val_accuracy: 0.8185\n",
            "Epoch 300/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3442 - accuracy: 0.8901 - val_loss: 0.6853 - val_accuracy: 0.8254\n",
            "Epoch 301/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3528 - accuracy: 0.8853 - val_loss: 0.6763 - val_accuracy: 0.8185\n",
            "Epoch 302/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3609 - accuracy: 0.8802 - val_loss: 0.6815 - val_accuracy: 0.8180\n",
            "Epoch 303/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3364 - accuracy: 0.8898 - val_loss: 0.6743 - val_accuracy: 0.8220\n",
            "Epoch 304/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8876 - val_loss: 0.6742 - val_accuracy: 0.8180\n",
            "Epoch 305/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3445 - accuracy: 0.8850 - val_loss: 0.6765 - val_accuracy: 0.8174\n",
            "Epoch 306/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3447 - accuracy: 0.8879 - val_loss: 0.6719 - val_accuracy: 0.8145\n",
            "Epoch 307/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3535 - accuracy: 0.8799 - val_loss: 0.6655 - val_accuracy: 0.8168\n",
            "Epoch 308/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3280 - accuracy: 0.8856 - val_loss: 0.6821 - val_accuracy: 0.8214\n",
            "Epoch 309/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3237 - accuracy: 0.8911 - val_loss: 0.6774 - val_accuracy: 0.8237\n",
            "Epoch 310/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.8858 - val_loss: 0.6461 - val_accuracy: 0.8237\n",
            "Epoch 311/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3318 - accuracy: 0.8901 - val_loss: 0.6783 - val_accuracy: 0.8180\n",
            "Epoch 312/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3556 - accuracy: 0.8827 - val_loss: 0.6683 - val_accuracy: 0.8145\n",
            "Epoch 313/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3416 - accuracy: 0.8878 - val_loss: 0.6515 - val_accuracy: 0.8260\n",
            "Epoch 314/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3374 - accuracy: 0.8832 - val_loss: 0.6525 - val_accuracy: 0.8277\n",
            "Epoch 315/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8848 - val_loss: 0.6634 - val_accuracy: 0.8203\n",
            "Epoch 316/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3319 - accuracy: 0.8961 - val_loss: 0.6733 - val_accuracy: 0.8197\n",
            "Epoch 317/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3505 - accuracy: 0.8889 - val_loss: 0.6591 - val_accuracy: 0.8226\n",
            "Epoch 318/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.8859 - val_loss: 0.6526 - val_accuracy: 0.8214\n",
            "Epoch 319/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.8862 - val_loss: 0.6716 - val_accuracy: 0.8180\n",
            "Epoch 320/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3677 - accuracy: 0.8749 - val_loss: 0.6809 - val_accuracy: 0.8185\n",
            "Epoch 321/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3274 - accuracy: 0.8906 - val_loss: 0.6693 - val_accuracy: 0.8220\n",
            "Epoch 322/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3359 - accuracy: 0.8899 - val_loss: 0.6662 - val_accuracy: 0.8191\n",
            "Epoch 323/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8862 - val_loss: 0.6538 - val_accuracy: 0.8191\n",
            "Epoch 324/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3275 - accuracy: 0.8929 - val_loss: 0.6741 - val_accuracy: 0.8168\n",
            "Epoch 325/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3273 - accuracy: 0.8956 - val_loss: 0.6892 - val_accuracy: 0.8174\n",
            "Epoch 326/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3304 - accuracy: 0.8903 - val_loss: 0.6650 - val_accuracy: 0.8157\n",
            "Epoch 327/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3353 - accuracy: 0.8911 - val_loss: 0.6717 - val_accuracy: 0.8168\n",
            "Epoch 328/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3302 - accuracy: 0.8942 - val_loss: 0.6772 - val_accuracy: 0.8151\n",
            "Epoch 329/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3358 - accuracy: 0.8908 - val_loss: 0.6727 - val_accuracy: 0.8168\n",
            "Epoch 330/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3226 - accuracy: 0.8943 - val_loss: 0.6729 - val_accuracy: 0.8254\n",
            "Epoch 331/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3310 - accuracy: 0.8912 - val_loss: 0.6612 - val_accuracy: 0.8128\n",
            "Epoch 332/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3191 - accuracy: 0.8902 - val_loss: 0.6782 - val_accuracy: 0.8157\n",
            "Epoch 333/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.8931 - val_loss: 0.6910 - val_accuracy: 0.8197\n",
            "Epoch 334/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.8951 - val_loss: 0.6597 - val_accuracy: 0.8203\n",
            "Epoch 335/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3408 - accuracy: 0.8882 - val_loss: 0.6803 - val_accuracy: 0.8168\n",
            "Epoch 336/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3262 - accuracy: 0.8942 - val_loss: 0.6620 - val_accuracy: 0.8208\n",
            "Epoch 337/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3282 - accuracy: 0.8912 - val_loss: 0.7011 - val_accuracy: 0.8151\n",
            "Epoch 338/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3336 - accuracy: 0.8882 - val_loss: 0.6630 - val_accuracy: 0.8226\n",
            "Epoch 339/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3370 - accuracy: 0.8889 - val_loss: 0.6748 - val_accuracy: 0.8226\n",
            "Epoch 340/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3377 - accuracy: 0.8889 - val_loss: 0.6853 - val_accuracy: 0.8214\n",
            "Epoch 341/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3460 - accuracy: 0.8858 - val_loss: 0.6655 - val_accuracy: 0.8248\n",
            "Epoch 342/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3423 - accuracy: 0.8913 - val_loss: 0.6896 - val_accuracy: 0.8220\n",
            "Epoch 343/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3303 - accuracy: 0.8922 - val_loss: 0.6777 - val_accuracy: 0.8134\n",
            "Epoch 344/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3106 - accuracy: 0.8961 - val_loss: 0.7153 - val_accuracy: 0.8151\n",
            "Epoch 345/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3225 - accuracy: 0.8921 - val_loss: 0.6763 - val_accuracy: 0.8185\n",
            "Epoch 346/500\n",
            "110/110 [==============================] - 1s 4ms/step - loss: 0.3370 - accuracy: 0.8941 - val_loss: 0.6694 - val_accuracy: 0.8117\n",
            "Epoch 347/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3186 - accuracy: 0.8908 - val_loss: 0.6956 - val_accuracy: 0.8203\n",
            "Epoch 348/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3114 - accuracy: 0.8938 - val_loss: 0.6901 - val_accuracy: 0.8288\n",
            "Epoch 349/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3212 - accuracy: 0.8925 - val_loss: 0.6610 - val_accuracy: 0.8277\n",
            "Epoch 350/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.8852 - val_loss: 0.6643 - val_accuracy: 0.8180\n",
            "Epoch 351/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3144 - accuracy: 0.8961 - val_loss: 0.6785 - val_accuracy: 0.8220\n",
            "Epoch 352/500\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.3307 - accuracy: 0.8946 - val_loss: 0.6752 - val_accuracy: 0.8243\n",
            "Epoch 353/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3121 - accuracy: 0.8968 - val_loss: 0.6700 - val_accuracy: 0.8220\n",
            "Epoch 354/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3239 - accuracy: 0.8943 - val_loss: 0.6543 - val_accuracy: 0.8271\n",
            "Epoch 355/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3284 - accuracy: 0.8869 - val_loss: 0.6963 - val_accuracy: 0.8191\n",
            "Epoch 356/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3253 - accuracy: 0.8956 - val_loss: 0.6788 - val_accuracy: 0.8214\n",
            "Epoch 357/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3308 - accuracy: 0.8936 - val_loss: 0.6656 - val_accuracy: 0.8191\n",
            "Epoch 358/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3139 - accuracy: 0.8966 - val_loss: 0.6861 - val_accuracy: 0.8300\n",
            "Epoch 359/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3328 - accuracy: 0.8931 - val_loss: 0.6706 - val_accuracy: 0.8185\n",
            "Epoch 360/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3104 - accuracy: 0.8989 - val_loss: 0.6624 - val_accuracy: 0.8168\n",
            "Epoch 361/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3273 - accuracy: 0.8941 - val_loss: 0.6725 - val_accuracy: 0.8260\n",
            "Epoch 362/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3176 - accuracy: 0.8969 - val_loss: 0.6760 - val_accuracy: 0.8283\n",
            "Epoch 363/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3265 - accuracy: 0.8942 - val_loss: 0.6745 - val_accuracy: 0.8231\n",
            "Epoch 364/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3266 - accuracy: 0.8951 - val_loss: 0.6672 - val_accuracy: 0.8128\n",
            "Epoch 365/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3386 - accuracy: 0.8848 - val_loss: 0.6679 - val_accuracy: 0.8145\n",
            "Epoch 366/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3338 - accuracy: 0.8888 - val_loss: 0.6700 - val_accuracy: 0.8151\n",
            "Epoch 367/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3256 - accuracy: 0.8938 - val_loss: 0.6628 - val_accuracy: 0.8168\n",
            "Epoch 368/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3171 - accuracy: 0.8979 - val_loss: 0.6566 - val_accuracy: 0.8226\n",
            "Epoch 369/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3142 - accuracy: 0.8969 - val_loss: 0.7030 - val_accuracy: 0.8128\n",
            "Epoch 370/500\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.3180 - accuracy: 0.8952 - val_loss: 0.6616 - val_accuracy: 0.8248\n",
            "Epoch 371/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3334 - accuracy: 0.8912 - val_loss: 0.6539 - val_accuracy: 0.8214\n",
            "Epoch 372/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3312 - accuracy: 0.8925 - val_loss: 0.6874 - val_accuracy: 0.8266\n",
            "Epoch 373/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3330 - accuracy: 0.8902 - val_loss: 0.6665 - val_accuracy: 0.8151\n",
            "Epoch 374/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8931 - val_loss: 0.6898 - val_accuracy: 0.8180\n",
            "Epoch 375/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3255 - accuracy: 0.8926 - val_loss: 0.6942 - val_accuracy: 0.8134\n",
            "Epoch 376/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3044 - accuracy: 0.8982 - val_loss: 0.6819 - val_accuracy: 0.8185\n",
            "Epoch 377/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3349 - accuracy: 0.8918 - val_loss: 0.6825 - val_accuracy: 0.8203\n",
            "Epoch 378/500\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.3229 - accuracy: 0.8931 - val_loss: 0.6613 - val_accuracy: 0.8220\n",
            "Epoch 379/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2993 - accuracy: 0.9014 - val_loss: 0.6812 - val_accuracy: 0.8248\n",
            "Epoch 380/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3340 - accuracy: 0.8908 - val_loss: 0.6695 - val_accuracy: 0.8260\n",
            "Epoch 381/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3109 - accuracy: 0.8988 - val_loss: 0.7207 - val_accuracy: 0.8214\n",
            "Epoch 382/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3246 - accuracy: 0.8922 - val_loss: 0.6802 - val_accuracy: 0.8185\n",
            "Epoch 383/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3128 - accuracy: 0.8961 - val_loss: 0.6542 - val_accuracy: 0.8260\n",
            "Epoch 384/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3194 - accuracy: 0.8952 - val_loss: 0.6822 - val_accuracy: 0.8128\n",
            "Epoch 385/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3108 - accuracy: 0.8958 - val_loss: 0.6752 - val_accuracy: 0.8254\n",
            "Epoch 386/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3270 - accuracy: 0.8931 - val_loss: 0.6484 - val_accuracy: 0.8248\n",
            "Epoch 387/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3011 - accuracy: 0.9002 - val_loss: 0.6600 - val_accuracy: 0.8294\n",
            "Epoch 388/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3333 - accuracy: 0.8925 - val_loss: 0.6651 - val_accuracy: 0.8237\n",
            "Epoch 389/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3086 - accuracy: 0.8995 - val_loss: 0.6676 - val_accuracy: 0.8266\n",
            "Epoch 390/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3371 - accuracy: 0.8911 - val_loss: 0.6624 - val_accuracy: 0.8237\n",
            "Epoch 391/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3175 - accuracy: 0.8941 - val_loss: 0.6655 - val_accuracy: 0.8168\n",
            "Epoch 392/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3171 - accuracy: 0.8966 - val_loss: 0.6760 - val_accuracy: 0.8266\n",
            "Epoch 393/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3003 - accuracy: 0.9028 - val_loss: 0.6781 - val_accuracy: 0.8231\n",
            "Epoch 394/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3243 - accuracy: 0.8918 - val_loss: 0.6524 - val_accuracy: 0.8254\n",
            "Epoch 395/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3143 - accuracy: 0.8991 - val_loss: 0.6501 - val_accuracy: 0.8277\n",
            "Epoch 396/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2909 - accuracy: 0.9022 - val_loss: 0.6883 - val_accuracy: 0.8163\n",
            "Epoch 397/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3088 - accuracy: 0.8969 - val_loss: 0.6662 - val_accuracy: 0.8191\n",
            "Epoch 398/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3215 - accuracy: 0.8931 - val_loss: 0.6803 - val_accuracy: 0.8197\n",
            "Epoch 399/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3239 - accuracy: 0.8948 - val_loss: 0.6897 - val_accuracy: 0.8243\n",
            "Epoch 400/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3076 - accuracy: 0.9002 - val_loss: 0.6815 - val_accuracy: 0.8237\n",
            "Epoch 401/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2930 - accuracy: 0.9069 - val_loss: 0.6943 - val_accuracy: 0.8283\n",
            "Epoch 402/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3309 - accuracy: 0.8905 - val_loss: 0.7127 - val_accuracy: 0.8134\n",
            "Epoch 403/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3046 - accuracy: 0.9049 - val_loss: 0.6957 - val_accuracy: 0.8260\n",
            "Epoch 404/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3261 - accuracy: 0.8984 - val_loss: 0.6898 - val_accuracy: 0.8191\n",
            "Epoch 405/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3032 - accuracy: 0.8988 - val_loss: 0.7004 - val_accuracy: 0.8237\n",
            "Epoch 406/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3034 - accuracy: 0.9014 - val_loss: 0.6861 - val_accuracy: 0.8266\n",
            "Epoch 407/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3027 - accuracy: 0.8988 - val_loss: 0.6769 - val_accuracy: 0.8288\n",
            "Epoch 408/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3097 - accuracy: 0.8958 - val_loss: 0.6898 - val_accuracy: 0.8214\n",
            "Epoch 409/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3068 - accuracy: 0.9006 - val_loss: 0.6994 - val_accuracy: 0.8231\n",
            "Epoch 410/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3121 - accuracy: 0.9026 - val_loss: 0.6978 - val_accuracy: 0.8208\n",
            "Epoch 411/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3258 - accuracy: 0.8919 - val_loss: 0.6848 - val_accuracy: 0.8214\n",
            "Epoch 412/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3113 - accuracy: 0.9005 - val_loss: 0.6837 - val_accuracy: 0.8254\n",
            "Epoch 413/500\n",
            "110/110 [==============================] - 1s 4ms/step - loss: 0.3098 - accuracy: 0.9049 - val_loss: 0.6726 - val_accuracy: 0.8248\n",
            "Epoch 414/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2948 - accuracy: 0.9049 - val_loss: 0.6926 - val_accuracy: 0.8208\n",
            "Epoch 415/500\n",
            "110/110 [==============================] - 1s 4ms/step - loss: 0.3105 - accuracy: 0.8988 - val_loss: 0.6741 - val_accuracy: 0.8260\n",
            "Epoch 416/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2916 - accuracy: 0.9012 - val_loss: 0.6811 - val_accuracy: 0.8266\n",
            "Epoch 417/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3140 - accuracy: 0.8992 - val_loss: 0.7005 - val_accuracy: 0.8271\n",
            "Epoch 418/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3052 - accuracy: 0.8998 - val_loss: 0.7187 - val_accuracy: 0.8163\n",
            "Epoch 419/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3169 - accuracy: 0.8958 - val_loss: 0.6706 - val_accuracy: 0.8266\n",
            "Epoch 420/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2924 - accuracy: 0.9015 - val_loss: 0.6678 - val_accuracy: 0.8260\n",
            "Epoch 421/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2915 - accuracy: 0.9052 - val_loss: 0.7080 - val_accuracy: 0.8248\n",
            "Epoch 422/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3185 - accuracy: 0.8938 - val_loss: 0.6763 - val_accuracy: 0.8277\n",
            "Epoch 423/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3064 - accuracy: 0.8974 - val_loss: 0.6554 - val_accuracy: 0.8294\n",
            "Epoch 424/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2900 - accuracy: 0.9016 - val_loss: 0.6967 - val_accuracy: 0.8185\n",
            "Epoch 425/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2999 - accuracy: 0.8989 - val_loss: 0.6605 - val_accuracy: 0.8329\n",
            "Epoch 426/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3158 - accuracy: 0.9014 - val_loss: 0.6821 - val_accuracy: 0.8283\n",
            "Epoch 427/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3122 - accuracy: 0.8961 - val_loss: 0.6832 - val_accuracy: 0.8197\n",
            "Epoch 428/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2955 - accuracy: 0.9005 - val_loss: 0.6728 - val_accuracy: 0.8294\n",
            "Epoch 429/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3005 - accuracy: 0.9034 - val_loss: 0.6865 - val_accuracy: 0.8191\n",
            "Epoch 430/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3169 - accuracy: 0.8995 - val_loss: 0.6756 - val_accuracy: 0.8220\n",
            "Epoch 431/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3090 - accuracy: 0.8969 - val_loss: 0.6893 - val_accuracy: 0.8243\n",
            "Epoch 432/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3179 - accuracy: 0.8943 - val_loss: 0.6721 - val_accuracy: 0.8254\n",
            "Epoch 433/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2936 - accuracy: 0.9062 - val_loss: 0.7127 - val_accuracy: 0.8243\n",
            "Epoch 434/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3024 - accuracy: 0.9032 - val_loss: 0.6946 - val_accuracy: 0.8271\n",
            "Epoch 435/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3042 - accuracy: 0.9011 - val_loss: 0.7125 - val_accuracy: 0.8248\n",
            "Epoch 436/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2980 - accuracy: 0.9024 - val_loss: 0.6782 - val_accuracy: 0.8191\n",
            "Epoch 437/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2942 - accuracy: 0.9048 - val_loss: 0.7288 - val_accuracy: 0.8191\n",
            "Epoch 438/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3095 - accuracy: 0.9022 - val_loss: 0.6738 - val_accuracy: 0.8283\n",
            "Epoch 439/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3135 - accuracy: 0.8952 - val_loss: 0.6758 - val_accuracy: 0.8231\n",
            "Epoch 440/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3200 - accuracy: 0.8958 - val_loss: 0.6748 - val_accuracy: 0.8214\n",
            "Epoch 441/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.8988 - val_loss: 0.6892 - val_accuracy: 0.8208\n",
            "Epoch 442/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3047 - accuracy: 0.8966 - val_loss: 0.6752 - val_accuracy: 0.8231\n",
            "Epoch 443/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2965 - accuracy: 0.9015 - val_loss: 0.6907 - val_accuracy: 0.8266\n",
            "Epoch 444/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2866 - accuracy: 0.9081 - val_loss: 0.6880 - val_accuracy: 0.8266\n",
            "Epoch 445/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2952 - accuracy: 0.9014 - val_loss: 0.6775 - val_accuracy: 0.8231\n",
            "Epoch 446/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2936 - accuracy: 0.9054 - val_loss: 0.6985 - val_accuracy: 0.8231\n",
            "Epoch 447/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2970 - accuracy: 0.9019 - val_loss: 0.6888 - val_accuracy: 0.8214\n",
            "Epoch 448/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2841 - accuracy: 0.9085 - val_loss: 0.6946 - val_accuracy: 0.8237\n",
            "Epoch 449/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3101 - accuracy: 0.9001 - val_loss: 0.6914 - val_accuracy: 0.8283\n",
            "Epoch 450/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2909 - accuracy: 0.9051 - val_loss: 0.6934 - val_accuracy: 0.8191\n",
            "Epoch 451/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2837 - accuracy: 0.9064 - val_loss: 0.6925 - val_accuracy: 0.8231\n",
            "Epoch 452/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2883 - accuracy: 0.9054 - val_loss: 0.7041 - val_accuracy: 0.8283\n",
            "Epoch 453/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2963 - accuracy: 0.9025 - val_loss: 0.7181 - val_accuracy: 0.8243\n",
            "Epoch 454/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2975 - accuracy: 0.9012 - val_loss: 0.6931 - val_accuracy: 0.8231\n",
            "Epoch 455/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2904 - accuracy: 0.9071 - val_loss: 0.6961 - val_accuracy: 0.8231\n",
            "Epoch 456/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2927 - accuracy: 0.9059 - val_loss: 0.7076 - val_accuracy: 0.8203\n",
            "Epoch 457/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2991 - accuracy: 0.9035 - val_loss: 0.7076 - val_accuracy: 0.8248\n",
            "Epoch 458/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3086 - accuracy: 0.9024 - val_loss: 0.7024 - val_accuracy: 0.8208\n",
            "Epoch 459/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3054 - accuracy: 0.8998 - val_loss: 0.6980 - val_accuracy: 0.8311\n",
            "Epoch 460/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3070 - accuracy: 0.8974 - val_loss: 0.6887 - val_accuracy: 0.8283\n",
            "Epoch 461/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2886 - accuracy: 0.9055 - val_loss: 0.7214 - val_accuracy: 0.8185\n",
            "Epoch 462/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2825 - accuracy: 0.9059 - val_loss: 0.7062 - val_accuracy: 0.8254\n",
            "Epoch 463/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2811 - accuracy: 0.9081 - val_loss: 0.7273 - val_accuracy: 0.8294\n",
            "Epoch 464/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2880 - accuracy: 0.9044 - val_loss: 0.7141 - val_accuracy: 0.8323\n",
            "Epoch 465/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3083 - accuracy: 0.9018 - val_loss: 0.6881 - val_accuracy: 0.8283\n",
            "Epoch 466/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3243 - accuracy: 0.8958 - val_loss: 0.6814 - val_accuracy: 0.8277\n",
            "Epoch 467/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3083 - accuracy: 0.8984 - val_loss: 0.7039 - val_accuracy: 0.8277\n",
            "Epoch 468/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2870 - accuracy: 0.9054 - val_loss: 0.7221 - val_accuracy: 0.8180\n",
            "Epoch 469/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2939 - accuracy: 0.9034 - val_loss: 0.6728 - val_accuracy: 0.8392\n",
            "Epoch 470/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2983 - accuracy: 0.9072 - val_loss: 0.6858 - val_accuracy: 0.8306\n",
            "Epoch 471/500\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.2889 - accuracy: 0.9051 - val_loss: 0.6994 - val_accuracy: 0.8329\n",
            "Epoch 472/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2853 - accuracy: 0.9069 - val_loss: 0.7190 - val_accuracy: 0.8203\n",
            "Epoch 473/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2903 - accuracy: 0.9018 - val_loss: 0.7302 - val_accuracy: 0.8248\n",
            "Epoch 474/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2719 - accuracy: 0.9135 - val_loss: 0.6934 - val_accuracy: 0.8271\n",
            "Epoch 475/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2693 - accuracy: 0.9102 - val_loss: 0.6848 - val_accuracy: 0.8266\n",
            "Epoch 476/500\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.2935 - accuracy: 0.9034 - val_loss: 0.6966 - val_accuracy: 0.8248\n",
            "Epoch 477/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2991 - accuracy: 0.9016 - val_loss: 0.7235 - val_accuracy: 0.8180\n",
            "Epoch 478/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3085 - accuracy: 0.8996 - val_loss: 0.7162 - val_accuracy: 0.8191\n",
            "Epoch 479/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2982 - accuracy: 0.9025 - val_loss: 0.6977 - val_accuracy: 0.8208\n",
            "Epoch 480/500\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.2792 - accuracy: 0.9065 - val_loss: 0.7405 - val_accuracy: 0.8254\n",
            "Epoch 481/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2969 - accuracy: 0.9081 - val_loss: 0.7078 - val_accuracy: 0.8254\n",
            "Epoch 482/500\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.2903 - accuracy: 0.9047 - val_loss: 0.6933 - val_accuracy: 0.8237\n",
            "Epoch 483/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2970 - accuracy: 0.9038 - val_loss: 0.6912 - val_accuracy: 0.8220\n",
            "Epoch 484/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2794 - accuracy: 0.9087 - val_loss: 0.6971 - val_accuracy: 0.8237\n",
            "Epoch 485/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2843 - accuracy: 0.9084 - val_loss: 0.6894 - val_accuracy: 0.8220\n",
            "Epoch 486/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2909 - accuracy: 0.9117 - val_loss: 0.6941 - val_accuracy: 0.8197\n",
            "Epoch 487/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2841 - accuracy: 0.9054 - val_loss: 0.6988 - val_accuracy: 0.8197\n",
            "Epoch 488/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2741 - accuracy: 0.9110 - val_loss: 0.7156 - val_accuracy: 0.8260\n",
            "Epoch 489/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2791 - accuracy: 0.9097 - val_loss: 0.7158 - val_accuracy: 0.8260\n",
            "Epoch 490/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2754 - accuracy: 0.9127 - val_loss: 0.6762 - val_accuracy: 0.8271\n",
            "Epoch 491/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2905 - accuracy: 0.9055 - val_loss: 0.7056 - val_accuracy: 0.8248\n",
            "Epoch 492/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2814 - accuracy: 0.9075 - val_loss: 0.7039 - val_accuracy: 0.8203\n",
            "Epoch 493/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2769 - accuracy: 0.9065 - val_loss: 0.6988 - val_accuracy: 0.8311\n",
            "Epoch 494/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2674 - accuracy: 0.9108 - val_loss: 0.7177 - val_accuracy: 0.8185\n",
            "Epoch 495/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2802 - accuracy: 0.9104 - val_loss: 0.7243 - val_accuracy: 0.8237\n",
            "Epoch 496/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3121 - accuracy: 0.9015 - val_loss: 0.6894 - val_accuracy: 0.8271\n",
            "Epoch 497/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3115 - accuracy: 0.8998 - val_loss: 0.6955 - val_accuracy: 0.8260\n",
            "Epoch 498/500\n",
            "110/110 [==============================] - 1s 4ms/step - loss: 0.2882 - accuracy: 0.9064 - val_loss: 0.6944 - val_accuracy: 0.8254\n",
            "Epoch 499/500\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2729 - accuracy: 0.9105 - val_loss: 0.7000 - val_accuracy: 0.8254\n",
            "Epoch 500/500\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.2951 - accuracy: 0.9085 - val_loss: 0.6884 - val_accuracy: 0.8277\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe7b825bfd0>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "scorers = {\n",
        "        'precision_score': make_scorer(precision_score),\n",
        "        'recall_score': make_scorer(recall_score),\n",
        "        'accuracy_score': make_scorer(accuracy_score)\n",
        "        }\n",
        "\n",
        "param_grid = dict(epochs=[500,1000,2000])\n",
        "grid_search_cv=GridSearchCV(model,param_grid,verbose=1,cv=3,scoring=scorers,refit=\"precision_score\")\n",
        "grid_result = grid_search_cv.fit(x, Y)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rj9bE1NJs2eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import math\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def step_decay(epoch):\n",
        "\tinitial_lrate = 0.008\n",
        "\tdrop = 0.5\n",
        "\tepochs_drop = 5.0\n",
        "\tlrate = 0.00001\n",
        "\treturn lrate      \n",
        "\n",
        "opt = Adam(lr=0.001)                                     # 0.0 here signifies this is not to be used\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "print(lrate)\n",
        "callbacks_list = [lrate]\n",
        "\n",
        "num_epochs = 1000\n",
        "num_batch_size = 128\n",
        "\n",
        "model.fit(\n",
        "          x_train, \n",
        "          y_train, \n",
        "          batch_size=num_batch_size, \n",
        "          epochs=num_epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=callbacks_list\n",
        "         )\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhT3EgV_nSJA",
        "outputId": "ba2ece75-85e8-4344-bf71-95ecfe2c4956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.callbacks.LearningRateScheduler object at 0x7f2dd5b97410>\n",
            "Epoch 1/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7082 - accuracy: 0.7496 - val_loss: 0.6190 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 2/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6960 - accuracy: 0.7593 - val_loss: 0.6190 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 3/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7035 - accuracy: 0.7502 - val_loss: 0.6190 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 4/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7063 - accuracy: 0.7552 - val_loss: 0.6188 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 5/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7258 - accuracy: 0.7473 - val_loss: 0.6188 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 6/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7089 - accuracy: 0.7539 - val_loss: 0.6187 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 7/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7061 - accuracy: 0.7512 - val_loss: 0.6189 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 8/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7052 - accuracy: 0.7552 - val_loss: 0.6191 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 9/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7145 - accuracy: 0.7529 - val_loss: 0.6193 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 10/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7136 - accuracy: 0.7489 - val_loss: 0.6194 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 11/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7072 - accuracy: 0.7543 - val_loss: 0.6192 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 12/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7018 - accuracy: 0.7545 - val_loss: 0.6191 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 13/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6995 - accuracy: 0.7496 - val_loss: 0.6189 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 14/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7160 - accuracy: 0.7482 - val_loss: 0.6187 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 15/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7157 - accuracy: 0.7503 - val_loss: 0.6188 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 16/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6949 - accuracy: 0.7555 - val_loss: 0.6183 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 17/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7069 - accuracy: 0.7592 - val_loss: 0.6180 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 18/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7007 - accuracy: 0.7548 - val_loss: 0.6179 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 19/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.7546 - val_loss: 0.6180 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 20/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7140 - accuracy: 0.7489 - val_loss: 0.6181 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 21/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6941 - accuracy: 0.7523 - val_loss: 0.6178 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 22/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6938 - accuracy: 0.7568 - val_loss: 0.6178 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 23/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7049 - accuracy: 0.7496 - val_loss: 0.6179 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 24/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7096 - accuracy: 0.7502 - val_loss: 0.6180 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 25/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7033 - accuracy: 0.7548 - val_loss: 0.6177 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 26/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7084 - accuracy: 0.7529 - val_loss: 0.6177 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
            "Epoch 27/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7130 - accuracy: 0.7542 - val_loss: 0.6174 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 28/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7128 - accuracy: 0.7510 - val_loss: 0.6174 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 29/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7058 - accuracy: 0.7522 - val_loss: 0.6172 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
            "Epoch 30/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7047 - accuracy: 0.7588 - val_loss: 0.6170 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
            "Epoch 31/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7138 - accuracy: 0.7512 - val_loss: 0.6172 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
            "Epoch 32/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7143 - accuracy: 0.7549 - val_loss: 0.6173 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 33/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6972 - accuracy: 0.7599 - val_loss: 0.6174 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
            "Epoch 34/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7071 - accuracy: 0.7536 - val_loss: 0.6178 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
            "Epoch 35/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6962 - accuracy: 0.7592 - val_loss: 0.6178 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 36/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7202 - accuracy: 0.7500 - val_loss: 0.6178 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 37/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6948 - accuracy: 0.7553 - val_loss: 0.6175 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 38/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7103 - accuracy: 0.7549 - val_loss: 0.6177 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 39/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7206 - accuracy: 0.7447 - val_loss: 0.6181 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 40/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6950 - accuracy: 0.7595 - val_loss: 0.6182 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 41/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7023 - accuracy: 0.7497 - val_loss: 0.6182 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 42/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7252 - accuracy: 0.7490 - val_loss: 0.6180 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 43/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7289 - accuracy: 0.7475 - val_loss: 0.6179 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 44/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6983 - accuracy: 0.7565 - val_loss: 0.6180 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 45/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7186 - accuracy: 0.7506 - val_loss: 0.6179 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 46/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7102 - accuracy: 0.7500 - val_loss: 0.6180 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 47/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7107 - accuracy: 0.7490 - val_loss: 0.6181 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 48/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7038 - accuracy: 0.7546 - val_loss: 0.6176 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 49/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7026 - accuracy: 0.7556 - val_loss: 0.6178 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 50/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7248 - accuracy: 0.7477 - val_loss: 0.6182 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 51/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6990 - accuracy: 0.7560 - val_loss: 0.6184 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 52/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7003 - accuracy: 0.7535 - val_loss: 0.6181 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 53/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6930 - accuracy: 0.7522 - val_loss: 0.6180 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 54/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7123 - accuracy: 0.7529 - val_loss: 0.6181 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 55/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6999 - accuracy: 0.7566 - val_loss: 0.6185 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 56/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6973 - accuracy: 0.7569 - val_loss: 0.6186 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 57/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7029 - accuracy: 0.7545 - val_loss: 0.6185 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 58/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7062 - accuracy: 0.7493 - val_loss: 0.6182 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 59/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6822 - accuracy: 0.7581 - val_loss: 0.6180 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 60/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6983 - accuracy: 0.7542 - val_loss: 0.6181 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 61/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7014 - accuracy: 0.7523 - val_loss: 0.6181 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 62/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6919 - accuracy: 0.7601 - val_loss: 0.6180 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 63/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7141 - accuracy: 0.7462 - val_loss: 0.6177 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 64/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7057 - accuracy: 0.7522 - val_loss: 0.6179 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 65/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7131 - accuracy: 0.7529 - val_loss: 0.6179 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 66/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7159 - accuracy: 0.7462 - val_loss: 0.6184 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 67/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6812 - accuracy: 0.7642 - val_loss: 0.6182 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 68/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7097 - accuracy: 0.7528 - val_loss: 0.6182 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 69/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7073 - accuracy: 0.7509 - val_loss: 0.6183 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 70/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7043 - accuracy: 0.7542 - val_loss: 0.6183 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 71/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7132 - accuracy: 0.7550 - val_loss: 0.6181 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 72/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7112 - accuracy: 0.7543 - val_loss: 0.6182 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 73/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7105 - accuracy: 0.7515 - val_loss: 0.6182 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 74/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7050 - accuracy: 0.7550 - val_loss: 0.6180 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 75/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7038 - accuracy: 0.7520 - val_loss: 0.6182 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 76/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6967 - accuracy: 0.7532 - val_loss: 0.6185 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 77/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7229 - accuracy: 0.7485 - val_loss: 0.6185 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 78/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6967 - accuracy: 0.7540 - val_loss: 0.6182 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 79/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7054 - accuracy: 0.7520 - val_loss: 0.6180 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
            "Epoch 80/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6989 - accuracy: 0.7530 - val_loss: 0.6179 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 81/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7127 - accuracy: 0.7462 - val_loss: 0.6178 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 82/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7189 - accuracy: 0.7465 - val_loss: 0.6178 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 83/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6960 - accuracy: 0.7549 - val_loss: 0.6179 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
            "Epoch 84/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7174 - accuracy: 0.7522 - val_loss: 0.6181 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 85/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7000 - accuracy: 0.7532 - val_loss: 0.6183 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 86/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7218 - accuracy: 0.7528 - val_loss: 0.6180 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 87/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7149 - accuracy: 0.7477 - val_loss: 0.6177 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 88/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7057 - accuracy: 0.7530 - val_loss: 0.6179 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 89/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6983 - accuracy: 0.7548 - val_loss: 0.6177 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 90/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7150 - accuracy: 0.7453 - val_loss: 0.6177 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 91/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7111 - accuracy: 0.7506 - val_loss: 0.6178 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 92/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7161 - accuracy: 0.7495 - val_loss: 0.6179 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 93/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6991 - accuracy: 0.7550 - val_loss: 0.6178 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 94/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7038 - accuracy: 0.7560 - val_loss: 0.6175 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 95/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7070 - accuracy: 0.7525 - val_loss: 0.6177 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 96/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7143 - accuracy: 0.7549 - val_loss: 0.6178 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 97/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6908 - accuracy: 0.7578 - val_loss: 0.6179 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 98/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7087 - accuracy: 0.7535 - val_loss: 0.6178 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 99/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7159 - accuracy: 0.7525 - val_loss: 0.6175 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 100/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7082 - accuracy: 0.7522 - val_loss: 0.6175 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 101/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7063 - accuracy: 0.7540 - val_loss: 0.6174 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 102/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6926 - accuracy: 0.7526 - val_loss: 0.6174 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 103/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6962 - accuracy: 0.7565 - val_loss: 0.6173 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 104/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7161 - accuracy: 0.7515 - val_loss: 0.6174 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 105/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6916 - accuracy: 0.7552 - val_loss: 0.6174 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 106/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7069 - accuracy: 0.7538 - val_loss: 0.6174 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 107/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7114 - accuracy: 0.7489 - val_loss: 0.6175 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 108/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7009 - accuracy: 0.7530 - val_loss: 0.6176 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 109/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6942 - accuracy: 0.7596 - val_loss: 0.6176 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 110/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7111 - accuracy: 0.7505 - val_loss: 0.6176 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 111/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7240 - accuracy: 0.7496 - val_loss: 0.6181 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 112/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6954 - accuracy: 0.7529 - val_loss: 0.6184 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 113/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7138 - accuracy: 0.7457 - val_loss: 0.6185 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 114/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7034 - accuracy: 0.7545 - val_loss: 0.6184 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 115/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7289 - accuracy: 0.7403 - val_loss: 0.6182 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 116/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7072 - accuracy: 0.7573 - val_loss: 0.6183 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 117/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6883 - accuracy: 0.7583 - val_loss: 0.6186 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 118/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7102 - accuracy: 0.7530 - val_loss: 0.6182 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 119/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7056 - accuracy: 0.7532 - val_loss: 0.6182 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 120/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7217 - accuracy: 0.7536 - val_loss: 0.6180 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
            "Epoch 121/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7201 - accuracy: 0.7475 - val_loss: 0.6180 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 122/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7020 - accuracy: 0.7519 - val_loss: 0.6183 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 123/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7037 - accuracy: 0.7487 - val_loss: 0.6182 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 124/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6961 - accuracy: 0.7555 - val_loss: 0.6178 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 125/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7139 - accuracy: 0.7497 - val_loss: 0.6176 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 126/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7013 - accuracy: 0.7502 - val_loss: 0.6176 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 127/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7130 - accuracy: 0.7543 - val_loss: 0.6178 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 128/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6920 - accuracy: 0.7578 - val_loss: 0.6179 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 129/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6973 - accuracy: 0.7508 - val_loss: 0.6179 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 130/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7037 - accuracy: 0.7543 - val_loss: 0.6176 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 131/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7273 - accuracy: 0.7426 - val_loss: 0.6173 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 132/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6881 - accuracy: 0.7578 - val_loss: 0.6173 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 133/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7009 - accuracy: 0.7588 - val_loss: 0.6173 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 134/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7074 - accuracy: 0.7582 - val_loss: 0.6173 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 135/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7060 - accuracy: 0.7550 - val_loss: 0.6176 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 136/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7021 - accuracy: 0.7575 - val_loss: 0.6178 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 137/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7058 - accuracy: 0.7520 - val_loss: 0.6179 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 138/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7196 - accuracy: 0.7505 - val_loss: 0.6180 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 139/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7044 - accuracy: 0.7543 - val_loss: 0.6181 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 140/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7111 - accuracy: 0.7487 - val_loss: 0.6180 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 141/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6923 - accuracy: 0.7571 - val_loss: 0.6181 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 142/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7064 - accuracy: 0.7540 - val_loss: 0.6180 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 143/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7151 - accuracy: 0.7512 - val_loss: 0.6181 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 144/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7003 - accuracy: 0.7558 - val_loss: 0.6184 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 145/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7075 - accuracy: 0.7519 - val_loss: 0.6183 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 146/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7114 - accuracy: 0.7475 - val_loss: 0.6181 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 147/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7045 - accuracy: 0.7553 - val_loss: 0.6180 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 148/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6967 - accuracy: 0.7539 - val_loss: 0.6182 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 149/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7031 - accuracy: 0.7583 - val_loss: 0.6181 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 150/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7117 - accuracy: 0.7550 - val_loss: 0.6180 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 151/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7121 - accuracy: 0.7555 - val_loss: 0.6180 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 152/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7046 - accuracy: 0.7518 - val_loss: 0.6177 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 153/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7197 - accuracy: 0.7445 - val_loss: 0.6176 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 154/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7035 - accuracy: 0.7518 - val_loss: 0.6176 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 155/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6863 - accuracy: 0.7595 - val_loss: 0.6178 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 156/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7034 - accuracy: 0.7560 - val_loss: 0.6178 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 157/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7139 - accuracy: 0.7565 - val_loss: 0.6180 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 158/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7005 - accuracy: 0.7497 - val_loss: 0.6177 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 159/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6966 - accuracy: 0.7601 - val_loss: 0.6179 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 160/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7024 - accuracy: 0.7550 - val_loss: 0.6180 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 161/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7152 - accuracy: 0.7447 - val_loss: 0.6180 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 162/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6965 - accuracy: 0.7526 - val_loss: 0.6181 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 163/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7088 - accuracy: 0.7523 - val_loss: 0.6181 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 164/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7137 - accuracy: 0.7443 - val_loss: 0.6180 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 165/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7147 - accuracy: 0.7487 - val_loss: 0.6182 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 166/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7031 - accuracy: 0.7566 - val_loss: 0.6184 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 167/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7031 - accuracy: 0.7559 - val_loss: 0.6182 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 168/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7157 - accuracy: 0.7473 - val_loss: 0.6181 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 169/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6990 - accuracy: 0.7569 - val_loss: 0.6178 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 170/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7007 - accuracy: 0.7542 - val_loss: 0.6179 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 171/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7221 - accuracy: 0.7480 - val_loss: 0.6180 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 172/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7121 - accuracy: 0.7505 - val_loss: 0.6178 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 173/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7070 - accuracy: 0.7543 - val_loss: 0.6177 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 174/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7092 - accuracy: 0.7606 - val_loss: 0.6175 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 175/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6946 - accuracy: 0.7563 - val_loss: 0.6176 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 176/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7194 - accuracy: 0.7505 - val_loss: 0.6176 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 177/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6967 - accuracy: 0.7542 - val_loss: 0.6175 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 178/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7012 - accuracy: 0.7536 - val_loss: 0.6175 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 179/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6966 - accuracy: 0.7543 - val_loss: 0.6174 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 180/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7036 - accuracy: 0.7595 - val_loss: 0.6172 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 181/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7091 - accuracy: 0.7495 - val_loss: 0.6171 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 182/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7089 - accuracy: 0.7522 - val_loss: 0.6172 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 183/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6982 - accuracy: 0.7573 - val_loss: 0.6171 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 184/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6985 - accuracy: 0.7565 - val_loss: 0.6171 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 185/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6985 - accuracy: 0.7589 - val_loss: 0.6170 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 186/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7150 - accuracy: 0.7473 - val_loss: 0.6172 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 187/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7076 - accuracy: 0.7530 - val_loss: 0.6170 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 188/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7113 - accuracy: 0.7499 - val_loss: 0.6168 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 189/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7030 - accuracy: 0.7506 - val_loss: 0.6170 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 190/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7062 - accuracy: 0.7482 - val_loss: 0.6172 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 191/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7157 - accuracy: 0.7472 - val_loss: 0.6174 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 192/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7214 - accuracy: 0.7407 - val_loss: 0.6175 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 193/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7133 - accuracy: 0.7520 - val_loss: 0.6175 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 194/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7002 - accuracy: 0.7529 - val_loss: 0.6175 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 195/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7198 - accuracy: 0.7490 - val_loss: 0.6176 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 196/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6976 - accuracy: 0.7545 - val_loss: 0.6178 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 197/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7128 - accuracy: 0.7499 - val_loss: 0.6177 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 198/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7033 - accuracy: 0.7477 - val_loss: 0.6179 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 199/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6962 - accuracy: 0.7490 - val_loss: 0.6180 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 200/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7177 - accuracy: 0.7529 - val_loss: 0.6183 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 201/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7102 - accuracy: 0.7460 - val_loss: 0.6185 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 202/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7189 - accuracy: 0.7526 - val_loss: 0.6182 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 203/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7297 - accuracy: 0.7417 - val_loss: 0.6182 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 204/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7083 - accuracy: 0.7525 - val_loss: 0.6181 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 205/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7188 - accuracy: 0.7518 - val_loss: 0.6181 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 206/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7068 - accuracy: 0.7565 - val_loss: 0.6177 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 207/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7136 - accuracy: 0.7525 - val_loss: 0.6176 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 208/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7084 - accuracy: 0.7492 - val_loss: 0.6178 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 209/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7154 - accuracy: 0.7449 - val_loss: 0.6178 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 210/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7042 - accuracy: 0.7515 - val_loss: 0.6178 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 211/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7036 - accuracy: 0.7569 - val_loss: 0.6178 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 212/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7112 - accuracy: 0.7495 - val_loss: 0.6175 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 213/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6977 - accuracy: 0.7585 - val_loss: 0.6175 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 214/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7029 - accuracy: 0.7505 - val_loss: 0.6176 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 215/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7046 - accuracy: 0.7546 - val_loss: 0.6175 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 216/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6987 - accuracy: 0.7606 - val_loss: 0.6176 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 217/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7186 - accuracy: 0.7479 - val_loss: 0.6175 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 218/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7100 - accuracy: 0.7510 - val_loss: 0.6176 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 219/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7017 - accuracy: 0.7609 - val_loss: 0.6178 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 220/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6998 - accuracy: 0.7578 - val_loss: 0.6176 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 221/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7045 - accuracy: 0.7562 - val_loss: 0.6174 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 222/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7016 - accuracy: 0.7595 - val_loss: 0.6177 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 223/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6840 - accuracy: 0.7575 - val_loss: 0.6177 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 224/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7051 - accuracy: 0.7513 - val_loss: 0.6176 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 225/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7083 - accuracy: 0.7542 - val_loss: 0.6175 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 226/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6949 - accuracy: 0.7571 - val_loss: 0.6174 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 227/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7147 - accuracy: 0.7539 - val_loss: 0.6175 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 228/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7027 - accuracy: 0.7589 - val_loss: 0.6173 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 229/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7045 - accuracy: 0.7536 - val_loss: 0.6173 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 230/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7108 - accuracy: 0.7509 - val_loss: 0.6176 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 231/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.7605 - val_loss: 0.6176 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 232/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7034 - accuracy: 0.7573 - val_loss: 0.6175 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 233/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7204 - accuracy: 0.7477 - val_loss: 0.6175 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 234/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7066 - accuracy: 0.7503 - val_loss: 0.6173 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 235/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6962 - accuracy: 0.7595 - val_loss: 0.6172 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 236/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7014 - accuracy: 0.7606 - val_loss: 0.6172 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 237/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7114 - accuracy: 0.7589 - val_loss: 0.6170 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 238/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7127 - accuracy: 0.7467 - val_loss: 0.6170 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 239/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7101 - accuracy: 0.7469 - val_loss: 0.6171 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 240/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7018 - accuracy: 0.7509 - val_loss: 0.6169 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 241/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7214 - accuracy: 0.7472 - val_loss: 0.6168 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 242/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7115 - accuracy: 0.7530 - val_loss: 0.6165 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 243/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6968 - accuracy: 0.7573 - val_loss: 0.6165 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 244/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6954 - accuracy: 0.7549 - val_loss: 0.6167 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 245/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6933 - accuracy: 0.7589 - val_loss: 0.6165 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 246/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6889 - accuracy: 0.7595 - val_loss: 0.6164 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 247/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7117 - accuracy: 0.7482 - val_loss: 0.6165 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 248/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7106 - accuracy: 0.7535 - val_loss: 0.6166 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 249/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6945 - accuracy: 0.7592 - val_loss: 0.6168 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 250/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6955 - accuracy: 0.7575 - val_loss: 0.6168 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 251/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7004 - accuracy: 0.7559 - val_loss: 0.6168 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 252/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6960 - accuracy: 0.7540 - val_loss: 0.6169 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 253/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7185 - accuracy: 0.7522 - val_loss: 0.6168 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 254/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7040 - accuracy: 0.7523 - val_loss: 0.6167 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 255/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7160 - accuracy: 0.7542 - val_loss: 0.6169 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 256/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6969 - accuracy: 0.7543 - val_loss: 0.6173 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 257/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7154 - accuracy: 0.7516 - val_loss: 0.6173 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 258/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7103 - accuracy: 0.7573 - val_loss: 0.6171 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 259/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7062 - accuracy: 0.7510 - val_loss: 0.6171 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 260/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6987 - accuracy: 0.7526 - val_loss: 0.6172 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 261/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7053 - accuracy: 0.7571 - val_loss: 0.6173 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 262/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7014 - accuracy: 0.7572 - val_loss: 0.6175 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 263/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7011 - accuracy: 0.7592 - val_loss: 0.6178 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 264/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6896 - accuracy: 0.7591 - val_loss: 0.6177 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 265/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7146 - accuracy: 0.7508 - val_loss: 0.6178 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 266/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6947 - accuracy: 0.7556 - val_loss: 0.6178 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 267/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7076 - accuracy: 0.7505 - val_loss: 0.6176 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 268/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7193 - accuracy: 0.7489 - val_loss: 0.6174 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 269/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7124 - accuracy: 0.7489 - val_loss: 0.6175 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 270/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6938 - accuracy: 0.7565 - val_loss: 0.6174 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 271/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7174 - accuracy: 0.7492 - val_loss: 0.6174 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 272/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6965 - accuracy: 0.7533 - val_loss: 0.6171 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 273/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6891 - accuracy: 0.7632 - val_loss: 0.6173 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 274/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7131 - accuracy: 0.7479 - val_loss: 0.6173 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 275/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7097 - accuracy: 0.7516 - val_loss: 0.6172 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 276/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7054 - accuracy: 0.7495 - val_loss: 0.6172 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 277/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7136 - accuracy: 0.7519 - val_loss: 0.6172 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 278/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7012 - accuracy: 0.7508 - val_loss: 0.6173 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 279/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6987 - accuracy: 0.7543 - val_loss: 0.6173 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 280/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7103 - accuracy: 0.7516 - val_loss: 0.6173 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 281/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7070 - accuracy: 0.7543 - val_loss: 0.6172 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 282/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6988 - accuracy: 0.7603 - val_loss: 0.6171 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 283/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6893 - accuracy: 0.7592 - val_loss: 0.6174 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 284/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7076 - accuracy: 0.7535 - val_loss: 0.6174 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 285/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7215 - accuracy: 0.7476 - val_loss: 0.6170 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 286/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7077 - accuracy: 0.7571 - val_loss: 0.6168 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 287/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6995 - accuracy: 0.7530 - val_loss: 0.6167 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 288/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7023 - accuracy: 0.7529 - val_loss: 0.6170 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 289/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7036 - accuracy: 0.7549 - val_loss: 0.6169 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 290/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7059 - accuracy: 0.7581 - val_loss: 0.6168 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 291/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7041 - accuracy: 0.7559 - val_loss: 0.6167 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 292/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7073 - accuracy: 0.7572 - val_loss: 0.6167 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 293/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6951 - accuracy: 0.7556 - val_loss: 0.6173 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 294/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7170 - accuracy: 0.7497 - val_loss: 0.6172 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 295/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7108 - accuracy: 0.7559 - val_loss: 0.6171 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 296/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7065 - accuracy: 0.7562 - val_loss: 0.6172 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 297/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7129 - accuracy: 0.7550 - val_loss: 0.6170 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 298/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7111 - accuracy: 0.7579 - val_loss: 0.6169 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 299/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7125 - accuracy: 0.7530 - val_loss: 0.6168 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 300/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6959 - accuracy: 0.7612 - val_loss: 0.6171 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 301/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6858 - accuracy: 0.7608 - val_loss: 0.6169 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 302/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7049 - accuracy: 0.7505 - val_loss: 0.6169 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 303/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6936 - accuracy: 0.7565 - val_loss: 0.6170 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 304/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6853 - accuracy: 0.7569 - val_loss: 0.6172 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 305/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6999 - accuracy: 0.7505 - val_loss: 0.6173 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 306/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6935 - accuracy: 0.7578 - val_loss: 0.6172 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 307/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7000 - accuracy: 0.7555 - val_loss: 0.6173 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 308/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6969 - accuracy: 0.7576 - val_loss: 0.6172 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 309/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7027 - accuracy: 0.7522 - val_loss: 0.6172 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 310/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7069 - accuracy: 0.7556 - val_loss: 0.6171 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 311/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7021 - accuracy: 0.7520 - val_loss: 0.6170 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 312/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7350 - accuracy: 0.7410 - val_loss: 0.6167 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 313/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6959 - accuracy: 0.7598 - val_loss: 0.6165 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 314/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7031 - accuracy: 0.7546 - val_loss: 0.6166 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 315/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6988 - accuracy: 0.7512 - val_loss: 0.6167 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 316/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7062 - accuracy: 0.7571 - val_loss: 0.6169 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 317/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7179 - accuracy: 0.7492 - val_loss: 0.6168 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 318/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7081 - accuracy: 0.7565 - val_loss: 0.6169 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 319/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6994 - accuracy: 0.7579 - val_loss: 0.6172 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 320/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7186 - accuracy: 0.7442 - val_loss: 0.6172 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 321/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7182 - accuracy: 0.7512 - val_loss: 0.6170 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 322/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.7065 - accuracy: 0.7552 - val_loss: 0.6167 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 323/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7095 - accuracy: 0.7492 - val_loss: 0.6168 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 324/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7074 - accuracy: 0.7545 - val_loss: 0.6168 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 325/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6859 - accuracy: 0.7628 - val_loss: 0.6167 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 326/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6976 - accuracy: 0.7553 - val_loss: 0.6167 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 327/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7133 - accuracy: 0.7483 - val_loss: 0.6169 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 328/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6756 - accuracy: 0.7654 - val_loss: 0.6172 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 329/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7117 - accuracy: 0.7453 - val_loss: 0.6170 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 330/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6979 - accuracy: 0.7539 - val_loss: 0.6170 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 331/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6916 - accuracy: 0.7548 - val_loss: 0.6169 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 332/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7156 - accuracy: 0.7457 - val_loss: 0.6169 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 333/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7217 - accuracy: 0.7496 - val_loss: 0.6171 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 334/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6918 - accuracy: 0.7576 - val_loss: 0.6172 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 335/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7043 - accuracy: 0.7523 - val_loss: 0.6171 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 336/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7211 - accuracy: 0.7503 - val_loss: 0.6172 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 337/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6983 - accuracy: 0.7545 - val_loss: 0.6172 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 338/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7134 - accuracy: 0.7496 - val_loss: 0.6172 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 339/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7069 - accuracy: 0.7562 - val_loss: 0.6170 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 340/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7148 - accuracy: 0.7493 - val_loss: 0.6170 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 341/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7131 - accuracy: 0.7500 - val_loss: 0.6170 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 342/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7020 - accuracy: 0.7553 - val_loss: 0.6168 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 343/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6877 - accuracy: 0.7578 - val_loss: 0.6168 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 344/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7063 - accuracy: 0.7542 - val_loss: 0.6170 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 345/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7112 - accuracy: 0.7506 - val_loss: 0.6171 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 346/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7257 - accuracy: 0.7492 - val_loss: 0.6169 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 347/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7324 - accuracy: 0.7450 - val_loss: 0.6169 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 348/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7035 - accuracy: 0.7565 - val_loss: 0.6169 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 349/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7079 - accuracy: 0.7477 - val_loss: 0.6172 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 350/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7071 - accuracy: 0.7503 - val_loss: 0.6172 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 351/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6995 - accuracy: 0.7559 - val_loss: 0.6171 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 352/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7012 - accuracy: 0.7565 - val_loss: 0.6169 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 353/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6912 - accuracy: 0.7576 - val_loss: 0.6172 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 354/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6969 - accuracy: 0.7562 - val_loss: 0.6173 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 355/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7118 - accuracy: 0.7538 - val_loss: 0.6173 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 356/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7106 - accuracy: 0.7519 - val_loss: 0.6174 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 357/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7124 - accuracy: 0.7576 - val_loss: 0.6174 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 358/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7036 - accuracy: 0.7536 - val_loss: 0.6173 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 359/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6858 - accuracy: 0.7582 - val_loss: 0.6173 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 360/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7035 - accuracy: 0.7506 - val_loss: 0.6172 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 361/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6936 - accuracy: 0.7579 - val_loss: 0.6170 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 362/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7040 - accuracy: 0.7518 - val_loss: 0.6171 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 363/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7187 - accuracy: 0.7485 - val_loss: 0.6171 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 364/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7033 - accuracy: 0.7472 - val_loss: 0.6174 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 365/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7035 - accuracy: 0.7496 - val_loss: 0.6172 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 366/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7049 - accuracy: 0.7473 - val_loss: 0.6174 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 367/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7266 - accuracy: 0.7457 - val_loss: 0.6173 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 368/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7094 - accuracy: 0.7520 - val_loss: 0.6174 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 369/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7045 - accuracy: 0.7533 - val_loss: 0.6173 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 370/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7106 - accuracy: 0.7499 - val_loss: 0.6171 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 371/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6933 - accuracy: 0.7622 - val_loss: 0.6173 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 372/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6988 - accuracy: 0.7499 - val_loss: 0.6172 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 373/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7048 - accuracy: 0.7569 - val_loss: 0.6171 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 374/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6911 - accuracy: 0.7571 - val_loss: 0.6169 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 375/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7121 - accuracy: 0.7529 - val_loss: 0.6170 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 376/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7003 - accuracy: 0.7480 - val_loss: 0.6169 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 377/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7154 - accuracy: 0.7490 - val_loss: 0.6167 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 378/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7054 - accuracy: 0.7545 - val_loss: 0.6170 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 379/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7190 - accuracy: 0.7485 - val_loss: 0.6172 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 380/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7073 - accuracy: 0.7563 - val_loss: 0.6174 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 381/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7166 - accuracy: 0.7479 - val_loss: 0.6171 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 382/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7012 - accuracy: 0.7506 - val_loss: 0.6173 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 383/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7046 - accuracy: 0.7548 - val_loss: 0.6172 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 384/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7071 - accuracy: 0.7540 - val_loss: 0.6172 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 385/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7089 - accuracy: 0.7515 - val_loss: 0.6169 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 386/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7069 - accuracy: 0.7538 - val_loss: 0.6169 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 387/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6909 - accuracy: 0.7572 - val_loss: 0.6169 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 388/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6990 - accuracy: 0.7545 - val_loss: 0.6169 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 389/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6975 - accuracy: 0.7581 - val_loss: 0.6171 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 390/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7098 - accuracy: 0.7543 - val_loss: 0.6172 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 391/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7071 - accuracy: 0.7542 - val_loss: 0.6175 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 392/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7093 - accuracy: 0.7563 - val_loss: 0.6179 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 393/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7075 - accuracy: 0.7495 - val_loss: 0.6181 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 394/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7055 - accuracy: 0.7565 - val_loss: 0.6178 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 395/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7121 - accuracy: 0.7516 - val_loss: 0.6176 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 396/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7028 - accuracy: 0.7575 - val_loss: 0.6177 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 397/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6974 - accuracy: 0.7578 - val_loss: 0.6176 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 398/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7132 - accuracy: 0.7467 - val_loss: 0.6174 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 399/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6969 - accuracy: 0.7611 - val_loss: 0.6176 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 400/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7206 - accuracy: 0.7512 - val_loss: 0.6175 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 401/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7064 - accuracy: 0.7558 - val_loss: 0.6171 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 402/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7008 - accuracy: 0.7563 - val_loss: 0.6170 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 403/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7016 - accuracy: 0.7560 - val_loss: 0.6171 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 404/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7061 - accuracy: 0.7588 - val_loss: 0.6172 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 405/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7041 - accuracy: 0.7496 - val_loss: 0.6173 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 406/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7115 - accuracy: 0.7533 - val_loss: 0.6174 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 407/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6874 - accuracy: 0.7538 - val_loss: 0.6174 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 408/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7058 - accuracy: 0.7542 - val_loss: 0.6171 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 409/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7008 - accuracy: 0.7486 - val_loss: 0.6169 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 410/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7073 - accuracy: 0.7581 - val_loss: 0.6168 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 411/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7072 - accuracy: 0.7565 - val_loss: 0.6170 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 412/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7004 - accuracy: 0.7543 - val_loss: 0.6170 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 413/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7115 - accuracy: 0.7477 - val_loss: 0.6168 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 414/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7077 - accuracy: 0.7532 - val_loss: 0.6168 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 415/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7110 - accuracy: 0.7546 - val_loss: 0.6169 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 416/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6951 - accuracy: 0.7588 - val_loss: 0.6171 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 417/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7072 - accuracy: 0.7546 - val_loss: 0.6171 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 418/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7104 - accuracy: 0.7510 - val_loss: 0.6175 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 419/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6845 - accuracy: 0.7605 - val_loss: 0.6175 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 420/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7102 - accuracy: 0.7579 - val_loss: 0.6175 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 421/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7063 - accuracy: 0.7532 - val_loss: 0.6176 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 422/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7112 - accuracy: 0.7500 - val_loss: 0.6176 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 423/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6933 - accuracy: 0.7596 - val_loss: 0.6177 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 424/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7072 - accuracy: 0.7505 - val_loss: 0.6176 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 425/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6881 - accuracy: 0.7591 - val_loss: 0.6177 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 426/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7142 - accuracy: 0.7515 - val_loss: 0.6179 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 427/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6988 - accuracy: 0.7585 - val_loss: 0.6174 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 428/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7238 - accuracy: 0.7482 - val_loss: 0.6174 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 429/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7077 - accuracy: 0.7556 - val_loss: 0.6174 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 430/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7057 - accuracy: 0.7579 - val_loss: 0.6174 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 431/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6940 - accuracy: 0.7538 - val_loss: 0.6172 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 432/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7120 - accuracy: 0.7612 - val_loss: 0.6171 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 433/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7008 - accuracy: 0.7569 - val_loss: 0.6172 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 434/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6961 - accuracy: 0.7523 - val_loss: 0.6175 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 435/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7112 - accuracy: 0.7540 - val_loss: 0.6175 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 436/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7172 - accuracy: 0.7497 - val_loss: 0.6173 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 437/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7153 - accuracy: 0.7515 - val_loss: 0.6170 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 438/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7037 - accuracy: 0.7592 - val_loss: 0.6172 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 439/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7016 - accuracy: 0.7535 - val_loss: 0.6170 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 440/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7092 - accuracy: 0.7513 - val_loss: 0.6168 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 441/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7015 - accuracy: 0.7536 - val_loss: 0.6171 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 442/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7118 - accuracy: 0.7540 - val_loss: 0.6172 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 443/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6994 - accuracy: 0.7588 - val_loss: 0.6171 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 444/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7175 - accuracy: 0.7518 - val_loss: 0.6171 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 445/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6964 - accuracy: 0.7583 - val_loss: 0.6171 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 446/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7036 - accuracy: 0.7563 - val_loss: 0.6168 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 447/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7085 - accuracy: 0.7545 - val_loss: 0.6165 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 448/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6974 - accuracy: 0.7540 - val_loss: 0.6165 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 449/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7043 - accuracy: 0.7565 - val_loss: 0.6169 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 450/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7072 - accuracy: 0.7538 - val_loss: 0.6169 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 451/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6868 - accuracy: 0.7576 - val_loss: 0.6169 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 452/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7011 - accuracy: 0.7583 - val_loss: 0.6167 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 453/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7029 - accuracy: 0.7525 - val_loss: 0.6167 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 454/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7121 - accuracy: 0.7515 - val_loss: 0.6171 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 455/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6994 - accuracy: 0.7560 - val_loss: 0.6172 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 456/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7031 - accuracy: 0.7505 - val_loss: 0.6173 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 457/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7092 - accuracy: 0.7553 - val_loss: 0.6172 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 458/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7108 - accuracy: 0.7523 - val_loss: 0.6168 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 459/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7026 - accuracy: 0.7579 - val_loss: 0.6169 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 460/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7017 - accuracy: 0.7599 - val_loss: 0.6170 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 461/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7063 - accuracy: 0.7582 - val_loss: 0.6169 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 462/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7066 - accuracy: 0.7612 - val_loss: 0.6169 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 463/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7104 - accuracy: 0.7565 - val_loss: 0.6168 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 464/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7021 - accuracy: 0.7552 - val_loss: 0.6171 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 465/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7156 - accuracy: 0.7459 - val_loss: 0.6169 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 466/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7133 - accuracy: 0.7523 - val_loss: 0.6170 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 467/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6942 - accuracy: 0.7578 - val_loss: 0.6169 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 468/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7082 - accuracy: 0.7519 - val_loss: 0.6171 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 469/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7159 - accuracy: 0.7490 - val_loss: 0.6172 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 470/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7016 - accuracy: 0.7549 - val_loss: 0.6172 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 471/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7144 - accuracy: 0.7556 - val_loss: 0.6172 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 472/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7094 - accuracy: 0.7520 - val_loss: 0.6171 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 473/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6956 - accuracy: 0.7556 - val_loss: 0.6173 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 474/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7281 - accuracy: 0.7518 - val_loss: 0.6175 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 475/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7065 - accuracy: 0.7529 - val_loss: 0.6175 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 476/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6995 - accuracy: 0.7532 - val_loss: 0.6172 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 477/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6944 - accuracy: 0.7560 - val_loss: 0.6172 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 478/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7030 - accuracy: 0.7568 - val_loss: 0.6174 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 479/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7012 - accuracy: 0.7566 - val_loss: 0.6172 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 480/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6933 - accuracy: 0.7592 - val_loss: 0.6170 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 481/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6872 - accuracy: 0.7602 - val_loss: 0.6171 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 482/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7122 - accuracy: 0.7479 - val_loss: 0.6171 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 483/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6880 - accuracy: 0.7530 - val_loss: 0.6169 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 484/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7060 - accuracy: 0.7538 - val_loss: 0.6171 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 485/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7127 - accuracy: 0.7529 - val_loss: 0.6169 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 486/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.7067 - accuracy: 0.7535 - val_loss: 0.6169 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 487/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7046 - accuracy: 0.7523 - val_loss: 0.6170 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 488/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6999 - accuracy: 0.7569 - val_loss: 0.6168 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 489/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6994 - accuracy: 0.7591 - val_loss: 0.6171 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 490/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6880 - accuracy: 0.7572 - val_loss: 0.6170 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 491/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7087 - accuracy: 0.7500 - val_loss: 0.6172 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 492/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7056 - accuracy: 0.7492 - val_loss: 0.6173 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 493/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6815 - accuracy: 0.7601 - val_loss: 0.6172 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 494/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6992 - accuracy: 0.7516 - val_loss: 0.6176 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 495/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7044 - accuracy: 0.7559 - val_loss: 0.6177 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 496/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7256 - accuracy: 0.7495 - val_loss: 0.6179 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 497/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7053 - accuracy: 0.7489 - val_loss: 0.6178 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 498/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7053 - accuracy: 0.7532 - val_loss: 0.6177 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 499/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7049 - accuracy: 0.7499 - val_loss: 0.6174 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 500/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7086 - accuracy: 0.7556 - val_loss: 0.6173 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 501/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7105 - accuracy: 0.7486 - val_loss: 0.6174 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 502/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7071 - accuracy: 0.7539 - val_loss: 0.6173 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 503/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7074 - accuracy: 0.7538 - val_loss: 0.6172 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 504/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7188 - accuracy: 0.7555 - val_loss: 0.6168 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 505/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6850 - accuracy: 0.7649 - val_loss: 0.6168 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 506/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7035 - accuracy: 0.7499 - val_loss: 0.6169 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 507/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6752 - accuracy: 0.7582 - val_loss: 0.6170 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 508/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7096 - accuracy: 0.7539 - val_loss: 0.6172 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 509/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7063 - accuracy: 0.7520 - val_loss: 0.6173 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 510/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7119 - accuracy: 0.7519 - val_loss: 0.6174 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 511/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6967 - accuracy: 0.7602 - val_loss: 0.6175 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 512/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6992 - accuracy: 0.7519 - val_loss: 0.6173 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 513/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7114 - accuracy: 0.7558 - val_loss: 0.6176 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 514/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7145 - accuracy: 0.7518 - val_loss: 0.6173 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 515/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7173 - accuracy: 0.7480 - val_loss: 0.6171 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 516/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6987 - accuracy: 0.7611 - val_loss: 0.6173 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 517/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6821 - accuracy: 0.7611 - val_loss: 0.6174 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 518/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6995 - accuracy: 0.7556 - val_loss: 0.6174 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 519/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7215 - accuracy: 0.7480 - val_loss: 0.6172 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 520/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6937 - accuracy: 0.7522 - val_loss: 0.6170 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 521/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7218 - accuracy: 0.7512 - val_loss: 0.6167 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 522/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7085 - accuracy: 0.7477 - val_loss: 0.6170 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 523/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6961 - accuracy: 0.7566 - val_loss: 0.6170 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 524/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6994 - accuracy: 0.7536 - val_loss: 0.6173 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 525/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7033 - accuracy: 0.7530 - val_loss: 0.6171 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 526/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7014 - accuracy: 0.7602 - val_loss: 0.6172 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 527/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7085 - accuracy: 0.7538 - val_loss: 0.6172 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 528/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7103 - accuracy: 0.7540 - val_loss: 0.6172 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 529/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7115 - accuracy: 0.7520 - val_loss: 0.6172 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 530/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6952 - accuracy: 0.7546 - val_loss: 0.6174 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 531/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7014 - accuracy: 0.7538 - val_loss: 0.6171 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 532/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6956 - accuracy: 0.7558 - val_loss: 0.6169 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 533/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6820 - accuracy: 0.7605 - val_loss: 0.6168 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 534/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7055 - accuracy: 0.7569 - val_loss: 0.6167 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 535/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6942 - accuracy: 0.7546 - val_loss: 0.6171 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 536/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6971 - accuracy: 0.7555 - val_loss: 0.6172 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 537/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7202 - accuracy: 0.7489 - val_loss: 0.6173 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 538/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7095 - accuracy: 0.7563 - val_loss: 0.6173 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 539/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6899 - accuracy: 0.7639 - val_loss: 0.6173 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 540/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6976 - accuracy: 0.7575 - val_loss: 0.6172 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 541/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7096 - accuracy: 0.7563 - val_loss: 0.6169 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 542/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7114 - accuracy: 0.7487 - val_loss: 0.6169 - val_accuracy: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 543/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6965 - accuracy: 0.7538 - val_loss: 0.6170 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 544/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7157 - accuracy: 0.7599 - val_loss: 0.6169 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 545/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7079 - accuracy: 0.7553 - val_loss: 0.6171 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 546/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6970 - accuracy: 0.7618 - val_loss: 0.6170 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 547/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7027 - accuracy: 0.7559 - val_loss: 0.6171 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 548/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7096 - accuracy: 0.7543 - val_loss: 0.6173 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 549/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7019 - accuracy: 0.7526 - val_loss: 0.6171 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 550/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7025 - accuracy: 0.7591 - val_loss: 0.6172 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 551/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7226 - accuracy: 0.7440 - val_loss: 0.6173 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 552/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6834 - accuracy: 0.7622 - val_loss: 0.6175 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 553/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6924 - accuracy: 0.7623 - val_loss: 0.6174 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 554/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6967 - accuracy: 0.7526 - val_loss: 0.6171 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 555/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7124 - accuracy: 0.7530 - val_loss: 0.6168 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 556/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7099 - accuracy: 0.7533 - val_loss: 0.6166 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 557/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7070 - accuracy: 0.7526 - val_loss: 0.6167 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 558/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7073 - accuracy: 0.7592 - val_loss: 0.6170 - val_accuracy: 0.7882 - lr: 1.0000e-05\n",
            "Epoch 559/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7067 - accuracy: 0.7548 - val_loss: 0.6170 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 560/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7108 - accuracy: 0.7540 - val_loss: 0.6171 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 561/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7187 - accuracy: 0.7496 - val_loss: 0.6173 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 562/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7012 - accuracy: 0.7565 - val_loss: 0.6173 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 563/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7110 - accuracy: 0.7456 - val_loss: 0.6171 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 564/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7079 - accuracy: 0.7571 - val_loss: 0.6169 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 565/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7078 - accuracy: 0.7483 - val_loss: 0.6171 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 566/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7035 - accuracy: 0.7500 - val_loss: 0.6173 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 567/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7120 - accuracy: 0.7470 - val_loss: 0.6175 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 568/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6882 - accuracy: 0.7629 - val_loss: 0.6177 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 569/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7150 - accuracy: 0.7497 - val_loss: 0.6176 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 570/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7050 - accuracy: 0.7480 - val_loss: 0.6175 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 571/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6919 - accuracy: 0.7586 - val_loss: 0.6173 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 572/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6877 - accuracy: 0.7636 - val_loss: 0.6170 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 573/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7047 - accuracy: 0.7542 - val_loss: 0.6172 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 574/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6967 - accuracy: 0.7569 - val_loss: 0.6172 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 575/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7043 - accuracy: 0.7586 - val_loss: 0.6173 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 576/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6981 - accuracy: 0.7601 - val_loss: 0.6173 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 577/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6953 - accuracy: 0.7602 - val_loss: 0.6174 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 578/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7043 - accuracy: 0.7582 - val_loss: 0.6174 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 579/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7164 - accuracy: 0.7486 - val_loss: 0.6173 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 580/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6983 - accuracy: 0.7526 - val_loss: 0.6176 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 581/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7090 - accuracy: 0.7497 - val_loss: 0.6176 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 582/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6959 - accuracy: 0.7497 - val_loss: 0.6175 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 583/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6891 - accuracy: 0.7608 - val_loss: 0.6174 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 584/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7197 - accuracy: 0.7489 - val_loss: 0.6174 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 585/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7038 - accuracy: 0.7616 - val_loss: 0.6175 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 586/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7073 - accuracy: 0.7522 - val_loss: 0.6177 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 587/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7044 - accuracy: 0.7515 - val_loss: 0.6172 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 588/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7053 - accuracy: 0.7475 - val_loss: 0.6171 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 589/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6918 - accuracy: 0.7528 - val_loss: 0.6171 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 590/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6939 - accuracy: 0.7522 - val_loss: 0.6171 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 591/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7089 - accuracy: 0.7533 - val_loss: 0.6170 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 592/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6913 - accuracy: 0.7586 - val_loss: 0.6168 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 593/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7073 - accuracy: 0.7549 - val_loss: 0.6170 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 594/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7089 - accuracy: 0.7532 - val_loss: 0.6168 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 595/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7121 - accuracy: 0.7575 - val_loss: 0.6167 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 596/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7001 - accuracy: 0.7579 - val_loss: 0.6165 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 597/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7132 - accuracy: 0.7503 - val_loss: 0.6165 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 598/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6992 - accuracy: 0.7563 - val_loss: 0.6164 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 599/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6891 - accuracy: 0.7606 - val_loss: 0.6164 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 600/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6951 - accuracy: 0.7559 - val_loss: 0.6163 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
            "Epoch 601/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6907 - accuracy: 0.7575 - val_loss: 0.6162 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 602/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7045 - accuracy: 0.7563 - val_loss: 0.6166 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 603/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7106 - accuracy: 0.7519 - val_loss: 0.6168 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 604/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7102 - accuracy: 0.7516 - val_loss: 0.6169 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 605/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7073 - accuracy: 0.7546 - val_loss: 0.6172 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 606/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7079 - accuracy: 0.7553 - val_loss: 0.6172 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 607/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7148 - accuracy: 0.7535 - val_loss: 0.6170 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 608/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6997 - accuracy: 0.7613 - val_loss: 0.6167 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 609/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7125 - accuracy: 0.7509 - val_loss: 0.6168 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 610/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6985 - accuracy: 0.7540 - val_loss: 0.6168 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 611/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6995 - accuracy: 0.7585 - val_loss: 0.6168 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 612/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7060 - accuracy: 0.7490 - val_loss: 0.6171 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 613/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7081 - accuracy: 0.7508 - val_loss: 0.6171 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 614/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6981 - accuracy: 0.7553 - val_loss: 0.6172 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 615/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7096 - accuracy: 0.7502 - val_loss: 0.6171 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 616/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7091 - accuracy: 0.7532 - val_loss: 0.6173 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 617/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6962 - accuracy: 0.7565 - val_loss: 0.6172 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 618/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6977 - accuracy: 0.7601 - val_loss: 0.6172 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 619/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6945 - accuracy: 0.7538 - val_loss: 0.6172 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 620/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7078 - accuracy: 0.7482 - val_loss: 0.6171 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 621/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7050 - accuracy: 0.7525 - val_loss: 0.6174 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 622/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7024 - accuracy: 0.7595 - val_loss: 0.6173 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 623/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6986 - accuracy: 0.7549 - val_loss: 0.6176 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 624/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7110 - accuracy: 0.7568 - val_loss: 0.6175 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 625/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6973 - accuracy: 0.7533 - val_loss: 0.6177 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 626/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7103 - accuracy: 0.7549 - val_loss: 0.6176 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 627/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7143 - accuracy: 0.7496 - val_loss: 0.6176 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 628/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7109 - accuracy: 0.7581 - val_loss: 0.6175 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 629/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7197 - accuracy: 0.7510 - val_loss: 0.6172 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 630/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7055 - accuracy: 0.7510 - val_loss: 0.6174 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 631/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7052 - accuracy: 0.7555 - val_loss: 0.6173 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 632/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6953 - accuracy: 0.7601 - val_loss: 0.6172 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 633/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7020 - accuracy: 0.7550 - val_loss: 0.6172 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 634/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7065 - accuracy: 0.7611 - val_loss: 0.6171 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 635/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7218 - accuracy: 0.7497 - val_loss: 0.6169 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 636/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7144 - accuracy: 0.7520 - val_loss: 0.6167 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 637/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7226 - accuracy: 0.7492 - val_loss: 0.6167 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 638/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7047 - accuracy: 0.7512 - val_loss: 0.6167 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
            "Epoch 639/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7116 - accuracy: 0.7552 - val_loss: 0.6168 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 640/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6857 - accuracy: 0.7615 - val_loss: 0.6169 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 641/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7064 - accuracy: 0.7492 - val_loss: 0.6169 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 642/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7048 - accuracy: 0.7525 - val_loss: 0.6168 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
            "Epoch 643/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7080 - accuracy: 0.7528 - val_loss: 0.6169 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
            "Epoch 644/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6993 - accuracy: 0.7556 - val_loss: 0.6170 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
            "Epoch 645/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7178 - accuracy: 0.7487 - val_loss: 0.6171 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 646/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7042 - accuracy: 0.7545 - val_loss: 0.6173 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 647/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7048 - accuracy: 0.7572 - val_loss: 0.6174 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 648/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7080 - accuracy: 0.7526 - val_loss: 0.6175 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 649/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7162 - accuracy: 0.7528 - val_loss: 0.6177 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 650/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6972 - accuracy: 0.7568 - val_loss: 0.6176 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 651/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7051 - accuracy: 0.7565 - val_loss: 0.6176 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 652/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7063 - accuracy: 0.7596 - val_loss: 0.6179 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 653/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7146 - accuracy: 0.7516 - val_loss: 0.6176 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 654/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7135 - accuracy: 0.7516 - val_loss: 0.6177 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 655/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7031 - accuracy: 0.7553 - val_loss: 0.6174 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 656/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7014 - accuracy: 0.7526 - val_loss: 0.6173 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 657/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6927 - accuracy: 0.7552 - val_loss: 0.6170 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 658/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7116 - accuracy: 0.7529 - val_loss: 0.6170 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 659/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7010 - accuracy: 0.7529 - val_loss: 0.6171 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 660/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7124 - accuracy: 0.7456 - val_loss: 0.6168 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 661/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7138 - accuracy: 0.7609 - val_loss: 0.6168 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 662/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6954 - accuracy: 0.7559 - val_loss: 0.6169 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 663/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7045 - accuracy: 0.7585 - val_loss: 0.6169 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 664/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6954 - accuracy: 0.7606 - val_loss: 0.6169 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 665/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6989 - accuracy: 0.7581 - val_loss: 0.6168 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 666/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6981 - accuracy: 0.7568 - val_loss: 0.6167 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 667/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7001 - accuracy: 0.7520 - val_loss: 0.6168 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 668/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7097 - accuracy: 0.7520 - val_loss: 0.6171 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 669/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7123 - accuracy: 0.7519 - val_loss: 0.6172 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
            "Epoch 670/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7106 - accuracy: 0.7520 - val_loss: 0.6172 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
            "Epoch 671/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6974 - accuracy: 0.7632 - val_loss: 0.6171 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
            "Epoch 672/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7305 - accuracy: 0.7487 - val_loss: 0.6171 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 673/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6983 - accuracy: 0.7542 - val_loss: 0.6170 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 674/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7042 - accuracy: 0.7499 - val_loss: 0.6167 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 675/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7022 - accuracy: 0.7486 - val_loss: 0.6167 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 676/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6981 - accuracy: 0.7585 - val_loss: 0.6166 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 677/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7010 - accuracy: 0.7540 - val_loss: 0.6170 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 678/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6848 - accuracy: 0.7599 - val_loss: 0.6173 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 679/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6959 - accuracy: 0.7543 - val_loss: 0.6174 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 680/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6999 - accuracy: 0.7533 - val_loss: 0.6172 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 681/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7024 - accuracy: 0.7489 - val_loss: 0.6170 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 682/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6883 - accuracy: 0.7566 - val_loss: 0.6170 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 683/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7118 - accuracy: 0.7523 - val_loss: 0.6171 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 684/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7074 - accuracy: 0.7457 - val_loss: 0.6171 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 685/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7000 - accuracy: 0.7533 - val_loss: 0.6169 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 686/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6960 - accuracy: 0.7592 - val_loss: 0.6170 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 687/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7056 - accuracy: 0.7496 - val_loss: 0.6168 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 688/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7245 - accuracy: 0.7548 - val_loss: 0.6166 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 689/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7044 - accuracy: 0.7503 - val_loss: 0.6167 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 690/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7099 - accuracy: 0.7470 - val_loss: 0.6168 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 691/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7035 - accuracy: 0.7483 - val_loss: 0.6169 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 692/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6967 - accuracy: 0.7563 - val_loss: 0.6170 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 693/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7096 - accuracy: 0.7532 - val_loss: 0.6171 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 694/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7022 - accuracy: 0.7493 - val_loss: 0.6172 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 695/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7112 - accuracy: 0.7463 - val_loss: 0.6172 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 696/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6963 - accuracy: 0.7606 - val_loss: 0.6174 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 697/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7226 - accuracy: 0.7528 - val_loss: 0.6174 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 698/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6900 - accuracy: 0.7608 - val_loss: 0.6171 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 699/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6947 - accuracy: 0.7605 - val_loss: 0.6168 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 700/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7077 - accuracy: 0.7553 - val_loss: 0.6169 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 701/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6845 - accuracy: 0.7595 - val_loss: 0.6169 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 702/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7094 - accuracy: 0.7546 - val_loss: 0.6169 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 703/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6945 - accuracy: 0.7552 - val_loss: 0.6170 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 704/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6952 - accuracy: 0.7608 - val_loss: 0.6171 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 705/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7019 - accuracy: 0.7528 - val_loss: 0.6172 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 706/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6948 - accuracy: 0.7566 - val_loss: 0.6170 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 707/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7003 - accuracy: 0.7479 - val_loss: 0.6172 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 708/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7199 - accuracy: 0.7486 - val_loss: 0.6174 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 709/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7094 - accuracy: 0.7553 - val_loss: 0.6173 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 710/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7127 - accuracy: 0.7588 - val_loss: 0.6173 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 711/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7123 - accuracy: 0.7532 - val_loss: 0.6174 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 712/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6972 - accuracy: 0.7601 - val_loss: 0.6176 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 713/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7246 - accuracy: 0.7423 - val_loss: 0.6175 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 714/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6881 - accuracy: 0.7615 - val_loss: 0.6178 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 715/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7135 - accuracy: 0.7515 - val_loss: 0.6176 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 716/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7008 - accuracy: 0.7596 - val_loss: 0.6175 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 717/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6986 - accuracy: 0.7591 - val_loss: 0.6173 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 718/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6896 - accuracy: 0.7542 - val_loss: 0.6172 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
            "Epoch 719/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7086 - accuracy: 0.7549 - val_loss: 0.6170 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 720/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7095 - accuracy: 0.7556 - val_loss: 0.6169 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 721/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6942 - accuracy: 0.7609 - val_loss: 0.6169 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 722/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7129 - accuracy: 0.7509 - val_loss: 0.6172 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 723/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6949 - accuracy: 0.7589 - val_loss: 0.6170 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 724/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6911 - accuracy: 0.7526 - val_loss: 0.6169 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 725/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7295 - accuracy: 0.7493 - val_loss: 0.6170 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 726/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7058 - accuracy: 0.7602 - val_loss: 0.6167 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 727/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7097 - accuracy: 0.7539 - val_loss: 0.6167 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 728/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7077 - accuracy: 0.7556 - val_loss: 0.6168 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 729/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7097 - accuracy: 0.7505 - val_loss: 0.6171 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 730/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7125 - accuracy: 0.7475 - val_loss: 0.6171 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 731/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6991 - accuracy: 0.7566 - val_loss: 0.6171 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 732/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6959 - accuracy: 0.7532 - val_loss: 0.6170 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 733/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6931 - accuracy: 0.7579 - val_loss: 0.6175 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 734/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6982 - accuracy: 0.7591 - val_loss: 0.6172 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 735/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7057 - accuracy: 0.7542 - val_loss: 0.6170 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 736/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7130 - accuracy: 0.7532 - val_loss: 0.6170 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 737/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6948 - accuracy: 0.7568 - val_loss: 0.6168 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 738/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7042 - accuracy: 0.7513 - val_loss: 0.6166 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 739/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6974 - accuracy: 0.7579 - val_loss: 0.6167 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 740/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7140 - accuracy: 0.7528 - val_loss: 0.6166 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 741/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7066 - accuracy: 0.7566 - val_loss: 0.6165 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 742/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7040 - accuracy: 0.7529 - val_loss: 0.6164 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 743/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6997 - accuracy: 0.7603 - val_loss: 0.6163 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 744/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6941 - accuracy: 0.7603 - val_loss: 0.6163 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 745/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7137 - accuracy: 0.7485 - val_loss: 0.6165 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 746/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6965 - accuracy: 0.7509 - val_loss: 0.6168 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 747/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7010 - accuracy: 0.7506 - val_loss: 0.6168 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 748/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7037 - accuracy: 0.7539 - val_loss: 0.6169 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 749/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7037 - accuracy: 0.7559 - val_loss: 0.6169 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
            "Epoch 750/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7033 - accuracy: 0.7532 - val_loss: 0.6166 - val_accuracy: 0.7882 - lr: 1.0000e-05\n",
            "Epoch 751/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6853 - accuracy: 0.7635 - val_loss: 0.6164 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 752/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7031 - accuracy: 0.7532 - val_loss: 0.6165 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 753/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6994 - accuracy: 0.7513 - val_loss: 0.6166 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 754/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7059 - accuracy: 0.7539 - val_loss: 0.6167 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 755/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7118 - accuracy: 0.7543 - val_loss: 0.6167 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 756/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6989 - accuracy: 0.7565 - val_loss: 0.6169 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 757/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7166 - accuracy: 0.7463 - val_loss: 0.6170 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 758/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7036 - accuracy: 0.7555 - val_loss: 0.6171 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 759/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6896 - accuracy: 0.7585 - val_loss: 0.6168 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 760/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6842 - accuracy: 0.7616 - val_loss: 0.6167 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 761/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6905 - accuracy: 0.7588 - val_loss: 0.6165 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 762/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6799 - accuracy: 0.7611 - val_loss: 0.6163 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 763/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7091 - accuracy: 0.7533 - val_loss: 0.6162 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 764/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7063 - accuracy: 0.7545 - val_loss: 0.6163 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 765/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7074 - accuracy: 0.7589 - val_loss: 0.6163 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 766/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7131 - accuracy: 0.7530 - val_loss: 0.6161 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 767/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6994 - accuracy: 0.7508 - val_loss: 0.6161 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 768/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7170 - accuracy: 0.7522 - val_loss: 0.6164 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 769/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6975 - accuracy: 0.7536 - val_loss: 0.6165 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 770/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7095 - accuracy: 0.7500 - val_loss: 0.6163 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 771/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7035 - accuracy: 0.7535 - val_loss: 0.6158 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 772/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7026 - accuracy: 0.7581 - val_loss: 0.6161 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 773/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7085 - accuracy: 0.7509 - val_loss: 0.6159 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 774/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7116 - accuracy: 0.7546 - val_loss: 0.6157 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 775/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.6894 - accuracy: 0.7552 - val_loss: 0.6156 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 776/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7016 - accuracy: 0.7563 - val_loss: 0.6157 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 777/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7080 - accuracy: 0.7549 - val_loss: 0.6158 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 778/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6944 - accuracy: 0.7513 - val_loss: 0.6159 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 779/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6978 - accuracy: 0.7578 - val_loss: 0.6158 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 780/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7076 - accuracy: 0.7515 - val_loss: 0.6156 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 781/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7107 - accuracy: 0.7536 - val_loss: 0.6158 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 782/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6810 - accuracy: 0.7575 - val_loss: 0.6158 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 783/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7105 - accuracy: 0.7520 - val_loss: 0.6157 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 784/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6982 - accuracy: 0.7599 - val_loss: 0.6158 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 785/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7025 - accuracy: 0.7622 - val_loss: 0.6158 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 786/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7080 - accuracy: 0.7492 - val_loss: 0.6158 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 787/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7019 - accuracy: 0.7475 - val_loss: 0.6158 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 788/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7083 - accuracy: 0.7530 - val_loss: 0.6157 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 789/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7158 - accuracy: 0.7566 - val_loss: 0.6155 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 790/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7062 - accuracy: 0.7505 - val_loss: 0.6155 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 791/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7026 - accuracy: 0.7586 - val_loss: 0.6155 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 792/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7115 - accuracy: 0.7442 - val_loss: 0.6157 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 793/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7067 - accuracy: 0.7535 - val_loss: 0.6158 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 794/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7085 - accuracy: 0.7536 - val_loss: 0.6159 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 795/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7000 - accuracy: 0.7591 - val_loss: 0.6159 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 796/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7110 - accuracy: 0.7503 - val_loss: 0.6158 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
            "Epoch 797/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7074 - accuracy: 0.7548 - val_loss: 0.6158 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
            "Epoch 798/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6912 - accuracy: 0.7566 - val_loss: 0.6159 - val_accuracy: 0.7871 - lr: 1.0000e-05\n",
            "Epoch 799/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7041 - accuracy: 0.7583 - val_loss: 0.6159 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 800/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7044 - accuracy: 0.7530 - val_loss: 0.6159 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 801/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6906 - accuracy: 0.7566 - val_loss: 0.6158 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 802/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7041 - accuracy: 0.7550 - val_loss: 0.6156 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 803/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7096 - accuracy: 0.7486 - val_loss: 0.6158 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 804/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6834 - accuracy: 0.7609 - val_loss: 0.6157 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 805/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6929 - accuracy: 0.7566 - val_loss: 0.6155 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 806/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6927 - accuracy: 0.7550 - val_loss: 0.6154 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 807/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6896 - accuracy: 0.7615 - val_loss: 0.6156 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 808/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6991 - accuracy: 0.7576 - val_loss: 0.6159 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 809/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7217 - accuracy: 0.7469 - val_loss: 0.6161 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 810/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7059 - accuracy: 0.7515 - val_loss: 0.6163 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 811/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6972 - accuracy: 0.7555 - val_loss: 0.6162 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 812/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6975 - accuracy: 0.7573 - val_loss: 0.6161 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 813/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7031 - accuracy: 0.7516 - val_loss: 0.6161 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 814/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7004 - accuracy: 0.7518 - val_loss: 0.6160 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 815/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7012 - accuracy: 0.7529 - val_loss: 0.6161 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 816/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7015 - accuracy: 0.7566 - val_loss: 0.6162 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 817/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7021 - accuracy: 0.7532 - val_loss: 0.6164 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 818/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6970 - accuracy: 0.7601 - val_loss: 0.6161 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 819/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7017 - accuracy: 0.7540 - val_loss: 0.6158 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 820/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6996 - accuracy: 0.7612 - val_loss: 0.6161 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 821/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6969 - accuracy: 0.7550 - val_loss: 0.6160 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 822/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6921 - accuracy: 0.7566 - val_loss: 0.6159 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 823/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7050 - accuracy: 0.7606 - val_loss: 0.6159 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 824/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7155 - accuracy: 0.7497 - val_loss: 0.6157 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 825/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7223 - accuracy: 0.7486 - val_loss: 0.6159 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 826/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7189 - accuracy: 0.7533 - val_loss: 0.6161 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 827/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6907 - accuracy: 0.7605 - val_loss: 0.6163 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 828/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7079 - accuracy: 0.7533 - val_loss: 0.6160 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 829/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6961 - accuracy: 0.7576 - val_loss: 0.6160 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 830/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7080 - accuracy: 0.7553 - val_loss: 0.6159 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 831/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7044 - accuracy: 0.7539 - val_loss: 0.6162 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 832/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7174 - accuracy: 0.7489 - val_loss: 0.6165 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 833/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7048 - accuracy: 0.7516 - val_loss: 0.6166 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 834/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.6833 - accuracy: 0.7619 - val_loss: 0.6165 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 835/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6926 - accuracy: 0.7606 - val_loss: 0.6164 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 836/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6849 - accuracy: 0.7629 - val_loss: 0.6162 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 837/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7122 - accuracy: 0.7477 - val_loss: 0.6162 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 838/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7109 - accuracy: 0.7556 - val_loss: 0.6162 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 839/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7191 - accuracy: 0.7453 - val_loss: 0.6162 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 840/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6976 - accuracy: 0.7585 - val_loss: 0.6161 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 841/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6995 - accuracy: 0.7509 - val_loss: 0.6162 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 842/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7022 - accuracy: 0.7593 - val_loss: 0.6162 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 843/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.6928 - accuracy: 0.7565 - val_loss: 0.6162 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 844/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7117 - accuracy: 0.7529 - val_loss: 0.6160 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 845/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7140 - accuracy: 0.7532 - val_loss: 0.6164 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 846/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6906 - accuracy: 0.7609 - val_loss: 0.6164 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 847/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6920 - accuracy: 0.7578 - val_loss: 0.6164 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 848/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7011 - accuracy: 0.7545 - val_loss: 0.6161 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 849/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7162 - accuracy: 0.7539 - val_loss: 0.6158 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 850/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6779 - accuracy: 0.7596 - val_loss: 0.6157 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 851/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6926 - accuracy: 0.7589 - val_loss: 0.6159 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 852/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6867 - accuracy: 0.7581 - val_loss: 0.6161 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 853/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6973 - accuracy: 0.7581 - val_loss: 0.6161 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 854/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7004 - accuracy: 0.7539 - val_loss: 0.6156 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 855/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7046 - accuracy: 0.7519 - val_loss: 0.6156 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 856/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7110 - accuracy: 0.7576 - val_loss: 0.6159 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 857/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6983 - accuracy: 0.7563 - val_loss: 0.6159 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 858/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6989 - accuracy: 0.7591 - val_loss: 0.6157 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 859/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6970 - accuracy: 0.7520 - val_loss: 0.6156 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 860/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6981 - accuracy: 0.7542 - val_loss: 0.6156 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 861/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7018 - accuracy: 0.7509 - val_loss: 0.6157 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 862/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6927 - accuracy: 0.7552 - val_loss: 0.6158 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 863/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7280 - accuracy: 0.7413 - val_loss: 0.6160 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 864/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6962 - accuracy: 0.7550 - val_loss: 0.6160 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 865/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7162 - accuracy: 0.7476 - val_loss: 0.6162 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 866/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7177 - accuracy: 0.7482 - val_loss: 0.6163 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 867/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6968 - accuracy: 0.7573 - val_loss: 0.6163 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 868/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6953 - accuracy: 0.7581 - val_loss: 0.6159 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 869/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7092 - accuracy: 0.7520 - val_loss: 0.6160 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 870/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7048 - accuracy: 0.7508 - val_loss: 0.6159 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 871/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.6905 - accuracy: 0.7596 - val_loss: 0.6158 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 872/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7021 - accuracy: 0.7581 - val_loss: 0.6157 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 873/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7254 - accuracy: 0.7470 - val_loss: 0.6158 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 874/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7079 - accuracy: 0.7505 - val_loss: 0.6158 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 875/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.6941 - accuracy: 0.7528 - val_loss: 0.6158 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 876/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.6964 - accuracy: 0.7629 - val_loss: 0.6159 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 877/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6998 - accuracy: 0.7542 - val_loss: 0.6159 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 878/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6965 - accuracy: 0.7629 - val_loss: 0.6158 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 879/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7123 - accuracy: 0.7556 - val_loss: 0.6157 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 880/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7152 - accuracy: 0.7506 - val_loss: 0.6158 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 881/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6931 - accuracy: 0.7560 - val_loss: 0.6161 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 882/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7168 - accuracy: 0.7449 - val_loss: 0.6163 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 883/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7023 - accuracy: 0.7550 - val_loss: 0.6165 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 884/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7134 - accuracy: 0.7489 - val_loss: 0.6164 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 885/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7119 - accuracy: 0.7522 - val_loss: 0.6165 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 886/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7073 - accuracy: 0.7513 - val_loss: 0.6168 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 887/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6994 - accuracy: 0.7480 - val_loss: 0.6164 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 888/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7073 - accuracy: 0.7508 - val_loss: 0.6162 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 889/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7030 - accuracy: 0.7560 - val_loss: 0.6160 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 890/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7071 - accuracy: 0.7538 - val_loss: 0.6161 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 891/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7061 - accuracy: 0.7545 - val_loss: 0.6160 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 892/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7094 - accuracy: 0.7522 - val_loss: 0.6161 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 893/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7130 - accuracy: 0.7500 - val_loss: 0.6162 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 894/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.6987 - accuracy: 0.7615 - val_loss: 0.6163 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 895/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7039 - accuracy: 0.7553 - val_loss: 0.6164 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 896/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.6882 - accuracy: 0.7563 - val_loss: 0.6163 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 897/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6935 - accuracy: 0.7543 - val_loss: 0.6163 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 898/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7119 - accuracy: 0.7480 - val_loss: 0.6162 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 899/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7124 - accuracy: 0.7552 - val_loss: 0.6159 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 900/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7025 - accuracy: 0.7563 - val_loss: 0.6160 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 901/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7018 - accuracy: 0.7535 - val_loss: 0.6160 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 902/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7229 - accuracy: 0.7492 - val_loss: 0.6162 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 903/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7060 - accuracy: 0.7518 - val_loss: 0.6162 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 904/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7075 - accuracy: 0.7515 - val_loss: 0.6160 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 905/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7011 - accuracy: 0.7556 - val_loss: 0.6158 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 906/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6907 - accuracy: 0.7568 - val_loss: 0.6157 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 907/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6952 - accuracy: 0.7572 - val_loss: 0.6157 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 908/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6995 - accuracy: 0.7586 - val_loss: 0.6158 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 909/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6974 - accuracy: 0.7603 - val_loss: 0.6155 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 910/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7091 - accuracy: 0.7489 - val_loss: 0.6156 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 911/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7082 - accuracy: 0.7562 - val_loss: 0.6157 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 912/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7036 - accuracy: 0.7563 - val_loss: 0.6159 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 913/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7093 - accuracy: 0.7538 - val_loss: 0.6159 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 914/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7004 - accuracy: 0.7569 - val_loss: 0.6154 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 915/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7055 - accuracy: 0.7576 - val_loss: 0.6157 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 916/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7064 - accuracy: 0.7525 - val_loss: 0.6157 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 917/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6840 - accuracy: 0.7599 - val_loss: 0.6156 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 918/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7162 - accuracy: 0.7513 - val_loss: 0.6156 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 919/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7194 - accuracy: 0.7459 - val_loss: 0.6156 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 920/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6908 - accuracy: 0.7592 - val_loss: 0.6154 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 921/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7070 - accuracy: 0.7543 - val_loss: 0.6155 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 922/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6989 - accuracy: 0.7586 - val_loss: 0.6156 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 923/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7220 - accuracy: 0.7485 - val_loss: 0.6157 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 924/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.6957 - accuracy: 0.7566 - val_loss: 0.6158 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 925/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7055 - accuracy: 0.7555 - val_loss: 0.6155 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 926/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7032 - accuracy: 0.7555 - val_loss: 0.6156 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 927/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6917 - accuracy: 0.7602 - val_loss: 0.6155 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 928/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6960 - accuracy: 0.7535 - val_loss: 0.6154 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 929/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7092 - accuracy: 0.7563 - val_loss: 0.6153 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 930/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6953 - accuracy: 0.7576 - val_loss: 0.6155 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 931/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7054 - accuracy: 0.7599 - val_loss: 0.6156 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 932/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7145 - accuracy: 0.7510 - val_loss: 0.6155 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 933/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7132 - accuracy: 0.7560 - val_loss: 0.6156 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 934/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6946 - accuracy: 0.7499 - val_loss: 0.6159 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 935/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7093 - accuracy: 0.7523 - val_loss: 0.6159 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 936/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7059 - accuracy: 0.7513 - val_loss: 0.6158 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 937/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7080 - accuracy: 0.7611 - val_loss: 0.6158 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 938/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6846 - accuracy: 0.7559 - val_loss: 0.6155 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 939/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.6993 - accuracy: 0.7539 - val_loss: 0.6160 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 940/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7007 - accuracy: 0.7525 - val_loss: 0.6158 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 941/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7090 - accuracy: 0.7542 - val_loss: 0.6158 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 942/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7016 - accuracy: 0.7599 - val_loss: 0.6156 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 943/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7090 - accuracy: 0.7513 - val_loss: 0.6156 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 944/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6976 - accuracy: 0.7585 - val_loss: 0.6157 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 945/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7160 - accuracy: 0.7533 - val_loss: 0.6159 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 946/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7001 - accuracy: 0.7558 - val_loss: 0.6161 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 947/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.6959 - accuracy: 0.7568 - val_loss: 0.6160 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 948/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7012 - accuracy: 0.7513 - val_loss: 0.6159 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 949/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6953 - accuracy: 0.7588 - val_loss: 0.6160 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 950/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7002 - accuracy: 0.7578 - val_loss: 0.6159 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 951/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6957 - accuracy: 0.7533 - val_loss: 0.6162 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 952/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.6895 - accuracy: 0.7566 - val_loss: 0.6164 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 953/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7078 - accuracy: 0.7550 - val_loss: 0.6162 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 954/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.6855 - accuracy: 0.7611 - val_loss: 0.6162 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 955/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7019 - accuracy: 0.7536 - val_loss: 0.6160 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 956/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7185 - accuracy: 0.7490 - val_loss: 0.6158 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 957/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7025 - accuracy: 0.7510 - val_loss: 0.6157 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 958/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7076 - accuracy: 0.7499 - val_loss: 0.6159 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 959/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7058 - accuracy: 0.7533 - val_loss: 0.6159 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 960/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6872 - accuracy: 0.7581 - val_loss: 0.6161 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 961/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7107 - accuracy: 0.7512 - val_loss: 0.6161 - val_accuracy: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 962/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7057 - accuracy: 0.7539 - val_loss: 0.6161 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 963/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6983 - accuracy: 0.7568 - val_loss: 0.6159 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 964/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7055 - accuracy: 0.7533 - val_loss: 0.6160 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 965/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7043 - accuracy: 0.7503 - val_loss: 0.6161 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 966/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7053 - accuracy: 0.7532 - val_loss: 0.6160 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 967/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7059 - accuracy: 0.7535 - val_loss: 0.6157 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 968/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6971 - accuracy: 0.7552 - val_loss: 0.6156 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 969/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7030 - accuracy: 0.7518 - val_loss: 0.6155 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
            "Epoch 970/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7058 - accuracy: 0.7518 - val_loss: 0.6155 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 971/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6982 - accuracy: 0.7606 - val_loss: 0.6157 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 972/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7038 - accuracy: 0.7499 - val_loss: 0.6161 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 973/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7026 - accuracy: 0.7553 - val_loss: 0.6162 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 974/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7028 - accuracy: 0.7571 - val_loss: 0.6162 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 975/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7117 - accuracy: 0.7560 - val_loss: 0.6161 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 976/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.6975 - accuracy: 0.7569 - val_loss: 0.6162 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 977/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7148 - accuracy: 0.7535 - val_loss: 0.6161 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 978/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7232 - accuracy: 0.7522 - val_loss: 0.6159 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 979/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6758 - accuracy: 0.7681 - val_loss: 0.6159 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 980/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6863 - accuracy: 0.7576 - val_loss: 0.6159 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 981/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.6841 - accuracy: 0.7575 - val_loss: 0.6162 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 982/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7017 - accuracy: 0.7586 - val_loss: 0.6161 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 983/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6866 - accuracy: 0.7644 - val_loss: 0.6162 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 984/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7163 - accuracy: 0.7525 - val_loss: 0.6164 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 985/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7059 - accuracy: 0.7595 - val_loss: 0.6162 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 986/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6921 - accuracy: 0.7575 - val_loss: 0.6162 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 987/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.6904 - accuracy: 0.7588 - val_loss: 0.6164 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 988/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7103 - accuracy: 0.7493 - val_loss: 0.6163 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
            "Epoch 989/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6965 - accuracy: 0.7603 - val_loss: 0.6165 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 990/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6961 - accuracy: 0.7603 - val_loss: 0.6165 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 991/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7166 - accuracy: 0.7479 - val_loss: 0.6164 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 992/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7053 - accuracy: 0.7522 - val_loss: 0.6162 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 993/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7068 - accuracy: 0.7555 - val_loss: 0.6163 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 994/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7017 - accuracy: 0.7493 - val_loss: 0.6163 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 995/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.7029 - accuracy: 0.7569 - val_loss: 0.6162 - val_accuracy: 0.7819 - lr: 1.0000e-05\n",
            "Epoch 996/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6948 - accuracy: 0.7560 - val_loss: 0.6163 - val_accuracy: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 997/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7038 - accuracy: 0.7523 - val_loss: 0.6162 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 998/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.6977 - accuracy: 0.7572 - val_loss: 0.6163 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 999/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.6942 - accuracy: 0.7569 - val_loss: 0.6166 - val_accuracy: 0.7831 - lr: 1.0000e-05\n",
            "Epoch 1000/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.6930 - accuracy: 0.7589 - val_loss: 0.6166 - val_accuracy: 0.7836 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2dd5c295d0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}